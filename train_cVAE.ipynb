{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2146116d",
   "metadata": {},
   "source": [
    "# Conditional VAE for LHC Olympics 2020 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b61ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 15:25:21.230164: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-02 15:25:21.616732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/cray/pe/papi/6.0.0.12/lib64:/opt/cray/job/2.2.4-7.0.3.1_3.24__g36b56f4.ari/lib64:/opt/intel/compilers_and_libraries_2020.2.254/linux/compiler/lib/intel64:/opt/intel/compilers_and_libraries_2020.2.254/linux/mkl/lib/intel64:/global/common/software/nersc/cori-2022q1/sw/darshan/3.4.0/lib\n",
      "2022-12-02 15:25:21.616762: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-02 15:25:21.664885: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-02 15:25:28.186680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/cray/pe/papi/6.0.0.12/lib64:/opt/cray/job/2.2.4-7.0.3.1_3.24__g36b56f4.ari/lib64:/opt/intel/compilers_and_libraries_2020.2.254/linux/compiler/lib/intel64:/opt/intel/compilers_and_libraries_2020.2.254/linux/mkl/lib/intel64:/global/common/software/nersc/cori-2022q1/sw/darshan/3.4.0/lib\n",
      "2022-12-02 15:25:28.186987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/cray/pe/papi/6.0.0.12/lib64:/opt/cray/job/2.2.4-7.0.3.1_3.24__g36b56f4.ari/lib64:/opt/intel/compilers_and_libraries_2020.2.254/linux/compiler/lib/intel64:/opt/intel/compilers_and_libraries_2020.2.254/linux/mkl/lib/intel64:/global/common/software/nersc/cori-2022q1/sw/darshan/3.4.0/lib\n",
      "2022-12-02 15:25:28.187003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Add, Activation, Concatenate\n",
    "from tensorflow.keras.callbacks import History, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f9d9cd-d9c7-44f3-9826-2e1d6534ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea69fd3-14ef-42d6-a62e-081b44ef7593",
   "metadata": {},
   "source": [
    "## Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e521f29-c5e4-459c-ac00-8a2373b78269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data_train:  (499889, 6)\n",
      "shape of data_test:  (378759, 6)\n",
      "shape of data:  (878648, 6)\n",
      "shape of cond_train (499889,)\n",
      "shape of cond_test (378759,)\n",
      "shape of cond_data:  (878648,)\n"
     ]
    }
   ],
   "source": [
    "outerdata_train = np.load(\"./data/preprocessed_data_6var/outerdata_train_6var.npy\")\n",
    "outerdata_test = np.load(\"./data/preprocessed_data_6var/outerdata_test_6var.npy\")\n",
    "\n",
    "# Num of feature stored in the data files\n",
    "nFeat = 6\n",
    "# Num of feature we want to use for training\n",
    "input_dim = 6\n",
    "\n",
    "outerdata_train = outerdata_train[outerdata_train[:,nFeat+1]==0]\n",
    "outerdata_test = outerdata_test[outerdata_test[:,nFeat+1]==0]\n",
    "\n",
    "data_train = outerdata_train[:,1:nFeat+1]\n",
    "print('shape of data_train: ', data_train.shape)\n",
    "data_test = outerdata_test[:,1:nFeat+1]\n",
    "print('shape of data_test: ', data_test.shape)\n",
    "\n",
    "data = np.concatenate((data_train, data_test), axis=0)\n",
    "print('shape of data: ', data.shape)\n",
    "\n",
    "cond_data_train = outerdata_train[:,0]\n",
    "print('shape of cond_train', cond_data_train.shape)\n",
    "cond_data_test = outerdata_test[:,0]\n",
    "print('shape of cond_test', cond_data_test.shape)\n",
    "\n",
    "cond_data = np.concatenate((cond_data_train, cond_data_test), axis=0)\n",
    "print('shape of cond_data: ', cond_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5842d",
   "metadata": {},
   "source": [
    "## Plot training features\n",
    "\n",
    "- Total 6 training features\n",
    "- 1 conditional feature\n",
    "- Training Features are scaled to such that they are in range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88601c4-1d40-4d8f-aad9-e76274615839",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = {\n",
    "                0: \"$m_{2}$\",\n",
    "                1: \"$\\Delta m = m_{1} - m_{2}$ \",\n",
    "                2: \"$\\\\tau_{21}^{J1}$\",\n",
    "                3: \"$\\\\tau_{21}^{J2}$\",\n",
    "                4: \"$\\\\tau_{32}^{J1}$\",\n",
    "                5: \"$\\\\tau_{32}^{J2}$\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b388ca-40de-47b8-81c4-02a9a5bb8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = {\n",
    "                0: \"Min. Jet Mass\",\n",
    "                1: \"Jet Mass Difference\",\n",
    "                2: \"$\\\\tau_{21}$ Lead Jet\",\n",
    "                3: \"$\\\\tau_{21}$ Sublead Jet\",\n",
    "                4: \"$\\\\tau_{32}$ Lead Jet\",\n",
    "                5: \"$\\\\tau_{32}$ Sublead Jet\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1735bd14-79fc-48ea-9630-fe267205f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variables(data, density = False):\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    if density == False:\n",
    "        plt.ylabel(\"Events\")\n",
    "    else:\n",
    "        plt.ylabel(\"Normalized events\")\n",
    "    \n",
    "    \n",
    "    for i in range(input_dim):\n",
    "        plt.subplot((input_dim+1)//2, 2, i+1)\n",
    "        plt.xlabel(feature_names[i])\n",
    "        plt.hist(data[:, i], bins=30, color = \"darkblue\",  histtype = \"step\", label = feature_labels[i], density = density)\n",
    "        plt.legend()\n",
    "        plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7765984a-04d6-43ce-9868-ef28d28c4740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_variables(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8f772",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "Dividing each feature by the `abs(maximum)` value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee1fa493-16ad-4223-8d9b-287e01d8dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_max = np.empty(nFeat)\n",
    "\n",
    "for i in range(0,data.shape[1]):\n",
    "    feature_max[i] = np.max(np.abs(data[:,i]))\n",
    "    if np.abs(feature_max[i]) > 0: \n",
    "        data[:,i] = data[:,i]/feature_max[i]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "cond_max = np.max(np.abs(cond_data))\n",
    "\n",
    "if np.abs(cond_max) > 0:\n",
    "    cond_data = cond_data/cond_max\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb21cf",
   "metadata": {},
   "source": [
    "## Setting up for training\n",
    "\n",
    "### Defining the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8335cb-14a1-451e-bc39-d869934ad28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (878648, 6)\n"
     ]
    }
   ],
   "source": [
    "trainsize = outerdata_train.shape[0]\n",
    "\n",
    "\n",
    "data = data[:,0:input_dim]\n",
    "data = np.reshape(data, (len(cond_data),input_dim))\n",
    "print(\"Data Shape: \", np.shape(data))\n",
    "x_train = data[:trainsize]\n",
    "x_test = data[trainsize:]\n",
    "y_train = cond_data[:trainsize]\n",
    "y_test = cond_data[trainsize:]\n",
    "\n",
    "# x_train = np.hstack([x_train,y_train.reshape(y_train.shape[0],1)])\n",
    "# x_test = np.hstack([x_test,y_test.reshape(y_test.shape[0],1)])\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "original_dim = image_size\n",
    "x_train = np.reshape(x_train, [-1, original_dim])\n",
    "x_test = np.reshape(x_test, [-1, original_dim])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = np.reshape(y_train, [-1, 1])\n",
    "y_test = np.reshape(y_test, [-1, 1])\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfc18d",
   "metadata": {},
   "source": [
    "### Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86819d1a-d303-4fd5-ad4c-b98f518972c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "intermediate_dim = 128\n",
    "encoder_dim = 128\n",
    "batch_size = 1024\n",
    "latent_dim = 6\n",
    "epochs_1, epochs_2 = 240, 120\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fefa64aa-26c4-49a0-9cb9-9cb40e417497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "folder_name = \"z6_smallModel_02-12-2022/\"\n",
    "comd = \"mkdir -p \"+\"./outputs/models/\"+folder_name\n",
    "os.system(comd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef1f2f9",
   "metadata": {},
   "source": [
    "### Function for Gaussian Sampling in the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2422b2dd-2fec-4c47-8525-77c798121bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e820f0",
   "metadata": {},
   "source": [
    "### Define the Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d5320a0-cc80-42c9-9c30-d52260d3ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(X,y):\n",
    "    inputs = Concatenate()([X, y])\n",
    "    x1 = Dense(32, activation='relu')(inputs)\n",
    "    x2 = Dense(64, activation='relu')(x1)\n",
    "    x3 = Dense(32, activation='relu')(x2)\n",
    "    \n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x3)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x3)\n",
    "    # use reparameterization trick to push the sampling out as input\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    \n",
    "    return Model([X, y], [z_mean, z_log_var, z], name='encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dde75a",
   "metadata": {},
   "source": [
    "### Define the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "367ea004-d93b-4156-9dc5-e7c5df86844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder(z,y):\n",
    "    latent_inputs = Concatenate()([z, y])\n",
    "    x1 = Dense(32, activation='relu')(latent_inputs)\n",
    "    x2 = Dense(64, activation='relu')(x1)\n",
    "    x3 = Dense(32, activation='relu')(x2)\n",
    "\n",
    "    outputs = Dense(input_dim, activation='linear')(x3)\n",
    "\n",
    "    return Model([z, y], outputs, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe1e99e-9687-40bc-b2da-f751fdb9b468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 7)            0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           256         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           2112        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 6)            198         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 6)            198         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 6)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,844\n",
      "Trainable params: 4,844\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate encoder model\n",
    "encoder = create_encoder(Input(shape=(input_dim,)), Input(shape=(1,)))\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c018f57a-f73b-433c-a8e9-27b80a03ade0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 7)            0           ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 32)           256         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           2112        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           2080        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 6)            198         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,646\n",
      "Trainable params: 4,646\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate decoder model\n",
    "decoder = create_decoder(Input(shape=(latent_dim,)), Input(shape=(1,)))\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252c341",
   "metadata": {},
   "source": [
    "### Define the full VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc0fcfb8-86b6-499f-ba05-8422da6caa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = Input(shape=(input_dim,))\n",
    "y_input = Input(shape=(1,))\n",
    "z_mean, z_log_var, z = encoder([X_input,y_input])\n",
    "outputs = decoder([z,y_input])\n",
    "\n",
    "cvae = Model([X_input, y_input], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72136fa0",
   "metadata": {},
   "source": [
    "### Define the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90f0dd72-c09d-4bd0-bd0e-6c91d404e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss_fn(x,  x_decoded_mean):\n",
    "#     mse_loss = mse(x, x_decoded_mean) # objectives.mean_squared_error(x, x_decoded_mean)\n",
    "    mse_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.mse(x, x_decoded_mean)\n",
    "            )\n",
    "        )\n",
    "    return mse_loss\n",
    "    \n",
    "def kl_loss_fn(x,  x_decoded_mean):\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    return kl_loss\n",
    "            \n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "#         mse_loss = mse(x, x_decoded_mean) # objectives.mean_squared_error(x, x_decoded_mean)\n",
    "    mse_loss = mse_loss_fn(x, x_decoded_mean)\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    beta=10**(-2)  #10**(-6)\n",
    "    loss = K.mean((1-beta)*mse_loss + beta*kl_loss)\n",
    "#         loss = K.mean(mse_loss + kl_loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb20287",
   "metadata": {},
   "source": [
    "### Custom Saver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc506102-b047-4e87-a4a2-6377488feeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSaver(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "           if (k == (iterations-1)):\n",
    "               decoder.save(\"outputs/models/{}/model_cbvae_6var_m{}.h5\".format(folder_name,epoch))\n",
    "               encoder.save(\"outputs/models/{}/encoder_cbvae_6var_m{}.h5\".format(folder_name,epoch))\n",
    "decoderSaver = CustomSaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7fd59",
   "metadata": {},
   "source": [
    "### Other network parameters and model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c22a9a26-c7c3-4b2f-9d03-b16ac7d3e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learnrate = 0.001\n",
    "iterations = 3\n",
    "lr_limit = 0.001/(2**iterations)\n",
    "history = History()\n",
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d208b34-cca6-4c78-a7e6-2371821ae9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " encoder (Functional)           [(None, 6),          4844        ['input_5[0][0]',                \n",
      "                                 (None, 6),                       'input_6[0][0]']                \n",
      "                                 (None, 6)]                                                       \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 6)            4646        ['encoder[0][2]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,490\n",
      "Trainable params: 9,490\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='outputs/models/%s/cbvae_LHCO2020_20d_e-6.hdf5'%(folder_name), verbose=1, save_best_only=True)\n",
    "opt = Adam(learning_rate=learnrate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "cvae.compile(optimizer=opt, loss=vae_loss)\n",
    "\n",
    "cvae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b04bd",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8482ec67-e112-4b3b-b646-c7232382b557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 499889 samples, validate on 378759 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 15:25:46.991906: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-02 15:25:46.992010: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cori03): /proc/driver/nvidia/version does not exist\n",
      "2022-12-02 15:25:47.001526: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-02 15:25:47.090704: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 13.4058 - mse_loss_fn: 13.2250 - kl_loss_fn: 31.2996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/projectdirs/atlas/elham/conda/lib/python3.8/site-packages/keras/engine/training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.44879, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 5s 9us/sample - loss: 13.2787 - mse_loss_fn: 13.0738 - kl_loss_fn: 31.4001 - val_loss: 1.4488 - val_mse_loss_fn: 1.0527 - val_kl_loss_fn: 40.6523\n",
      "Epoch 2/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.8380 - mse_loss_fn: 0.4812 - kl_loss_fn: 36.1581\n",
      "Epoch 2: val_loss improved from 1.44879 to 0.39772, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.8297 - mse_loss_fn: 0.4727 - kl_loss_fn: 36.0913 - val_loss: 0.3977 - val_mse_loss_fn: 0.0728 - val_kl_loss_fn: 32.5612\n",
      "Epoch 3/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.3690 - mse_loss_fn: 0.0640 - kl_loss_fn: 30.5704\n",
      "Epoch 3: val_loss improved from 0.39772 to 0.37517, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.3690 - mse_loss_fn: 0.0638 - kl_loss_fn: 30.5699 - val_loss: 0.3752 - val_mse_loss_fn: 0.0852 - val_kl_loss_fn: 29.0806\n",
      "Epoch 4/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.3385 - mse_loss_fn: 0.0564 - kl_loss_fn: 28.2643\n",
      "Epoch 4: val_loss improved from 0.37517 to 0.35093, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.3385 - mse_loss_fn: 0.0563 - kl_loss_fn: 28.2621 - val_loss: 0.3509 - val_mse_loss_fn: 0.0758 - val_kl_loss_fn: 27.5905\n",
      "Epoch 5/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.3247 - mse_loss_fn: 0.0535 - kl_loss_fn: 27.1780\n",
      "Epoch 5: val_loss improved from 0.35093 to 0.33498, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.3247 - mse_loss_fn: 0.0534 - kl_loss_fn: 27.1737 - val_loss: 0.3350 - val_mse_loss_fn: 0.0676 - val_kl_loss_fn: 26.8078\n",
      "Epoch 6/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.3157 - mse_loss_fn: 0.0508 - kl_loss_fn: 26.5484\n",
      "Epoch 6: val_loss improved from 0.33498 to 0.31207, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.3157 - mse_loss_fn: 0.0507 - kl_loss_fn: 26.5427 - val_loss: 0.3121 - val_mse_loss_fn: 0.0500 - val_kl_loss_fn: 26.2538\n",
      "Epoch 7/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.3102 - mse_loss_fn: 0.0498 - kl_loss_fn: 26.0942\n",
      "Epoch 7: val_loss did not improve from 0.31207\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.3103 - mse_loss_fn: 0.0498 - kl_loss_fn: 26.0926 - val_loss: 0.3870 - val_mse_loss_fn: 0.1284 - val_kl_loss_fn: 25.9904\n",
      "Epoch 8/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.3078 - mse_loss_fn: 0.0508 - kl_loss_fn: 25.7525\n",
      "Epoch 8: val_loss did not improve from 0.31207\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.3077 - mse_loss_fn: 0.0506 - kl_loss_fn: 25.7500 - val_loss: 0.3156 - val_mse_loss_fn: 0.0608 - val_kl_loss_fn: 25.5394\n",
      "Epoch 9/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.3015 - mse_loss_fn: 0.0472 - kl_loss_fn: 25.4767\n",
      "Epoch 9: val_loss improved from 0.31207 to 0.31097, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.3014 - mse_loss_fn: 0.0470 - kl_loss_fn: 25.4741 - val_loss: 0.3110 - val_mse_loss_fn: 0.0592 - val_kl_loss_fn: 25.2319\n",
      "Epoch 10/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2997 - mse_loss_fn: 0.0479 - kl_loss_fn: 25.2214\n",
      "Epoch 10: val_loss improved from 0.31097 to 0.29696, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2996 - mse_loss_fn: 0.0479 - kl_loss_fn: 25.2202 - val_loss: 0.2970 - val_mse_loss_fn: 0.0464 - val_kl_loss_fn: 25.1017\n",
      "Epoch 11/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2951 - mse_loss_fn: 0.0456 - kl_loss_fn: 24.9949\n",
      "Epoch 11: val_loss improved from 0.29696 to 0.29483, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2950 - mse_loss_fn: 0.0455 - kl_loss_fn: 24.9929 - val_loss: 0.2948 - val_mse_loss_fn: 0.0470 - val_kl_loss_fn: 24.8256\n",
      "Epoch 12/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2934 - mse_loss_fn: 0.0461 - kl_loss_fn: 24.7734\n",
      "Epoch 12: val_loss did not improve from 0.29483\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2933 - mse_loss_fn: 0.0460 - kl_loss_fn: 24.7725 - val_loss: 0.3035 - val_mse_loss_fn: 0.0578 - val_kl_loss_fn: 24.6238\n",
      "Epoch 13/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2905 - mse_loss_fn: 0.0454 - kl_loss_fn: 24.5589\n",
      "Epoch 13: val_loss improved from 0.29483 to 0.28738, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2904 - mse_loss_fn: 0.0452 - kl_loss_fn: 24.5577 - val_loss: 0.2874 - val_mse_loss_fn: 0.0435 - val_kl_loss_fn: 24.4323\n",
      "Epoch 14/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2879 - mse_loss_fn: 0.0447 - kl_loss_fn: 24.3621\n",
      "Epoch 14: val_loss did not improve from 0.28738\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2879 - mse_loss_fn: 0.0446 - kl_loss_fn: 24.3612 - val_loss: 0.2904 - val_mse_loss_fn: 0.0493 - val_kl_loss_fn: 24.1503\n",
      "Epoch 15/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2852 - mse_loss_fn: 0.0441 - kl_loss_fn: 24.1559\n",
      "Epoch 15: val_loss did not improve from 0.28738\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2852 - mse_loss_fn: 0.0441 - kl_loss_fn: 24.1553 - val_loss: 0.3006 - val_mse_loss_fn: 0.0611 - val_kl_loss_fn: 24.0163\n",
      "Epoch 16/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2828 - mse_loss_fn: 0.0437 - kl_loss_fn: 23.9478\n",
      "Epoch 16: val_loss improved from 0.28738 to 0.28418, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2826 - mse_loss_fn: 0.0435 - kl_loss_fn: 23.9465 - val_loss: 0.2842 - val_mse_loss_fn: 0.0465 - val_kl_loss_fn: 23.8139\n",
      "Epoch 17/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2800 - mse_loss_fn: 0.0430 - kl_loss_fn: 23.7424\n",
      "Epoch 17: val_loss did not improve from 0.28418\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2800 - mse_loss_fn: 0.0429 - kl_loss_fn: 23.7424 - val_loss: 0.2890 - val_mse_loss_fn: 0.0541 - val_kl_loss_fn: 23.5524\n",
      "Epoch 18/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2790 - mse_loss_fn: 0.0440 - kl_loss_fn: 23.5370\n",
      "Epoch 18: val_loss did not improve from 0.28418\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2789 - mse_loss_fn: 0.0439 - kl_loss_fn: 23.5350 - val_loss: 0.3647 - val_mse_loss_fn: 0.1332 - val_kl_loss_fn: 23.2916\n",
      "Epoch 19/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2784 - mse_loss_fn: 0.0455 - kl_loss_fn: 23.3374\n",
      "Epoch 19: val_loss did not improve from 0.28418\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2783 - mse_loss_fn: 0.0453 - kl_loss_fn: 23.3359 - val_loss: 0.3193 - val_mse_loss_fn: 0.0890 - val_kl_loss_fn: 23.1228\n",
      "Epoch 20/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2733 - mse_loss_fn: 0.0424 - kl_loss_fn: 23.1393\n",
      "Epoch 20: val_loss did not improve from 0.28418\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2733 - mse_loss_fn: 0.0423 - kl_loss_fn: 23.1394 - val_loss: 0.3076 - val_mse_loss_fn: 0.0779 - val_kl_loss_fn: 23.0519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2718 - mse_loss_fn: 0.0428 - kl_loss_fn: 22.9444\n",
      "Epoch 21: val_loss improved from 0.28418 to 0.27642, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2717 - mse_loss_fn: 0.0426 - kl_loss_fn: 22.9425 - val_loss: 0.2764 - val_mse_loss_fn: 0.0500 - val_kl_loss_fn: 22.6939\n",
      "Epoch 22/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2687 - mse_loss_fn: 0.0417 - kl_loss_fn: 22.7385\n",
      "Epoch 22: val_loss improved from 0.27642 to 0.26233, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2686 - mse_loss_fn: 0.0416 - kl_loss_fn: 22.7377 - val_loss: 0.2623 - val_mse_loss_fn: 0.0372 - val_kl_loss_fn: 22.5535\n",
      "Epoch 23/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2665 - mse_loss_fn: 0.0416 - kl_loss_fn: 22.5284\n",
      "Epoch 23: val_loss did not improve from 0.26233\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2665 - mse_loss_fn: 0.0416 - kl_loss_fn: 22.5277 - val_loss: 0.3033 - val_mse_loss_fn: 0.0805 - val_kl_loss_fn: 22.3601\n",
      "Epoch 24/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2653 - mse_loss_fn: 0.0425 - kl_loss_fn: 22.3211\n",
      "Epoch 24: val_loss did not improve from 0.26233\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2652 - mse_loss_fn: 0.0424 - kl_loss_fn: 22.3204 - val_loss: 0.2752 - val_mse_loss_fn: 0.0538 - val_kl_loss_fn: 22.1943\n",
      "Epoch 25/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2611 - mse_loss_fn: 0.0404 - kl_loss_fn: 22.1165\n",
      "Epoch 25: val_loss did not improve from 0.26233\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2611 - mse_loss_fn: 0.0403 - kl_loss_fn: 22.1148 - val_loss: 0.2772 - val_mse_loss_fn: 0.0586 - val_kl_loss_fn: 21.9196\n",
      "Epoch 26/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2590 - mse_loss_fn: 0.0403 - kl_loss_fn: 21.9054\n",
      "Epoch 26: val_loss did not improve from 0.26233\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2590 - mse_loss_fn: 0.0403 - kl_loss_fn: 21.9051 - val_loss: 0.2956 - val_mse_loss_fn: 0.0791 - val_kl_loss_fn: 21.7305\n",
      "Epoch 27/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2574 - mse_loss_fn: 0.0408 - kl_loss_fn: 21.7019\n",
      "Epoch 27: val_loss did not improve from 0.26233\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2575 - mse_loss_fn: 0.0408 - kl_loss_fn: 21.7003 - val_loss: 0.2974 - val_mse_loss_fn: 0.0829 - val_kl_loss_fn: 21.5321\n",
      "Epoch 28/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2549 - mse_loss_fn: 0.0402 - kl_loss_fn: 21.5151\n",
      "Epoch 28: val_loss did not improve from 0.26233\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2549 - mse_loss_fn: 0.0401 - kl_loss_fn: 21.5150 - val_loss: 0.2827 - val_mse_loss_fn: 0.0697 - val_kl_loss_fn: 21.3642\n",
      "Epoch 29/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2525 - mse_loss_fn: 0.0396 - kl_loss_fn: 21.3327\n",
      "Epoch 29: val_loss improved from 0.26233 to 0.24986, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2525 - mse_loss_fn: 0.0395 - kl_loss_fn: 21.3318 - val_loss: 0.2499 - val_mse_loss_fn: 0.0386 - val_kl_loss_fn: 21.1604\n",
      "Epoch 30/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2496 - mse_loss_fn: 0.0386 - kl_loss_fn: 21.1416\n",
      "Epoch 30: val_loss did not improve from 0.24986\n",
      "499889/499889 [==============================] - 4s 9us/sample - loss: 0.2496 - mse_loss_fn: 0.0385 - kl_loss_fn: 21.1411 - val_loss: 0.2582 - val_mse_loss_fn: 0.0498 - val_kl_loss_fn: 20.8865\n",
      "Epoch 31/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2478 - mse_loss_fn: 0.0386 - kl_loss_fn: 20.9564\n",
      "Epoch 31: val_loss did not improve from 0.24986\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2477 - mse_loss_fn: 0.0385 - kl_loss_fn: 20.9562 - val_loss: 0.2768 - val_mse_loss_fn: 0.0693 - val_kl_loss_fn: 20.8182\n",
      "Epoch 32/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2463 - mse_loss_fn: 0.0390 - kl_loss_fn: 20.7756\n",
      "Epoch 32: val_loss did not improve from 0.24986\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2463 - mse_loss_fn: 0.0389 - kl_loss_fn: 20.7754 - val_loss: 0.2769 - val_mse_loss_fn: 0.0713 - val_kl_loss_fn: 20.6275\n",
      "Epoch 33/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2442 - mse_loss_fn: 0.0385 - kl_loss_fn: 20.6098\n",
      "Epoch 33: val_loss did not improve from 0.24986\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2442 - mse_loss_fn: 0.0385 - kl_loss_fn: 20.6098 - val_loss: 0.2521 - val_mse_loss_fn: 0.0491 - val_kl_loss_fn: 20.3518\n",
      "Epoch 34/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2427 - mse_loss_fn: 0.0387 - kl_loss_fn: 20.4385\n",
      "Epoch 34: val_loss did not improve from 0.24986\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2426 - mse_loss_fn: 0.0386 - kl_loss_fn: 20.4381 - val_loss: 0.2539 - val_mse_loss_fn: 0.0516 - val_kl_loss_fn: 20.2857\n",
      "Epoch 35/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2403 - mse_loss_fn: 0.0378 - kl_loss_fn: 20.2844\n",
      "Epoch 35: val_loss did not improve from 0.24986\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2403 - mse_loss_fn: 0.0378 - kl_loss_fn: 20.2830 - val_loss: 0.2624 - val_mse_loss_fn: 0.0623 - val_kl_loss_fn: 20.0666\n",
      "Epoch 36/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2397 - mse_loss_fn: 0.0387 - kl_loss_fn: 20.1347\n",
      "Epoch 36: val_loss improved from 0.24986 to 0.24757, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2397 - mse_loss_fn: 0.0386 - kl_loss_fn: 20.1346 - val_loss: 0.2476 - val_mse_loss_fn: 0.0479 - val_kl_loss_fn: 20.0178\n",
      "Epoch 37/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2367 - mse_loss_fn: 0.0371 - kl_loss_fn: 19.9973\n",
      "Epoch 37: val_loss did not improve from 0.24757\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2367 - mse_loss_fn: 0.0370 - kl_loss_fn: 19.9968 - val_loss: 0.2888 - val_mse_loss_fn: 0.0906 - val_kl_loss_fn: 19.9093\n",
      "Epoch 38/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2366 - mse_loss_fn: 0.0384 - kl_loss_fn: 19.8567\n",
      "Epoch 38: val_loss improved from 0.24757 to 0.23939, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2365 - mse_loss_fn: 0.0383 - kl_loss_fn: 19.8555 - val_loss: 0.2394 - val_mse_loss_fn: 0.0436 - val_kl_loss_fn: 19.6259\n",
      "Epoch 39/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2338 - mse_loss_fn: 0.0368 - kl_loss_fn: 19.7321\n",
      "Epoch 39: val_loss did not improve from 0.23939\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2337 - mse_loss_fn: 0.0367 - kl_loss_fn: 19.7315 - val_loss: 0.2409 - val_mse_loss_fn: 0.0462 - val_kl_loss_fn: 19.5072\n",
      "Epoch 40/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2330 - mse_loss_fn: 0.0373 - kl_loss_fn: 19.6045\n",
      "Epoch 40: val_loss did not improve from 0.23939\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2330 - mse_loss_fn: 0.0373 - kl_loss_fn: 19.6045 - val_loss: 0.2669 - val_mse_loss_fn: 0.0727 - val_kl_loss_fn: 19.4926\n",
      "Epoch 41/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2326 - mse_loss_fn: 0.0381 - kl_loss_fn: 19.4948\n",
      "Epoch 41: val_loss improved from 0.23939 to 0.22972, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2326 - mse_loss_fn: 0.0380 - kl_loss_fn: 19.4944 - val_loss: 0.2297 - val_mse_loss_fn: 0.0375 - val_kl_loss_fn: 19.2549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2301 - mse_loss_fn: 0.0367 - kl_loss_fn: 19.3817\n",
      "Epoch 42: val_loss improved from 0.22972 to 0.22873, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2301 - mse_loss_fn: 0.0366 - kl_loss_fn: 19.3815 - val_loss: 0.2287 - val_mse_loss_fn: 0.0368 - val_kl_loss_fn: 19.2314\n",
      "Epoch 43/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2293 - mse_loss_fn: 0.0368 - kl_loss_fn: 19.2777\n",
      "Epoch 43: val_loss did not improve from 0.22873\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2292 - mse_loss_fn: 0.0368 - kl_loss_fn: 19.2777 - val_loss: 0.2582 - val_mse_loss_fn: 0.0673 - val_kl_loss_fn: 19.1532\n",
      "Epoch 44/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2292 - mse_loss_fn: 0.0378 - kl_loss_fn: 19.1787\n",
      "Epoch 44: val_loss did not improve from 0.22873\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2292 - mse_loss_fn: 0.0377 - kl_loss_fn: 19.1784 - val_loss: 0.2592 - val_mse_loss_fn: 0.0693 - val_kl_loss_fn: 19.0526\n",
      "Epoch 45/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2281 - mse_loss_fn: 0.0376 - kl_loss_fn: 19.0831\n",
      "Epoch 45: val_loss did not improve from 0.22873\n",
      "499889/499889 [==============================] - 6s 13us/sample - loss: 0.2280 - mse_loss_fn: 0.0375 - kl_loss_fn: 19.0823 - val_loss: 0.2403 - val_mse_loss_fn: 0.0519 - val_kl_loss_fn: 18.8977\n",
      "Epoch 46/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2262 - mse_loss_fn: 0.0366 - kl_loss_fn: 18.9989\n",
      "Epoch 46: val_loss did not improve from 0.22873\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2262 - mse_loss_fn: 0.0365 - kl_loss_fn: 18.9989 - val_loss: 0.2805 - val_mse_loss_fn: 0.0926 - val_kl_loss_fn: 18.8818\n",
      "Epoch 47/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2268 - mse_loss_fn: 0.0381 - kl_loss_fn: 18.9107\n",
      "Epoch 47: val_loss did not improve from 0.22873\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2268 - mse_loss_fn: 0.0380 - kl_loss_fn: 18.9095 - val_loss: 0.2359 - val_mse_loss_fn: 0.0489 - val_kl_loss_fn: 18.7432\n",
      "Epoch 48/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2236 - mse_loss_fn: 0.0356 - kl_loss_fn: 18.8373\n",
      "Epoch 48: val_loss did not improve from 0.22873\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2236 - mse_loss_fn: 0.0355 - kl_loss_fn: 18.8373 - val_loss: 0.2570 - val_mse_loss_fn: 0.0712 - val_kl_loss_fn: 18.6456\n",
      "Epoch 49/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2242 - mse_loss_fn: 0.0369 - kl_loss_fn: 18.7655\n",
      "Epoch 49: val_loss improved from 0.22873 to 0.22227, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2241 - mse_loss_fn: 0.0368 - kl_loss_fn: 18.7648 - val_loss: 0.2223 - val_mse_loss_fn: 0.0370 - val_kl_loss_fn: 18.5611\n",
      "Epoch 50/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2223 - mse_loss_fn: 0.0357 - kl_loss_fn: 18.6986\n",
      "Epoch 50: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2223 - mse_loss_fn: 0.0357 - kl_loss_fn: 18.6986 - val_loss: 0.2345 - val_mse_loss_fn: 0.0499 - val_kl_loss_fn: 18.5070\n",
      "Epoch 51/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2224 - mse_loss_fn: 0.0364 - kl_loss_fn: 18.6385\n",
      "Epoch 51: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2224 - mse_loss_fn: 0.0363 - kl_loss_fn: 18.6379 - val_loss: 0.2325 - val_mse_loss_fn: 0.0490 - val_kl_loss_fn: 18.4073\n",
      "Epoch 52/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2219 - mse_loss_fn: 0.0364 - kl_loss_fn: 18.5871\n",
      "Epoch 52: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2219 - mse_loss_fn: 0.0363 - kl_loss_fn: 18.5862 - val_loss: 0.2307 - val_mse_loss_fn: 0.0473 - val_kl_loss_fn: 18.3899\n",
      "Epoch 53/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2204 - mse_loss_fn: 0.0354 - kl_loss_fn: 18.5361\n",
      "Epoch 53: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2204 - mse_loss_fn: 0.0354 - kl_loss_fn: 18.5360 - val_loss: 0.2234 - val_mse_loss_fn: 0.0406 - val_kl_loss_fn: 18.3141\n",
      "Epoch 54/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2203 - mse_loss_fn: 0.0357 - kl_loss_fn: 18.4941\n",
      "Epoch 54: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2203 - mse_loss_fn: 0.0356 - kl_loss_fn: 18.4940 - val_loss: 0.2288 - val_mse_loss_fn: 0.0465 - val_kl_loss_fn: 18.2809\n",
      "Epoch 55/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2202 - mse_loss_fn: 0.0360 - kl_loss_fn: 18.4495\n",
      "Epoch 55: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2201 - mse_loss_fn: 0.0359 - kl_loss_fn: 18.4495 - val_loss: 0.2398 - val_mse_loss_fn: 0.0568 - val_kl_loss_fn: 18.3559\n",
      "Epoch 56/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2201 - mse_loss_fn: 0.0363 - kl_loss_fn: 18.4150\n",
      "Epoch 56: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2200 - mse_loss_fn: 0.0362 - kl_loss_fn: 18.4149 - val_loss: 0.2277 - val_mse_loss_fn: 0.0461 - val_kl_loss_fn: 18.2152\n",
      "Epoch 57/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2194 - mse_loss_fn: 0.0358 - kl_loss_fn: 18.3887\n",
      "Epoch 57: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2194 - mse_loss_fn: 0.0358 - kl_loss_fn: 18.3892 - val_loss: 0.2484 - val_mse_loss_fn: 0.0671 - val_kl_loss_fn: 18.1990\n",
      "Epoch 58/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2190 - mse_loss_fn: 0.0356 - kl_loss_fn: 18.3697\n",
      "Epoch 58: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2190 - mse_loss_fn: 0.0356 - kl_loss_fn: 18.3695 - val_loss: 0.2340 - val_mse_loss_fn: 0.0521 - val_kl_loss_fn: 18.2457\n",
      "Epoch 59/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2192 - mse_loss_fn: 0.0361 - kl_loss_fn: 18.3498\n",
      "Epoch 59: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2192 - mse_loss_fn: 0.0360 - kl_loss_fn: 18.3498 - val_loss: 0.2302 - val_mse_loss_fn: 0.0488 - val_kl_loss_fn: 18.1884\n",
      "Epoch 60/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2180 - mse_loss_fn: 0.0351 - kl_loss_fn: 18.3250\n",
      "Epoch 60: val_loss did not improve from 0.22227\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2180 - mse_loss_fn: 0.0351 - kl_loss_fn: 18.3251 - val_loss: 0.2258 - val_mse_loss_fn: 0.0442 - val_kl_loss_fn: 18.2037\n",
      "Epoch 61/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2181 - mse_loss_fn: 0.0354 - kl_loss_fn: 18.3041\n",
      "Epoch 61: val_loss improved from 0.22227 to 0.21589, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2181 - mse_loss_fn: 0.0354 - kl_loss_fn: 18.3044 - val_loss: 0.2159 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 18.1973\n",
      "Epoch 62/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2179 - mse_loss_fn: 0.0353 - kl_loss_fn: 18.2922\n",
      "Epoch 62: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2179 - mse_loss_fn: 0.0353 - kl_loss_fn: 18.2922 - val_loss: 0.2293 - val_mse_loss_fn: 0.0477 - val_kl_loss_fn: 18.2100\n",
      "Epoch 63/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2178 - mse_loss_fn: 0.0353 - kl_loss_fn: 18.2780\n",
      "Epoch 63: val_loss did not improve from 0.21589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2178 - mse_loss_fn: 0.0353 - kl_loss_fn: 18.2781 - val_loss: 0.2252 - val_mse_loss_fn: 0.0447 - val_kl_loss_fn: 18.0935\n",
      "Epoch 64/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2176 - mse_loss_fn: 0.0353 - kl_loss_fn: 18.2687\n",
      "Epoch 64: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2176 - mse_loss_fn: 0.0353 - kl_loss_fn: 18.2680 - val_loss: 0.2654 - val_mse_loss_fn: 0.0850 - val_kl_loss_fn: 18.1232\n",
      "Epoch 65/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2192 - mse_loss_fn: 0.0369 - kl_loss_fn: 18.2591\n",
      "Epoch 65: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2191 - mse_loss_fn: 0.0369 - kl_loss_fn: 18.2591 - val_loss: 0.2246 - val_mse_loss_fn: 0.0438 - val_kl_loss_fn: 18.1211\n",
      "Epoch 66/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2172 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.2522\n",
      "Epoch 66: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2171 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.2522 - val_loss: 0.2577 - val_mse_loss_fn: 0.0782 - val_kl_loss_fn: 18.0281\n",
      "Epoch 67/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2178 - mse_loss_fn: 0.0358 - kl_loss_fn: 18.2374\n",
      "Epoch 67: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 7s 14us/sample - loss: 0.2178 - mse_loss_fn: 0.0357 - kl_loss_fn: 18.2374 - val_loss: 0.2229 - val_mse_loss_fn: 0.0428 - val_kl_loss_fn: 18.0506\n",
      "Epoch 68/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2165 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.2308\n",
      "Epoch 68: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2165 - mse_loss_fn: 0.0345 - kl_loss_fn: 18.2305 - val_loss: 0.2483 - val_mse_loss_fn: 0.0692 - val_kl_loss_fn: 17.9802\n",
      "Epoch 69/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2183 - mse_loss_fn: 0.0364 - kl_loss_fn: 18.2309\n",
      "Epoch 69: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2183 - mse_loss_fn: 0.0363 - kl_loss_fn: 18.2310 - val_loss: 0.2200 - val_mse_loss_fn: 0.0397 - val_kl_loss_fn: 18.0692\n",
      "Epoch 70/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2167 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.2160\n",
      "Epoch 70: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2167 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.2157 - val_loss: 0.2317 - val_mse_loss_fn: 0.0522 - val_kl_loss_fn: 17.9970\n",
      "Epoch 71/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2168 - mse_loss_fn: 0.0351 - kl_loss_fn: 18.2118\n",
      "Epoch 71: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2168 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.2116 - val_loss: 0.2454 - val_mse_loss_fn: 0.0663 - val_kl_loss_fn: 17.9731\n",
      "Epoch 72/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2176 - mse_loss_fn: 0.0359 - kl_loss_fn: 18.2007\n",
      "Epoch 72: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2176 - mse_loss_fn: 0.0359 - kl_loss_fn: 18.2007 - val_loss: 0.2297 - val_mse_loss_fn: 0.0492 - val_kl_loss_fn: 18.0897\n",
      "Epoch 73/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2164 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.1964\n",
      "Epoch 73: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2163 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.1965 - val_loss: 0.2289 - val_mse_loss_fn: 0.0490 - val_kl_loss_fn: 18.0368\n",
      "Epoch 74/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2165 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.1848\n",
      "Epoch 74: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2165 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.1848 - val_loss: 0.2223 - val_mse_loss_fn: 0.0425 - val_kl_loss_fn: 18.0224\n",
      "Epoch 75/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2168 - mse_loss_fn: 0.0353 - kl_loss_fn: 18.1787\n",
      "Epoch 75: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2168 - mse_loss_fn: 0.0353 - kl_loss_fn: 18.1787 - val_loss: 0.2347 - val_mse_loss_fn: 0.0547 - val_kl_loss_fn: 18.0551\n",
      "Epoch 76/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2164 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.1770\n",
      "Epoch 76: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2164 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.1767 - val_loss: 0.2437 - val_mse_loss_fn: 0.0645 - val_kl_loss_fn: 17.9823\n",
      "Epoch 77/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2166 - mse_loss_fn: 0.0352 - kl_loss_fn: 18.1740\n",
      "Epoch 77: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2166 - mse_loss_fn: 0.0351 - kl_loss_fn: 18.1742 - val_loss: 0.2321 - val_mse_loss_fn: 0.0518 - val_kl_loss_fn: 18.0849\n",
      "Epoch 78/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2163 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.1649\n",
      "Epoch 78: val_loss did not improve from 0.21589\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2163 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.1646 - val_loss: 0.2282 - val_mse_loss_fn: 0.0481 - val_kl_loss_fn: 18.0524\n",
      "Epoch 79/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2164 - mse_loss_fn: 0.0351 - kl_loss_fn: 18.1618\n",
      "Epoch 79: val_loss improved from 0.21589 to 0.21434, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2164 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.1620 - val_loss: 0.2143 - val_mse_loss_fn: 0.0347 - val_kl_loss_fn: 17.9942\n",
      "Epoch 80/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2159 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.1510\n",
      "Epoch 80: val_loss did not improve from 0.21434\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2159 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.1507 - val_loss: 0.2283 - val_mse_loss_fn: 0.0491 - val_kl_loss_fn: 17.9675\n",
      "Epoch 81/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2160 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.1508\n",
      "Epoch 81: val_loss did not improve from 0.21434\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2160 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.1505 - val_loss: 0.2373 - val_mse_loss_fn: 0.0581 - val_kl_loss_fn: 17.9771\n",
      "Epoch 82/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2164 - mse_loss_fn: 0.0353 - kl_loss_fn: 18.1453\n",
      "Epoch 82: val_loss did not improve from 0.21434\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2164 - mse_loss_fn: 0.0352 - kl_loss_fn: 18.1453 - val_loss: 0.2455 - val_mse_loss_fn: 0.0666 - val_kl_loss_fn: 17.9503\n",
      "Epoch 83/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2160 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.1428\n",
      "Epoch 83: val_loss did not improve from 0.21434\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2160 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.1428 - val_loss: 0.2209 - val_mse_loss_fn: 0.0420 - val_kl_loss_fn: 17.9318\n",
      "Epoch 84/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2155 - mse_loss_fn: 0.0345 - kl_loss_fn: 18.1366\n",
      "Epoch 84: val_loss did not improve from 0.21434\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2155 - mse_loss_fn: 0.0344 - kl_loss_fn: 18.1366 - val_loss: 0.2184 - val_mse_loss_fn: 0.0390 - val_kl_loss_fn: 17.9747\n",
      "Epoch 85/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2157 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.1308\n",
      "Epoch 85: val_loss did not improve from 0.21434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2157 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.1309 - val_loss: 0.2217 - val_mse_loss_fn: 0.0425 - val_kl_loss_fn: 17.9597\n",
      "Epoch 86/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2152 - mse_loss_fn: 0.0343 - kl_loss_fn: 18.1254\n",
      "Epoch 86: val_loss did not improve from 0.21434\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2152 - mse_loss_fn: 0.0343 - kl_loss_fn: 18.1256 - val_loss: 0.2214 - val_mse_loss_fn: 0.0423 - val_kl_loss_fn: 17.9555\n",
      "Epoch 87/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2159 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.1234\n",
      "Epoch 87: val_loss did not improve from 0.21434\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2158 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.1236 - val_loss: 0.2222 - val_mse_loss_fn: 0.0430 - val_kl_loss_fn: 17.9621\n",
      "Epoch 88/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2155 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.1196\n",
      "Epoch 88: val_loss did not improve from 0.21434\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2155 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.1198 - val_loss: 0.2226 - val_mse_loss_fn: 0.0431 - val_kl_loss_fn: 17.9871\n",
      "Epoch 89/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2156 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.1109\n",
      "Epoch 89: val_loss improved from 0.21434 to 0.21318, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2156 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.1109 - val_loss: 0.2132 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.9655\n",
      "Epoch 90/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2149 - mse_loss_fn: 0.0342 - kl_loss_fn: 18.1079\n",
      "Epoch 90: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2149 - mse_loss_fn: 0.0341 - kl_loss_fn: 18.1083 - val_loss: 0.2221 - val_mse_loss_fn: 0.0431 - val_kl_loss_fn: 17.9413\n",
      "Epoch 91/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2157 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.1059\n",
      "Epoch 91: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2156 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.1066 - val_loss: 0.2182 - val_mse_loss_fn: 0.0388 - val_kl_loss_fn: 17.9809\n",
      "Epoch 92/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2154 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.1000\n",
      "Epoch 92: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2154 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.1013 - val_loss: 0.2363 - val_mse_loss_fn: 0.0576 - val_kl_loss_fn: 17.9292\n",
      "Epoch 93/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2154 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.1029\n",
      "Epoch 93: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2154 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.1029 - val_loss: 0.2239 - val_mse_loss_fn: 0.0452 - val_kl_loss_fn: 17.9182\n",
      "Epoch 94/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2152 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.0899\n",
      "Epoch 94: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 5s 9us/sample - loss: 0.2152 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.0900 - val_loss: 0.2212 - val_mse_loss_fn: 0.0419 - val_kl_loss_fn: 17.9649\n",
      "Epoch 95/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2151 - mse_loss_fn: 0.0345 - kl_loss_fn: 18.0892\n",
      "Epoch 95: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 6s 13us/sample - loss: 0.2151 - mse_loss_fn: 0.0345 - kl_loss_fn: 18.0893 - val_loss: 0.2215 - val_mse_loss_fn: 0.0427 - val_kl_loss_fn: 17.9252\n",
      "Epoch 96/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2147 - mse_loss_fn: 0.0342 - kl_loss_fn: 18.0847\n",
      "Epoch 96: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2147 - mse_loss_fn: 0.0342 - kl_loss_fn: 18.0847 - val_loss: 0.2175 - val_mse_loss_fn: 0.0382 - val_kl_loss_fn: 17.9726\n",
      "Epoch 97/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2152 - mse_loss_fn: 0.0347 - kl_loss_fn: 18.0838\n",
      "Epoch 97: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2152 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.0843 - val_loss: 0.2206 - val_mse_loss_fn: 0.0418 - val_kl_loss_fn: 17.9219\n",
      "Epoch 98/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2150 - mse_loss_fn: 0.0345 - kl_loss_fn: 18.0816\n",
      "Epoch 98: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2150 - mse_loss_fn: 0.0345 - kl_loss_fn: 18.0816 - val_loss: 0.2235 - val_mse_loss_fn: 0.0449 - val_kl_loss_fn: 17.9027\n",
      "Epoch 99/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2150 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.0726\n",
      "Epoch 99: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2149 - mse_loss_fn: 0.0345 - kl_loss_fn: 18.0720 - val_loss: 0.2326 - val_mse_loss_fn: 0.0547 - val_kl_loss_fn: 17.8518\n",
      "Epoch 100/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2152 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.0657\n",
      "Epoch 100: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2151 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.0660 - val_loss: 0.2261 - val_mse_loss_fn: 0.0472 - val_kl_loss_fn: 17.9364\n",
      "Epoch 101/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2146 - mse_loss_fn: 0.0343 - kl_loss_fn: 18.0640\n",
      "Epoch 101: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2146 - mse_loss_fn: 0.0343 - kl_loss_fn: 18.0638 - val_loss: 0.2396 - val_mse_loss_fn: 0.0609 - val_kl_loss_fn: 17.9357\n",
      "Epoch 102/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2150 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.0672\n",
      "Epoch 102: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2150 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.0663 - val_loss: 0.2298 - val_mse_loss_fn: 0.0507 - val_kl_loss_fn: 17.9674\n",
      "Epoch 103/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2151 - mse_loss_fn: 0.0349 - kl_loss_fn: 18.0544\n",
      "Epoch 103: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2150 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.0547 - val_loss: 0.2247 - val_mse_loss_fn: 0.0459 - val_kl_loss_fn: 17.9230\n",
      "Epoch 104/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2140 - mse_loss_fn: 0.0338 - kl_loss_fn: 18.0499\n",
      "Epoch 104: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2140 - mse_loss_fn: 0.0338 - kl_loss_fn: 18.0499 - val_loss: 0.2146 - val_mse_loss_fn: 0.0360 - val_kl_loss_fn: 17.8878\n",
      "Epoch 105/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2145 - mse_loss_fn: 0.0344 - kl_loss_fn: 18.0429\n",
      "Epoch 105: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2145 - mse_loss_fn: 0.0343 - kl_loss_fn: 18.0430 - val_loss: 0.2267 - val_mse_loss_fn: 0.0481 - val_kl_loss_fn: 17.9136\n",
      "Epoch 106/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2147 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.0447\n",
      "Epoch 106: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2147 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.0441 - val_loss: 0.2313 - val_mse_loss_fn: 0.0530 - val_kl_loss_fn: 17.8792\n",
      "Epoch 107/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2147 - mse_loss_fn: 0.0346 - kl_loss_fn: 18.0423\n",
      "Epoch 107: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2146 - mse_loss_fn: 0.0345 - kl_loss_fn: 18.0426 - val_loss: 0.2502 - val_mse_loss_fn: 0.0714 - val_kl_loss_fn: 17.9503\n",
      "Epoch 108/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2151 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.0369\n",
      "Epoch 108: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2151 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.0369 - val_loss: 0.2204 - val_mse_loss_fn: 0.0419 - val_kl_loss_fn: 17.8911\n",
      "Epoch 109/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2142 - mse_loss_fn: 0.0341 - kl_loss_fn: 18.0360\n",
      "Epoch 109: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2141 - mse_loss_fn: 0.0341 - kl_loss_fn: 18.0360 - val_loss: 0.2151 - val_mse_loss_fn: 0.0366 - val_kl_loss_fn: 17.8872\n",
      "Epoch 110/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2143 - mse_loss_fn: 0.0343 - kl_loss_fn: 18.0332\n",
      "Epoch 110: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2143 - mse_loss_fn: 0.0343 - kl_loss_fn: 18.0337 - val_loss: 0.2474 - val_mse_loss_fn: 0.0686 - val_kl_loss_fn: 17.9460\n",
      "Epoch 111/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2150 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.0273\n",
      "Epoch 111: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2149 - mse_loss_fn: 0.0350 - kl_loss_fn: 18.0277 - val_loss: 0.2185 - val_mse_loss_fn: 0.0400 - val_kl_loss_fn: 17.8877\n",
      "Epoch 112/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2140 - mse_loss_fn: 0.0341 - kl_loss_fn: 18.0231\n",
      "Epoch 112: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2140 - mse_loss_fn: 0.0341 - kl_loss_fn: 18.0231 - val_loss: 0.2235 - val_mse_loss_fn: 0.0453 - val_kl_loss_fn: 17.8657\n",
      "Epoch 113/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2147 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.0231\n",
      "Epoch 113: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2147 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.0232 - val_loss: 0.2164 - val_mse_loss_fn: 0.0379 - val_kl_loss_fn: 17.8873\n",
      "Epoch 114/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2140 - mse_loss_fn: 0.0341 - kl_loss_fn: 18.0264\n",
      "Epoch 114: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2140 - mse_loss_fn: 0.0340 - kl_loss_fn: 18.0267 - val_loss: 0.2449 - val_mse_loss_fn: 0.0663 - val_kl_loss_fn: 17.9286\n",
      "Epoch 115/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2147 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.0227\n",
      "Epoch 115: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2147 - mse_loss_fn: 0.0348 - kl_loss_fn: 18.0227 - val_loss: 0.2230 - val_mse_loss_fn: 0.0443 - val_kl_loss_fn: 17.9136\n",
      "Epoch 116/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2138 - mse_loss_fn: 0.0340 - kl_loss_fn: 18.0173\n",
      "Epoch 116: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2138 - mse_loss_fn: 0.0340 - kl_loss_fn: 18.0171 - val_loss: 0.2203 - val_mse_loss_fn: 0.0413 - val_kl_loss_fn: 17.9469\n",
      "Epoch 117/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2141 - mse_loss_fn: 0.0342 - kl_loss_fn: 18.0175\n",
      "Epoch 117: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2141 - mse_loss_fn: 0.0342 - kl_loss_fn: 18.0171 - val_loss: 0.2153 - val_mse_loss_fn: 0.0370 - val_kl_loss_fn: 17.8680\n",
      "Epoch 118/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2140 - mse_loss_fn: 0.0342 - kl_loss_fn: 18.0135\n",
      "Epoch 118: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2140 - mse_loss_fn: 0.0342 - kl_loss_fn: 18.0134 - val_loss: 0.2182 - val_mse_loss_fn: 0.0403 - val_kl_loss_fn: 17.8303\n",
      "Epoch 119/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2141 - mse_loss_fn: 0.0343 - kl_loss_fn: 18.0119\n",
      "Epoch 119: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2140 - mse_loss_fn: 0.0342 - kl_loss_fn: 18.0118 - val_loss: 0.2156 - val_mse_loss_fn: 0.0371 - val_kl_loss_fn: 17.8828\n",
      "Epoch 120/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2141 - mse_loss_fn: 0.0344 - kl_loss_fn: 18.0090\n",
      "Epoch 120: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2141 - mse_loss_fn: 0.0343 - kl_loss_fn: 18.0091 - val_loss: 0.2182 - val_mse_loss_fn: 0.0399 - val_kl_loss_fn: 17.8655\n",
      "Epoch 121/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2138 - mse_loss_fn: 0.0341 - kl_loss_fn: 18.0052\n",
      "Epoch 121: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2138 - mse_loss_fn: 0.0340 - kl_loss_fn: 18.0060 - val_loss: 0.2200 - val_mse_loss_fn: 0.0412 - val_kl_loss_fn: 17.9272\n",
      "Epoch 122/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2142 - mse_loss_fn: 0.0344 - kl_loss_fn: 18.0117\n",
      "Epoch 122: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2142 - mse_loss_fn: 0.0344 - kl_loss_fn: 18.0119 - val_loss: 0.2219 - val_mse_loss_fn: 0.0443 - val_kl_loss_fn: 17.8094\n",
      "Epoch 123/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2139 - mse_loss_fn: 0.0342 - kl_loss_fn: 18.0077\n",
      "Epoch 123: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2139 - mse_loss_fn: 0.0341 - kl_loss_fn: 18.0082 - val_loss: 0.2196 - val_mse_loss_fn: 0.0417 - val_kl_loss_fn: 17.8332\n",
      "Epoch 124/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2141 - mse_loss_fn: 0.0345 - kl_loss_fn: 17.9994\n",
      "Epoch 124: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2141 - mse_loss_fn: 0.0344 - kl_loss_fn: 17.9996 - val_loss: 0.2175 - val_mse_loss_fn: 0.0398 - val_kl_loss_fn: 17.8163\n",
      "Epoch 125/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2136 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9979\n",
      "Epoch 125: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2136 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9978 - val_loss: 0.2222 - val_mse_loss_fn: 0.0442 - val_kl_loss_fn: 17.8496\n",
      "Epoch 126/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2138 - mse_loss_fn: 0.0342 - kl_loss_fn: 17.9990\n",
      "Epoch 126: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2138 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9989 - val_loss: 0.2457 - val_mse_loss_fn: 0.0681 - val_kl_loss_fn: 17.8310\n",
      "Epoch 127/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2143 - mse_loss_fn: 0.0347 - kl_loss_fn: 17.9983\n",
      "Epoch 127: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2143 - mse_loss_fn: 0.0346 - kl_loss_fn: 17.9982 - val_loss: 0.2201 - val_mse_loss_fn: 0.0425 - val_kl_loss_fn: 17.8066\n",
      "Epoch 128/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2134 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9918\n",
      "Epoch 128: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2134 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9918 - val_loss: 0.2194 - val_mse_loss_fn: 0.0418 - val_kl_loss_fn: 17.7991\n",
      "Epoch 129/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2139 - mse_loss_fn: 0.0343 - kl_loss_fn: 17.9916\n",
      "Epoch 129: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2139 - mse_loss_fn: 0.0343 - kl_loss_fn: 17.9916 - val_loss: 0.2278 - val_mse_loss_fn: 0.0491 - val_kl_loss_fn: 17.9194\n",
      "Epoch 130/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2142 - mse_loss_fn: 0.0346 - kl_loss_fn: 17.9914\n",
      "Epoch 130: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2142 - mse_loss_fn: 0.0345 - kl_loss_fn: 17.9914 - val_loss: 0.2331 - val_mse_loss_fn: 0.0555 - val_kl_loss_fn: 17.8154\n",
      "Epoch 131/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2137 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9876\n",
      "Epoch 131: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2137 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9876 - val_loss: 0.2216 - val_mse_loss_fn: 0.0434 - val_kl_loss_fn: 17.8589\n",
      "Epoch 132/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2137 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9905\n",
      "Epoch 132: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2137 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9907 - val_loss: 0.2134 - val_mse_loss_fn: 0.0353 - val_kl_loss_fn: 17.8413\n",
      "Epoch 133/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2136 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9890\n",
      "Epoch 133: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2136 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9889 - val_loss: 0.2263 - val_mse_loss_fn: 0.0489 - val_kl_loss_fn: 17.7978\n",
      "Epoch 134/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2139 - mse_loss_fn: 0.0344 - kl_loss_fn: 17.9858\n",
      "Epoch 134: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2139 - mse_loss_fn: 0.0343 - kl_loss_fn: 17.9851 - val_loss: 0.2135 - val_mse_loss_fn: 0.0353 - val_kl_loss_fn: 17.8513\n",
      "Epoch 135/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2136 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9866\n",
      "Epoch 135: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2136 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9875 - val_loss: 0.2141 - val_mse_loss_fn: 0.0353 - val_kl_loss_fn: 17.9100\n",
      "Epoch 136/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2136 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9875\n",
      "Epoch 136: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2136 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9885 - val_loss: 0.2133 - val_mse_loss_fn: 0.0355 - val_kl_loss_fn: 17.8230\n",
      "Epoch 137/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2133 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9851\n",
      "Epoch 137: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 10s 20us/sample - loss: 0.2133 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9850 - val_loss: 0.2262 - val_mse_loss_fn: 0.0485 - val_kl_loss_fn: 17.8192\n",
      "Epoch 138/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2137 - mse_loss_fn: 0.0342 - kl_loss_fn: 17.9856\n",
      "Epoch 138: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2137 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9858 - val_loss: 0.2143 - val_mse_loss_fn: 0.0365 - val_kl_loss_fn: 17.8146\n",
      "Epoch 139/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2137 - mse_loss_fn: 0.0343 - kl_loss_fn: 17.9794\n",
      "Epoch 139: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2137 - mse_loss_fn: 0.0342 - kl_loss_fn: 17.9796 - val_loss: 0.2296 - val_mse_loss_fn: 0.0522 - val_kl_loss_fn: 17.7904\n",
      "Epoch 140/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2136 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9799\n",
      "Epoch 140: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2136 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9801 - val_loss: 0.2314 - val_mse_loss_fn: 0.0534 - val_kl_loss_fn: 17.8546\n",
      "Epoch 141/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2135 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9787\n",
      "Epoch 141: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2134 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9791 - val_loss: 0.2207 - val_mse_loss_fn: 0.0430 - val_kl_loss_fn: 17.8081\n",
      "Epoch 142/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2136 - mse_loss_fn: 0.0342 - kl_loss_fn: 17.9695\n",
      "Epoch 142: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2136 - mse_loss_fn: 0.0342 - kl_loss_fn: 17.9697 - val_loss: 0.2308 - val_mse_loss_fn: 0.0537 - val_kl_loss_fn: 17.7675\n",
      "Epoch 143/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2136 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9786\n",
      "Epoch 143: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 9us/sample - loss: 0.2135 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9785 - val_loss: 0.2184 - val_mse_loss_fn: 0.0409 - val_kl_loss_fn: 17.7975\n",
      "Epoch 144/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2132 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9749\n",
      "Epoch 144: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2132 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9745 - val_loss: 0.2246 - val_mse_loss_fn: 0.0473 - val_kl_loss_fn: 17.7726\n",
      "Epoch 145/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2136 - mse_loss_fn: 0.0342 - kl_loss_fn: 17.9703\n",
      "Epoch 145: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2136 - mse_loss_fn: 0.0342 - kl_loss_fn: 17.9701 - val_loss: 0.2212 - val_mse_loss_fn: 0.0433 - val_kl_loss_fn: 17.8333\n",
      "Epoch 146/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2133 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9713\n",
      "Epoch 146: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2133 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9711 - val_loss: 0.2214 - val_mse_loss_fn: 0.0437 - val_kl_loss_fn: 17.8132\n",
      "Epoch 147/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2135 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9779\n",
      "Epoch 147: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2136 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9781 - val_loss: 0.2379 - val_mse_loss_fn: 0.0606 - val_kl_loss_fn: 17.7921\n",
      "Epoch 148/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2135 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9700\n",
      "Epoch 148: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2134 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9699 - val_loss: 0.2160 - val_mse_loss_fn: 0.0378 - val_kl_loss_fn: 17.8501\n",
      "Epoch 149/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2132 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9690\n",
      "Epoch 149: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2132 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9688 - val_loss: 0.2202 - val_mse_loss_fn: 0.0426 - val_kl_loss_fn: 17.8046\n",
      "Epoch 150/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2133 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9706\n",
      "Epoch 150: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2133 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9707 - val_loss: 0.2202 - val_mse_loss_fn: 0.0427 - val_kl_loss_fn: 17.7948\n",
      "Epoch 151/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2132 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9683\n",
      "Epoch 151: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2132 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9683 - val_loss: 0.2174 - val_mse_loss_fn: 0.0398 - val_kl_loss_fn: 17.7953\n",
      "Epoch 152/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2133 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9624\n",
      "Epoch 152: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2133 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9631 - val_loss: 0.2232 - val_mse_loss_fn: 0.0462 - val_kl_loss_fn: 17.7504\n",
      "Epoch 153/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2134 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9654\n",
      "Epoch 153: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2134 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9652 - val_loss: 0.2186 - val_mse_loss_fn: 0.0412 - val_kl_loss_fn: 17.7805\n",
      "Epoch 154/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2131 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9675\n",
      "Epoch 154: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2131 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9679 - val_loss: 0.2177 - val_mse_loss_fn: 0.0393 - val_kl_loss_fn: 17.8796\n",
      "Epoch 155/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2133 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9621\n",
      "Epoch 155: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2134 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9627 - val_loss: 0.2431 - val_mse_loss_fn: 0.0661 - val_kl_loss_fn: 17.7659\n",
      "Epoch 156/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2136 - mse_loss_fn: 0.0344 - kl_loss_fn: 17.9610\n",
      "Epoch 156: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2136 - mse_loss_fn: 0.0343 - kl_loss_fn: 17.9614 - val_loss: 0.2197 - val_mse_loss_fn: 0.0426 - val_kl_loss_fn: 17.7560\n",
      "Epoch 157/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2130 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9624\n",
      "Epoch 157: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2129 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9615 - val_loss: 0.2175 - val_mse_loss_fn: 0.0396 - val_kl_loss_fn: 17.8246\n",
      "Epoch 158/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2131 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9584\n",
      "Epoch 158: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2131 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9581 - val_loss: 0.2206 - val_mse_loss_fn: 0.0430 - val_kl_loss_fn: 17.7962\n",
      "Epoch 159/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2132 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9582\n",
      "Epoch 159: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2132 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9584 - val_loss: 0.2223 - val_mse_loss_fn: 0.0448 - val_kl_loss_fn: 17.7939\n",
      "Epoch 160/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2131 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9596\n",
      "Epoch 160: val_loss did not improve from 0.21318\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2131 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9608 - val_loss: 0.2198 - val_mse_loss_fn: 0.0415 - val_kl_loss_fn: 17.8723\n",
      "Epoch 161/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2132 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9612\n",
      "Epoch 161: val_loss improved from 0.21318 to 0.21314, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2132 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9616 - val_loss: 0.2131 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.8593\n",
      "Epoch 162/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2130 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9621\n",
      "Epoch 162: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2130 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9618 - val_loss: 0.2252 - val_mse_loss_fn: 0.0473 - val_kl_loss_fn: 17.8351\n",
      "Epoch 163/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2133 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9538\n",
      "Epoch 163: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2133 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9533 - val_loss: 0.2348 - val_mse_loss_fn: 0.0576 - val_kl_loss_fn: 17.7721\n",
      "Epoch 164/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2131 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9584\n",
      "Epoch 164: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2131 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9587 - val_loss: 0.2236 - val_mse_loss_fn: 0.0451 - val_kl_loss_fn: 17.8930\n",
      "Epoch 165/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2132 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9548\n",
      "Epoch 165: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2132 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9548 - val_loss: 0.2187 - val_mse_loss_fn: 0.0414 - val_kl_loss_fn: 17.7703\n",
      "Epoch 166/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9579\n",
      "Epoch 166: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2128 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9575 - val_loss: 0.2172 - val_mse_loss_fn: 0.0399 - val_kl_loss_fn: 17.7695\n",
      "Epoch 167/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2132 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9514\n",
      "Epoch 167: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2132 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9514 - val_loss: 0.2378 - val_mse_loss_fn: 0.0609 - val_kl_loss_fn: 17.7579\n",
      "Epoch 168/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2133 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9557\n",
      "Epoch 168: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2133 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9563 - val_loss: 0.2212 - val_mse_loss_fn: 0.0431 - val_kl_loss_fn: 17.8529\n",
      "Epoch 169/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2131 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9521\n",
      "Epoch 169: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2130 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9533 - val_loss: 0.2192 - val_mse_loss_fn: 0.0418 - val_kl_loss_fn: 17.7883\n",
      "Epoch 170/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9546\n",
      "Epoch 170: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2125 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9542 - val_loss: 0.2292 - val_mse_loss_fn: 0.0520 - val_kl_loss_fn: 17.7758\n",
      "Epoch 171/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2131 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9529\n",
      "Epoch 171: val_loss did not improve from 0.21314\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2131 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9533 - val_loss: 0.2203 - val_mse_loss_fn: 0.0425 - val_kl_loss_fn: 17.8273\n",
      "Epoch 172/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2130 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9474\n",
      "Epoch 172: val_loss improved from 0.21314 to 0.21307, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2130 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9477 - val_loss: 0.2131 - val_mse_loss_fn: 0.0365 - val_kl_loss_fn: 17.6964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9498\n",
      "Epoch 173: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2128 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9498 - val_loss: 0.2217 - val_mse_loss_fn: 0.0446 - val_kl_loss_fn: 17.7469\n",
      "Epoch 174/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2130 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9483\n",
      "Epoch 174: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2130 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9483 - val_loss: 0.2250 - val_mse_loss_fn: 0.0480 - val_kl_loss_fn: 17.7474\n",
      "Epoch 175/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2129 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9493\n",
      "Epoch 175: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2129 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9494 - val_loss: 0.2173 - val_mse_loss_fn: 0.0394 - val_kl_loss_fn: 17.8300\n",
      "Epoch 176/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9461\n",
      "Epoch 176: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2128 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9463 - val_loss: 0.2306 - val_mse_loss_fn: 0.0535 - val_kl_loss_fn: 17.7599\n",
      "Epoch 177/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2132 - mse_loss_fn: 0.0341 - kl_loss_fn: 17.9465\n",
      "Epoch 177: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2132 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9463 - val_loss: 0.2175 - val_mse_loss_fn: 0.0406 - val_kl_loss_fn: 17.7337\n",
      "Epoch 178/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9508\n",
      "Epoch 178: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2128 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9507 - val_loss: 0.2204 - val_mse_loss_fn: 0.0436 - val_kl_loss_fn: 17.7254\n",
      "Epoch 179/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2130 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9470\n",
      "Epoch 179: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2130 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9468 - val_loss: 0.2320 - val_mse_loss_fn: 0.0550 - val_kl_loss_fn: 17.7560\n",
      "Epoch 180/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9426\n",
      "Epoch 180: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 6s 12us/sample - loss: 0.2128 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9427 - val_loss: 0.2169 - val_mse_loss_fn: 0.0400 - val_kl_loss_fn: 17.7301\n",
      "Epoch 181/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2129 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9495\n",
      "Epoch 181: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 7s 14us/sample - loss: 0.2129 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9495 - val_loss: 0.2181 - val_mse_loss_fn: 0.0402 - val_kl_loss_fn: 17.8340\n",
      "Epoch 182/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2127 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9494\n",
      "Epoch 182: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2127 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9496 - val_loss: 0.2255 - val_mse_loss_fn: 0.0477 - val_kl_loss_fn: 17.8283\n",
      "Epoch 183/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9423\n",
      "Epoch 183: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9425 - val_loss: 0.2155 - val_mse_loss_fn: 0.0381 - val_kl_loss_fn: 17.7741\n",
      "Epoch 184/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9457\n",
      "Epoch 184: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2126 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9452 - val_loss: 0.2215 - val_mse_loss_fn: 0.0443 - val_kl_loss_fn: 17.7657\n",
      "Epoch 185/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2129 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9406\n",
      "Epoch 185: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2129 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9401 - val_loss: 0.2245 - val_mse_loss_fn: 0.0462 - val_kl_loss_fn: 17.8786\n",
      "Epoch 186/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2129 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9476\n",
      "Epoch 186: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2129 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9476 - val_loss: 0.2219 - val_mse_loss_fn: 0.0444 - val_kl_loss_fn: 17.7951\n",
      "Epoch 187/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9411\n",
      "Epoch 187: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9417 - val_loss: 0.2323 - val_mse_loss_fn: 0.0544 - val_kl_loss_fn: 17.8508\n",
      "Epoch 188/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2130 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9433\n",
      "Epoch 188: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2129 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9428 - val_loss: 0.2238 - val_mse_loss_fn: 0.0464 - val_kl_loss_fn: 17.7813\n",
      "Epoch 189/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2129 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9430\n",
      "Epoch 189: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2129 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9436 - val_loss: 0.2204 - val_mse_loss_fn: 0.0428 - val_kl_loss_fn: 17.8042\n",
      "Epoch 190/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9438\n",
      "Epoch 190: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2128 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9434 - val_loss: 0.2131 - val_mse_loss_fn: 0.0355 - val_kl_loss_fn: 17.7906\n",
      "Epoch 191/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2131 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9445\n",
      "Epoch 191: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2130 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9447 - val_loss: 0.2155 - val_mse_loss_fn: 0.0380 - val_kl_loss_fn: 17.7897\n",
      "Epoch 192/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9396\n",
      "Epoch 192: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9399 - val_loss: 0.2345 - val_mse_loss_fn: 0.0571 - val_kl_loss_fn: 17.7964\n",
      "Epoch 193/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9388\n",
      "Epoch 193: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9388 - val_loss: 0.2260 - val_mse_loss_fn: 0.0492 - val_kl_loss_fn: 17.7218\n",
      "Epoch 194/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9342\n",
      "Epoch 194: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2126 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9341 - val_loss: 0.2192 - val_mse_loss_fn: 0.0414 - val_kl_loss_fn: 17.8250\n",
      "Epoch 195/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9369\n",
      "Epoch 195: val_loss did not improve from 0.21307\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9368 - val_loss: 0.2146 - val_mse_loss_fn: 0.0374 - val_kl_loss_fn: 17.7510\n",
      "Epoch 196/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9393\n",
      "Epoch 196: val_loss improved from 0.21307 to 0.21217, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2126 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9392 - val_loss: 0.2122 - val_mse_loss_fn: 0.0347 - val_kl_loss_fn: 17.7843\n",
      "Epoch 197/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2127 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9396\n",
      "Epoch 197: val_loss did not improve from 0.21217\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2127 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9395 - val_loss: 0.2266 - val_mse_loss_fn: 0.0497 - val_kl_loss_fn: 17.7379\n",
      "Epoch 198/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2129 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9402\n",
      "Epoch 198: val_loss did not improve from 0.21217\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2129 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9407 - val_loss: 0.2262 - val_mse_loss_fn: 0.0483 - val_kl_loss_fn: 17.8340\n",
      "Epoch 199/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2129 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9382\n",
      "Epoch 199: val_loss improved from 0.21217 to 0.21186, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2129 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9395 - val_loss: 0.2119 - val_mse_loss_fn: 0.0344 - val_kl_loss_fn: 17.7826\n",
      "Epoch 200/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2123 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9349\n",
      "Epoch 200: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2123 - mse_loss_fn: 0.0332 - kl_loss_fn: 17.9353 - val_loss: 0.2225 - val_mse_loss_fn: 0.0456 - val_kl_loss_fn: 17.7381\n",
      "Epoch 201/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2127 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9377\n",
      "Epoch 201: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2127 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9377 - val_loss: 0.2168 - val_mse_loss_fn: 0.0389 - val_kl_loss_fn: 17.8219\n",
      "Epoch 202/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2125 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9351\n",
      "Epoch 202: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2125 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9351 - val_loss: 0.2248 - val_mse_loss_fn: 0.0471 - val_kl_loss_fn: 17.8168\n",
      "Epoch 203/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2130 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9362\n",
      "Epoch 203: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2129 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9363 - val_loss: 0.2223 - val_mse_loss_fn: 0.0445 - val_kl_loss_fn: 17.8199\n",
      "Epoch 204/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2123 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9341\n",
      "Epoch 204: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2123 - mse_loss_fn: 0.0332 - kl_loss_fn: 17.9345 - val_loss: 0.2129 - val_mse_loss_fn: 0.0348 - val_kl_loss_fn: 17.8523\n",
      "Epoch 205/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9360\n",
      "Epoch 205: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2127 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9360 - val_loss: 0.2125 - val_mse_loss_fn: 0.0351 - val_kl_loss_fn: 17.7759\n",
      "Epoch 206/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2125 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9338\n",
      "Epoch 206: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2125 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9337 - val_loss: 0.2180 - val_mse_loss_fn: 0.0409 - val_kl_loss_fn: 17.7432\n",
      "Epoch 207/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2127 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9402\n",
      "Epoch 207: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2126 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9403 - val_loss: 0.2257 - val_mse_loss_fn: 0.0484 - val_kl_loss_fn: 17.7764\n",
      "Epoch 208/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2127 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9331\n",
      "Epoch 208: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2127 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9331 - val_loss: 0.2183 - val_mse_loss_fn: 0.0403 - val_kl_loss_fn: 17.8453\n",
      "Epoch 209/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9306\n",
      "Epoch 209: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2126 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9306 - val_loss: 0.2145 - val_mse_loss_fn: 0.0376 - val_kl_loss_fn: 17.7354\n",
      "Epoch 210/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2124 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9318\n",
      "Epoch 210: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2124 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9311 - val_loss: 0.2277 - val_mse_loss_fn: 0.0504 - val_kl_loss_fn: 17.7767\n",
      "Epoch 211/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2130 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9307\n",
      "Epoch 211: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2130 - mse_loss_fn: 0.0340 - kl_loss_fn: 17.9304 - val_loss: 0.2249 - val_mse_loss_fn: 0.0476 - val_kl_loss_fn: 17.7696\n",
      "Epoch 212/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2125 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9310\n",
      "Epoch 212: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2125 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9312 - val_loss: 0.2140 - val_mse_loss_fn: 0.0365 - val_kl_loss_fn: 17.7819\n",
      "Epoch 213/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2124 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9308\n",
      "Epoch 213: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2124 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9309 - val_loss: 0.2219 - val_mse_loss_fn: 0.0446 - val_kl_loss_fn: 17.7720\n",
      "Epoch 214/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0339 - kl_loss_fn: 17.9293\n",
      "Epoch 214: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2128 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9296 - val_loss: 0.2193 - val_mse_loss_fn: 0.0422 - val_kl_loss_fn: 17.7516\n",
      "Epoch 215/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2125 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9353\n",
      "Epoch 215: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2125 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9348 - val_loss: 0.2199 - val_mse_loss_fn: 0.0423 - val_kl_loss_fn: 17.8009\n",
      "Epoch 216/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2122 - mse_loss_fn: 0.0332 - kl_loss_fn: 17.9325\n",
      "Epoch 216: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2122 - mse_loss_fn: 0.0331 - kl_loss_fn: 17.9329 - val_loss: 0.2146 - val_mse_loss_fn: 0.0369 - val_kl_loss_fn: 17.8093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2125 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9261\n",
      "Epoch 217: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2125 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9260 - val_loss: 0.2181 - val_mse_loss_fn: 0.0408 - val_kl_loss_fn: 17.7725\n",
      "Epoch 218/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2128 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9305\n",
      "Epoch 218: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2128 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9306 - val_loss: 0.2300 - val_mse_loss_fn: 0.0526 - val_kl_loss_fn: 17.7932\n",
      "Epoch 219/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9292\n",
      "Epoch 219: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2125 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9295 - val_loss: 0.2192 - val_mse_loss_fn: 0.0419 - val_kl_loss_fn: 17.7724\n",
      "Epoch 220/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9291\n",
      "Epoch 220: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2126 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9290 - val_loss: 0.2164 - val_mse_loss_fn: 0.0390 - val_kl_loss_fn: 17.7804\n",
      "Epoch 221/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9324\n",
      "Epoch 221: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2125 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9322 - val_loss: 0.2123 - val_mse_loss_fn: 0.0350 - val_kl_loss_fn: 17.7611\n",
      "Epoch 222/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2122 - mse_loss_fn: 0.0332 - kl_loss_fn: 17.9286\n",
      "Epoch 222: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2122 - mse_loss_fn: 0.0332 - kl_loss_fn: 17.9285 - val_loss: 0.2172 - val_mse_loss_fn: 0.0402 - val_kl_loss_fn: 17.7453\n",
      "Epoch 223/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2125 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9287\n",
      "Epoch 223: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2124 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9286 - val_loss: 0.2212 - val_mse_loss_fn: 0.0437 - val_kl_loss_fn: 17.7934\n",
      "Epoch 224/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2124 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9252\n",
      "Epoch 224: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2124 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9246 - val_loss: 0.2381 - val_mse_loss_fn: 0.0610 - val_kl_loss_fn: 17.7755\n",
      "Epoch 225/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2125 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9215\n",
      "Epoch 225: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2125 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9216 - val_loss: 0.2121 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.7574\n",
      "Epoch 226/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9284\n",
      "Epoch 226: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2126 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9299 - val_loss: 0.2138 - val_mse_loss_fn: 0.0359 - val_kl_loss_fn: 17.8308\n",
      "Epoch 227/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2123 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9239\n",
      "Epoch 227: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2123 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9237 - val_loss: 0.2184 - val_mse_loss_fn: 0.0410 - val_kl_loss_fn: 17.7833\n",
      "Epoch 228/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2124 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9259\n",
      "Epoch 228: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2124 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9263 - val_loss: 0.2156 - val_mse_loss_fn: 0.0385 - val_kl_loss_fn: 17.7415\n",
      "Epoch 229/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2123 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9245\n",
      "Epoch 229: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2123 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9240 - val_loss: 0.2154 - val_mse_loss_fn: 0.0379 - val_kl_loss_fn: 17.7852\n",
      "Epoch 230/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2121 - mse_loss_fn: 0.0332 - kl_loss_fn: 17.9268\n",
      "Epoch 230: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 9s 18us/sample - loss: 0.2121 - mse_loss_fn: 0.0331 - kl_loss_fn: 17.9269 - val_loss: 0.2128 - val_mse_loss_fn: 0.0357 - val_kl_loss_fn: 17.7446\n",
      "Epoch 231/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9277\n",
      "Epoch 231: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 9us/sample - loss: 0.2125 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9274 - val_loss: 0.2242 - val_mse_loss_fn: 0.0469 - val_kl_loss_fn: 17.7753\n",
      "Epoch 232/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2124 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9265\n",
      "Epoch 232: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2124 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9273 - val_loss: 0.2183 - val_mse_loss_fn: 0.0413 - val_kl_loss_fn: 17.7459\n",
      "Epoch 233/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2123 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9238\n",
      "Epoch 233: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2123 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9238 - val_loss: 0.2248 - val_mse_loss_fn: 0.0475 - val_kl_loss_fn: 17.7702\n",
      "Epoch 234/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2127 - mse_loss_fn: 0.0338 - kl_loss_fn: 17.9240\n",
      "Epoch 234: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2127 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9243 - val_loss: 0.2165 - val_mse_loss_fn: 0.0394 - val_kl_loss_fn: 17.7511\n",
      "Epoch 235/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2122 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9165\n",
      "Epoch 235: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2122 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9165 - val_loss: 0.2268 - val_mse_loss_fn: 0.0487 - val_kl_loss_fn: 17.8517\n",
      "Epoch 236/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2126 - mse_loss_fn: 0.0337 - kl_loss_fn: 17.9267\n",
      "Epoch 236: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2126 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9265 - val_loss: 0.2199 - val_mse_loss_fn: 0.0425 - val_kl_loss_fn: 17.7822\n",
      "Epoch 237/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2123 - mse_loss_fn: 0.0334 - kl_loss_fn: 17.9275\n",
      "Epoch 237: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2123 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9270 - val_loss: 0.2159 - val_mse_loss_fn: 0.0382 - val_kl_loss_fn: 17.8054\n",
      "Epoch 238/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2122 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9262\n",
      "Epoch 238: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2122 - mse_loss_fn: 0.0332 - kl_loss_fn: 17.9264 - val_loss: 0.2189 - val_mse_loss_fn: 0.0411 - val_kl_loss_fn: 17.8206\n",
      "Epoch 239/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2123 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9247\n",
      "Epoch 239: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2123 - mse_loss_fn: 0.0333 - kl_loss_fn: 17.9247 - val_loss: 0.2260 - val_mse_loss_fn: 0.0483 - val_kl_loss_fn: 17.8131\n",
      "Epoch 240/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2125 - mse_loss_fn: 0.0336 - kl_loss_fn: 17.9217\n",
      "Epoch 240: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2124 - mse_loss_fn: 0.0335 - kl_loss_fn: 17.9220 - val_loss: 0.2170 - val_mse_loss_fn: 0.0399 - val_kl_loss_fn: 17.7539\n",
      "Train on 499889 samples, validate on 378759 samples\n",
      "Epoch 1/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2135 - mse_loss_fn: 0.0344 - kl_loss_fn: 17.9419\n",
      "Epoch 1: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2134 - mse_loss_fn: 0.0343 - kl_loss_fn: 17.9421 - val_loss: 0.2123 - val_mse_loss_fn: 0.0341 - val_kl_loss_fn: 17.8476\n",
      "Epoch 2/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.9345\n",
      "Epoch 2: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2106 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.9345 - val_loss: 0.2131 - val_mse_loss_fn: 0.0348 - val_kl_loss_fn: 17.8617\n",
      "Epoch 3/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9351\n",
      "Epoch 3: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9347 - val_loss: 0.2140 - val_mse_loss_fn: 0.0358 - val_kl_loss_fn: 17.8483\n",
      "Epoch 4/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9375\n",
      "Epoch 4: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9375 - val_loss: 0.2151 - val_mse_loss_fn: 0.0376 - val_kl_loss_fn: 17.7867\n",
      "Epoch 5/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9383\n",
      "Epoch 5: val_loss did not improve from 0.21186\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9379 - val_loss: 0.2176 - val_mse_loss_fn: 0.0395 - val_kl_loss_fn: 17.8532\n",
      "Epoch 6/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2110 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9317\n",
      "Epoch 6: val_loss improved from 0.21186 to 0.21084, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2110 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9318 - val_loss: 0.2108 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.8291\n",
      "Epoch 7/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9360\n",
      "Epoch 7: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9360 - val_loss: 0.2117 - val_mse_loss_fn: 0.0336 - val_kl_loss_fn: 17.8476\n",
      "Epoch 8/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2110 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9346\n",
      "Epoch 8: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2110 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9347 - val_loss: 0.2122 - val_mse_loss_fn: 0.0341 - val_kl_loss_fn: 17.8394\n",
      "Epoch 9/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9365\n",
      "Epoch 9: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9364 - val_loss: 0.2112 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.8717\n",
      "Epoch 10/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9340\n",
      "Epoch 10: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9346 - val_loss: 0.2115 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.8441\n",
      "Epoch 11/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2110 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9359\n",
      "Epoch 11: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9352 - val_loss: 0.2109 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8526\n",
      "Epoch 12/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9298\n",
      "Epoch 12: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9295 - val_loss: 0.2118 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8244\n",
      "Epoch 13/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9348\n",
      "Epoch 13: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9347 - val_loss: 0.2149 - val_mse_loss_fn: 0.0370 - val_kl_loss_fn: 17.8260\n",
      "Epoch 14/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2110 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9338\n",
      "Epoch 14: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9345 - val_loss: 0.2139 - val_mse_loss_fn: 0.0360 - val_kl_loss_fn: 17.8340\n",
      "Epoch 15/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2110 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9372\n",
      "Epoch 15: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2110 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9373 - val_loss: 0.2145 - val_mse_loss_fn: 0.0363 - val_kl_loss_fn: 17.8575\n",
      "Epoch 16/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9319\n",
      "Epoch 16: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9317 - val_loss: 0.2149 - val_mse_loss_fn: 0.0370 - val_kl_loss_fn: 17.8227\n",
      "Epoch 17/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2110 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9314\n",
      "Epoch 17: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2110 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9314 - val_loss: 0.2137 - val_mse_loss_fn: 0.0356 - val_kl_loss_fn: 17.8443\n",
      "Epoch 18/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9304\n",
      "Epoch 18: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9308 - val_loss: 0.2141 - val_mse_loss_fn: 0.0358 - val_kl_loss_fn: 17.8588\n",
      "Epoch 19/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9324\n",
      "Epoch 19: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9323 - val_loss: 0.2137 - val_mse_loss_fn: 0.0353 - val_kl_loss_fn: 17.8763\n",
      "Epoch 20/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9299\n",
      "Epoch 20: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9300 - val_loss: 0.2144 - val_mse_loss_fn: 0.0366 - val_kl_loss_fn: 17.8098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9292\n",
      "Epoch 21: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9296 - val_loss: 0.2190 - val_mse_loss_fn: 0.0408 - val_kl_loss_fn: 17.8615\n",
      "Epoch 22/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9289\n",
      "Epoch 22: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9295 - val_loss: 0.2132 - val_mse_loss_fn: 0.0348 - val_kl_loss_fn: 17.8774\n",
      "Epoch 23/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2110 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9318\n",
      "Epoch 23: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9323 - val_loss: 0.2118 - val_mse_loss_fn: 0.0337 - val_kl_loss_fn: 17.8446\n",
      "Epoch 24/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9302\n",
      "Epoch 24: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9307 - val_loss: 0.2136 - val_mse_loss_fn: 0.0353 - val_kl_loss_fn: 17.8740\n",
      "Epoch 25/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9288\n",
      "Epoch 25: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9287 - val_loss: 0.2110 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.8300\n",
      "Epoch 26/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9295\n",
      "Epoch 26: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2109 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9298 - val_loss: 0.2128 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.8233\n",
      "Epoch 27/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9275\n",
      "Epoch 27: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9277 - val_loss: 0.2151 - val_mse_loss_fn: 0.0371 - val_kl_loss_fn: 17.8341\n",
      "Epoch 28/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9312\n",
      "Epoch 28: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9310 - val_loss: 0.2113 - val_mse_loss_fn: 0.0333 - val_kl_loss_fn: 17.8344\n",
      "Epoch 29/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9261\n",
      "Epoch 29: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9263 - val_loss: 0.2124 - val_mse_loss_fn: 0.0346 - val_kl_loss_fn: 17.8078\n",
      "Epoch 30/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9339\n",
      "Epoch 30: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9348 - val_loss: 0.2152 - val_mse_loss_fn: 0.0374 - val_kl_loss_fn: 17.8202\n",
      "Epoch 31/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9263\n",
      "Epoch 31: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9258 - val_loss: 0.2161 - val_mse_loss_fn: 0.0384 - val_kl_loss_fn: 17.8162\n",
      "Epoch 32/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9286\n",
      "Epoch 32: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 8s 16us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9285 - val_loss: 0.2130 - val_mse_loss_fn: 0.0356 - val_kl_loss_fn: 17.7736\n",
      "Epoch 33/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9235\n",
      "Epoch 33: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9235 - val_loss: 0.2142 - val_mse_loss_fn: 0.0365 - val_kl_loss_fn: 17.8060\n",
      "Epoch 34/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9238\n",
      "Epoch 34: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9238 - val_loss: 0.2195 - val_mse_loss_fn: 0.0416 - val_kl_loss_fn: 17.8397\n",
      "Epoch 35/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9260\n",
      "Epoch 35: val_loss did not improve from 0.21084\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9260 - val_loss: 0.2139 - val_mse_loss_fn: 0.0359 - val_kl_loss_fn: 17.8355\n",
      "Epoch 36/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9218\n",
      "Epoch 36: val_loss improved from 0.21084 to 0.21078, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9214 - val_loss: 0.2108 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8269\n",
      "Epoch 37/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9234\n",
      "Epoch 37: val_loss did not improve from 0.21078\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9235 - val_loss: 0.2109 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8494\n",
      "Epoch 38/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9236\n",
      "Epoch 38: val_loss did not improve from 0.21078\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9239 - val_loss: 0.2120 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.8008\n",
      "Epoch 39/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9222\n",
      "Epoch 39: val_loss did not improve from 0.21078\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9224 - val_loss: 0.2116 - val_mse_loss_fn: 0.0337 - val_kl_loss_fn: 17.8238\n",
      "Epoch 40/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9235\n",
      "Epoch 40: val_loss improved from 0.21078 to 0.21064, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9237 - val_loss: 0.2106 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8452\n",
      "Epoch 41/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9246\n",
      "Epoch 41: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9256 - val_loss: 0.2132 - val_mse_loss_fn: 0.0352 - val_kl_loss_fn: 17.8299\n",
      "Epoch 42/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9195\n",
      "Epoch 42: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9204 - val_loss: 0.2187 - val_mse_loss_fn: 0.0404 - val_kl_loss_fn: 17.8613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9271\n",
      "Epoch 43: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9271 - val_loss: 0.2138 - val_mse_loss_fn: 0.0358 - val_kl_loss_fn: 17.8296\n",
      "Epoch 44/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9233\n",
      "Epoch 44: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9227 - val_loss: 0.2116 - val_mse_loss_fn: 0.0342 - val_kl_loss_fn: 17.7726\n",
      "Epoch 45/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9274\n",
      "Epoch 45: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9273 - val_loss: 0.2126 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.8372\n",
      "Epoch 46/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9199\n",
      "Epoch 46: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9201 - val_loss: 0.2120 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8400\n",
      "Epoch 47/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9246\n",
      "Epoch 47: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9247 - val_loss: 0.2171 - val_mse_loss_fn: 0.0396 - val_kl_loss_fn: 17.7908\n",
      "Epoch 48/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9223\n",
      "Epoch 48: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9221 - val_loss: 0.2118 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.8159\n",
      "Epoch 49/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9238\n",
      "Epoch 49: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9241 - val_loss: 0.2134 - val_mse_loss_fn: 0.0353 - val_kl_loss_fn: 17.8499\n",
      "Epoch 50/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9178\n",
      "Epoch 50: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9177 - val_loss: 0.2113 - val_mse_loss_fn: 0.0331 - val_kl_loss_fn: 17.8536\n",
      "Epoch 51/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9231\n",
      "Epoch 51: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9228 - val_loss: 0.2171 - val_mse_loss_fn: 0.0395 - val_kl_loss_fn: 17.8041\n",
      "Epoch 52/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9220\n",
      "Epoch 52: val_loss did not improve from 0.21064\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9221 - val_loss: 0.2124 - val_mse_loss_fn: 0.0346 - val_kl_loss_fn: 17.8183\n",
      "Epoch 53/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9162\n",
      "Epoch 53: val_loss improved from 0.21064 to 0.21039, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9160 - val_loss: 0.2104 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8100\n",
      "Epoch 54/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9175\n",
      "Epoch 54: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2105 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.9174 - val_loss: 0.2120 - val_mse_loss_fn: 0.0347 - val_kl_loss_fn: 17.7601\n",
      "Epoch 55/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9167\n",
      "Epoch 55: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9171 - val_loss: 0.2203 - val_mse_loss_fn: 0.0420 - val_kl_loss_fn: 17.8701\n",
      "Epoch 56/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9262\n",
      "Epoch 56: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2109 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9262 - val_loss: 0.2105 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8502\n",
      "Epoch 57/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9163\n",
      "Epoch 57: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9163 - val_loss: 0.2127 - val_mse_loss_fn: 0.0348 - val_kl_loss_fn: 17.8297\n",
      "Epoch 58/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9216\n",
      "Epoch 58: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9214 - val_loss: 0.2135 - val_mse_loss_fn: 0.0354 - val_kl_loss_fn: 17.8446\n",
      "Epoch 59/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9219\n",
      "Epoch 59: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9213 - val_loss: 0.2128 - val_mse_loss_fn: 0.0354 - val_kl_loss_fn: 17.7779\n",
      "Epoch 60/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9189\n",
      "Epoch 60: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 4s 8us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9184 - val_loss: 0.2165 - val_mse_loss_fn: 0.0393 - val_kl_loss_fn: 17.7678\n",
      "Epoch 61/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9219\n",
      "Epoch 61: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9221 - val_loss: 0.2149 - val_mse_loss_fn: 0.0372 - val_kl_loss_fn: 17.8114\n",
      "Epoch 62/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9193\n",
      "Epoch 62: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9189 - val_loss: 0.2118 - val_mse_loss_fn: 0.0341 - val_kl_loss_fn: 17.8061\n",
      "Epoch 63/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9195\n",
      "Epoch 63: val_loss did not improve from 0.21039\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9200 - val_loss: 0.2129 - val_mse_loss_fn: 0.0351 - val_kl_loss_fn: 17.8181\n",
      "Epoch 64/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9133\n",
      "Epoch 64: val_loss improved from 0.21039 to 0.21019, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9133 - val_loss: 0.2102 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.8496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9160\n",
      "Epoch 65: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9165 - val_loss: 0.2109 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.8268\n",
      "Epoch 66/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9217\n",
      "Epoch 66: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9220 - val_loss: 0.2160 - val_mse_loss_fn: 0.0382 - val_kl_loss_fn: 17.8252\n",
      "Epoch 67/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9162\n",
      "Epoch 67: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9147 - val_loss: 0.2116 - val_mse_loss_fn: 0.0336 - val_kl_loss_fn: 17.8381\n",
      "Epoch 68/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9235\n",
      "Epoch 68: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9235 - val_loss: 0.2136 - val_mse_loss_fn: 0.0357 - val_kl_loss_fn: 17.8190\n",
      "Epoch 69/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2109 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9157\n",
      "Epoch 69: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2108 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9144 - val_loss: 0.2107 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.8115\n",
      "Epoch 70/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9135\n",
      "Epoch 70: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9138 - val_loss: 0.2118 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.8191\n",
      "Epoch 71/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9191\n",
      "Epoch 71: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9192 - val_loss: 0.2135 - val_mse_loss_fn: 0.0360 - val_kl_loss_fn: 17.7884\n",
      "Epoch 72/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9144\n",
      "Epoch 72: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9142 - val_loss: 0.2184 - val_mse_loss_fn: 0.0411 - val_kl_loss_fn: 17.7674\n",
      "Epoch 73/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9212\n",
      "Epoch 73: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 7s 14us/sample - loss: 0.2108 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9211 - val_loss: 0.2168 - val_mse_loss_fn: 0.0397 - val_kl_loss_fn: 17.7504\n",
      "Epoch 74/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9200\n",
      "Epoch 74: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 4s 9us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9199 - val_loss: 0.2121 - val_mse_loss_fn: 0.0344 - val_kl_loss_fn: 17.7995\n",
      "Epoch 75/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9137\n",
      "Epoch 75: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9137 - val_loss: 0.2106 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8377\n",
      "Epoch 76/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9170\n",
      "Epoch 76: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9171 - val_loss: 0.2140 - val_mse_loss_fn: 0.0364 - val_kl_loss_fn: 17.7960\n",
      "Epoch 77/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9139\n",
      "Epoch 77: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9141 - val_loss: 0.2129 - val_mse_loss_fn: 0.0352 - val_kl_loss_fn: 17.8062\n",
      "Epoch 78/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9141\n",
      "Epoch 78: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9143 - val_loss: 0.2106 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.8571\n",
      "Epoch 79/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9180\n",
      "Epoch 79: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9184 - val_loss: 0.2136 - val_mse_loss_fn: 0.0358 - val_kl_loss_fn: 17.8191\n",
      "Epoch 80/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9133\n",
      "Epoch 80: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9133 - val_loss: 0.2114 - val_mse_loss_fn: 0.0333 - val_kl_loss_fn: 17.8361\n",
      "Epoch 81/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9128\n",
      "Epoch 81: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9122 - val_loss: 0.2162 - val_mse_loss_fn: 0.0385 - val_kl_loss_fn: 17.8080\n",
      "Epoch 82/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9144\n",
      "Epoch 82: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9149 - val_loss: 0.2130 - val_mse_loss_fn: 0.0354 - val_kl_loss_fn: 17.7917\n",
      "Epoch 83/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9171\n",
      "Epoch 83: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9172 - val_loss: 0.2142 - val_mse_loss_fn: 0.0368 - val_kl_loss_fn: 17.7786\n",
      "Epoch 84/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9166\n",
      "Epoch 84: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9181 - val_loss: 0.2151 - val_mse_loss_fn: 0.0366 - val_kl_loss_fn: 17.8879\n",
      "Epoch 85/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9105\n",
      "Epoch 85: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9110 - val_loss: 0.2132 - val_mse_loss_fn: 0.0352 - val_kl_loss_fn: 17.8386\n",
      "Epoch 86/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9155\n",
      "Epoch 86: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9155 - val_loss: 0.2160 - val_mse_loss_fn: 0.0385 - val_kl_loss_fn: 17.7864\n",
      "Epoch 87/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9102\n",
      "Epoch 87: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9110 - val_loss: 0.2113 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.8199\n",
      "Epoch 88/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9114\n",
      "Epoch 88: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9115 - val_loss: 0.2133 - val_mse_loss_fn: 0.0358 - val_kl_loss_fn: 17.7867\n",
      "Epoch 89/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9081\n",
      "Epoch 89: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9083 - val_loss: 0.2121 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.8129\n",
      "Epoch 90/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9133\n",
      "Epoch 90: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9139 - val_loss: 0.2134 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.8813\n",
      "Epoch 91/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9095\n",
      "Epoch 91: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9095 - val_loss: 0.2123 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.7670\n",
      "Epoch 92/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9123\n",
      "Epoch 92: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9123 - val_loss: 0.2147 - val_mse_loss_fn: 0.0368 - val_kl_loss_fn: 17.8247\n",
      "Epoch 93/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9142\n",
      "Epoch 93: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9146 - val_loss: 0.2137 - val_mse_loss_fn: 0.0357 - val_kl_loss_fn: 17.8370\n",
      "Epoch 94/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9152\n",
      "Epoch 94: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9151 - val_loss: 0.2180 - val_mse_loss_fn: 0.0403 - val_kl_loss_fn: 17.8089\n",
      "Epoch 95/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9072\n",
      "Epoch 95: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9069 - val_loss: 0.2141 - val_mse_loss_fn: 0.0364 - val_kl_loss_fn: 17.8078\n",
      "Epoch 96/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9115\n",
      "Epoch 96: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9125 - val_loss: 0.2122 - val_mse_loss_fn: 0.0342 - val_kl_loss_fn: 17.8342\n",
      "Epoch 97/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9111\n",
      "Epoch 97: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9111 - val_loss: 0.2155 - val_mse_loss_fn: 0.0376 - val_kl_loss_fn: 17.8294\n",
      "Epoch 98/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9125\n",
      "Epoch 98: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9128 - val_loss: 0.2125 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.8575\n",
      "Epoch 99/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9134\n",
      "Epoch 99: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9136 - val_loss: 0.2134 - val_mse_loss_fn: 0.0359 - val_kl_loss_fn: 17.7854\n",
      "Epoch 100/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9129\n",
      "Epoch 100: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9128 - val_loss: 0.2169 - val_mse_loss_fn: 0.0391 - val_kl_loss_fn: 17.8213\n",
      "Epoch 101/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2108 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9122\n",
      "Epoch 101: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2108 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9122 - val_loss: 0.2130 - val_mse_loss_fn: 0.0351 - val_kl_loss_fn: 17.8215\n",
      "Epoch 102/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9084\n",
      "Epoch 102: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9088 - val_loss: 0.2131 - val_mse_loss_fn: 0.0353 - val_kl_loss_fn: 17.8107\n",
      "Epoch 103/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9074\n",
      "Epoch 103: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9075 - val_loss: 0.2124 - val_mse_loss_fn: 0.0346 - val_kl_loss_fn: 17.8137\n",
      "Epoch 104/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9100\n",
      "Epoch 104: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9098 - val_loss: 0.2120 - val_mse_loss_fn: 0.0344 - val_kl_loss_fn: 17.7942\n",
      "Epoch 105/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9058\n",
      "Epoch 105: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9058 - val_loss: 0.2155 - val_mse_loss_fn: 0.0380 - val_kl_loss_fn: 17.7843\n",
      "Epoch 106/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9029\n",
      "Epoch 106: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9031 - val_loss: 0.2106 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8110\n",
      "Epoch 107/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9068\n",
      "Epoch 107: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9064 - val_loss: 0.2148 - val_mse_loss_fn: 0.0374 - val_kl_loss_fn: 17.7741\n",
      "Epoch 108/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9122\n",
      "Epoch 108: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9123 - val_loss: 0.2139 - val_mse_loss_fn: 0.0363 - val_kl_loss_fn: 17.7972\n",
      "Epoch 109/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9074\n",
      "Epoch 109: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9078 - val_loss: 0.2136 - val_mse_loss_fn: 0.0356 - val_kl_loss_fn: 17.8311\n",
      "Epoch 110/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9063\n",
      "Epoch 110: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9064 - val_loss: 0.2114 - val_mse_loss_fn: 0.0338 - val_kl_loss_fn: 17.8022\n",
      "Epoch 111/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9101\n",
      "Epoch 111: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9099 - val_loss: 0.2103 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.7969\n",
      "Epoch 112/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9091\n",
      "Epoch 112: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9091 - val_loss: 0.2139 - val_mse_loss_fn: 0.0361 - val_kl_loss_fn: 17.8171\n",
      "Epoch 113/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9071\n",
      "Epoch 113: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9068 - val_loss: 0.2117 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8079\n",
      "Epoch 114/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9107\n",
      "Epoch 114: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9108 - val_loss: 0.2123 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.7735\n",
      "Epoch 115/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9075\n",
      "Epoch 115: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9078 - val_loss: 0.2121 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.8212\n",
      "Epoch 116/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9060\n",
      "Epoch 116: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9059 - val_loss: 0.2146 - val_mse_loss_fn: 0.0366 - val_kl_loss_fn: 17.8387\n",
      "Epoch 117/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9070\n",
      "Epoch 117: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9067 - val_loss: 0.2132 - val_mse_loss_fn: 0.0354 - val_kl_loss_fn: 17.8118\n",
      "Epoch 118/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9037\n",
      "Epoch 118: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9037 - val_loss: 0.2132 - val_mse_loss_fn: 0.0354 - val_kl_loss_fn: 17.8206\n",
      "Epoch 119/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.9024\n",
      "Epoch 119: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.9024 - val_loss: 0.2139 - val_mse_loss_fn: 0.0359 - val_kl_loss_fn: 17.8396\n",
      "Epoch 120/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9107\n",
      "Epoch 120: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9107 - val_loss: 0.2129 - val_mse_loss_fn: 0.0346 - val_kl_loss_fn: 17.8633\n",
      "Epoch 121/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9063\n",
      "Epoch 121: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9062 - val_loss: 0.2165 - val_mse_loss_fn: 0.0391 - val_kl_loss_fn: 17.7817\n",
      "Epoch 122/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9098\n",
      "Epoch 122: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9097 - val_loss: 0.2126 - val_mse_loss_fn: 0.0341 - val_kl_loss_fn: 17.8826\n",
      "Epoch 123/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9039\n",
      "Epoch 123: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9038 - val_loss: 0.2128 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.8265\n",
      "Epoch 124/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9085\n",
      "Epoch 124: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9077 - val_loss: 0.2117 - val_mse_loss_fn: 0.0342 - val_kl_loss_fn: 17.7829\n",
      "Epoch 125/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9047\n",
      "Epoch 125: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9043 - val_loss: 0.2120 - val_mse_loss_fn: 0.0346 - val_kl_loss_fn: 17.7754\n",
      "Epoch 126/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9052\n",
      "Epoch 126: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9049 - val_loss: 0.2115 - val_mse_loss_fn: 0.0338 - val_kl_loss_fn: 17.8013\n",
      "Epoch 127/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9022\n",
      "Epoch 127: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9022 - val_loss: 0.2136 - val_mse_loss_fn: 0.0360 - val_kl_loss_fn: 17.7953\n",
      "Epoch 128/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9023\n",
      "Epoch 128: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9023 - val_loss: 0.2110 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8566\n",
      "Epoch 129/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9057\n",
      "Epoch 129: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9058 - val_loss: 0.2136 - val_mse_loss_fn: 0.0361 - val_kl_loss_fn: 17.7854\n",
      "Epoch 130/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9090\n",
      "Epoch 130: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9087 - val_loss: 0.2119 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.8031\n",
      "Epoch 131/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9051\n",
      "Epoch 131: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9059 - val_loss: 0.2143 - val_mse_loss_fn: 0.0362 - val_kl_loss_fn: 17.8467\n",
      "Epoch 132/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9042\n",
      "Epoch 132: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9041 - val_loss: 0.2116 - val_mse_loss_fn: 0.0337 - val_kl_loss_fn: 17.8239\n",
      "Epoch 133/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9035\n",
      "Epoch 133: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9040 - val_loss: 0.2118 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.8158\n",
      "Epoch 134/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9076\n",
      "Epoch 134: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9076 - val_loss: 0.2110 - val_mse_loss_fn: 0.0336 - val_kl_loss_fn: 17.7725\n",
      "Epoch 135/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9026\n",
      "Epoch 135: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9026 - val_loss: 0.2120 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.8046\n",
      "Epoch 136/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9048\n",
      "Epoch 136: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9051 - val_loss: 0.2124 - val_mse_loss_fn: 0.0344 - val_kl_loss_fn: 17.8258\n",
      "Epoch 137/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9048\n",
      "Epoch 137: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9047 - val_loss: 0.2105 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.7903\n",
      "Epoch 138/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9067\n",
      "Epoch 138: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9068 - val_loss: 0.2109 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8024\n",
      "Epoch 139/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9032\n",
      "Epoch 139: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9035 - val_loss: 0.2147 - val_mse_loss_fn: 0.0367 - val_kl_loss_fn: 17.8379\n",
      "Epoch 140/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2107 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.9040\n",
      "Epoch 140: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2107 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9042 - val_loss: 0.2114 - val_mse_loss_fn: 0.0333 - val_kl_loss_fn: 17.8511\n",
      "Epoch 141/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.9066\n",
      "Epoch 141: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.9066 - val_loss: 0.2145 - val_mse_loss_fn: 0.0373 - val_kl_loss_fn: 17.7581\n",
      "Epoch 142/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9010\n",
      "Epoch 142: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9005 - val_loss: 0.2133 - val_mse_loss_fn: 0.0360 - val_kl_loss_fn: 17.7641\n",
      "Epoch 143/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9029\n",
      "Epoch 143: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9017 - val_loss: 0.2176 - val_mse_loss_fn: 0.0406 - val_kl_loss_fn: 17.7378\n",
      "Epoch 144/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9050\n",
      "Epoch 144: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9050 - val_loss: 0.2109 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8043\n",
      "Epoch 145/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9056\n",
      "Epoch 145: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9056 - val_loss: 0.2126 - val_mse_loss_fn: 0.0344 - val_kl_loss_fn: 17.8519\n",
      "Epoch 146/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9032\n",
      "Epoch 146: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9032 - val_loss: 0.2134 - val_mse_loss_fn: 0.0359 - val_kl_loss_fn: 17.7944\n",
      "Epoch 147/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8992\n",
      "Epoch 147: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9003 - val_loss: 0.2166 - val_mse_loss_fn: 0.0388 - val_kl_loss_fn: 17.8198\n",
      "Epoch 148/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9043\n",
      "Epoch 148: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9038 - val_loss: 0.2111 - val_mse_loss_fn: 0.0338 - val_kl_loss_fn: 17.7577\n",
      "Epoch 149/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8973\n",
      "Epoch 149: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8982 - val_loss: 0.2128 - val_mse_loss_fn: 0.0352 - val_kl_loss_fn: 17.7879\n",
      "Epoch 150/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9011\n",
      "Epoch 150: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9009 - val_loss: 0.2127 - val_mse_loss_fn: 0.0346 - val_kl_loss_fn: 17.8365\n",
      "Epoch 151/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9006\n",
      "Epoch 151: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9007 - val_loss: 0.2123 - val_mse_loss_fn: 0.0344 - val_kl_loss_fn: 17.8182\n",
      "Epoch 152/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8976\n",
      "Epoch 152: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8978 - val_loss: 0.2177 - val_mse_loss_fn: 0.0398 - val_kl_loss_fn: 17.8273\n",
      "Epoch 153/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9028\n",
      "Epoch 153: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9036 - val_loss: 0.2119 - val_mse_loss_fn: 0.0342 - val_kl_loss_fn: 17.8047\n",
      "Epoch 154/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9001\n",
      "Epoch 154: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9001 - val_loss: 0.2108 - val_mse_loss_fn: 0.0331 - val_kl_loss_fn: 17.7997\n",
      "Epoch 155/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8997\n",
      "Epoch 155: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8999 - val_loss: 0.2136 - val_mse_loss_fn: 0.0359 - val_kl_loss_fn: 17.8078\n",
      "Epoch 156/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9001\n",
      "Epoch 156: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9004 - val_loss: 0.2198 - val_mse_loss_fn: 0.0419 - val_kl_loss_fn: 17.8341\n",
      "Epoch 157/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9005\n",
      "Epoch 157: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9008 - val_loss: 0.2136 - val_mse_loss_fn: 0.0357 - val_kl_loss_fn: 17.8276\n",
      "Epoch 158/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9026\n",
      "Epoch 158: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 5us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9019 - val_loss: 0.2166 - val_mse_loss_fn: 0.0394 - val_kl_loss_fn: 17.7526\n",
      "Epoch 159/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9011\n",
      "Epoch 159: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9016 - val_loss: 0.2110 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.8527\n",
      "Epoch 160/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9037\n",
      "Epoch 160: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9039 - val_loss: 0.2122 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.8024\n",
      "Epoch 161/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9028\n",
      "Epoch 161: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9031 - val_loss: 0.2135 - val_mse_loss_fn: 0.0356 - val_kl_loss_fn: 17.8325\n",
      "Epoch 162/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9012\n",
      "Epoch 162: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9012 - val_loss: 0.2116 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.7897\n",
      "Epoch 163/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9014\n",
      "Epoch 163: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9018 - val_loss: 0.2113 - val_mse_loss_fn: 0.0333 - val_kl_loss_fn: 17.8323\n",
      "Epoch 164/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8975\n",
      "Epoch 164: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8973 - val_loss: 0.2104 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.7781\n",
      "Epoch 165/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9035\n",
      "Epoch 165: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 8s 16us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9035 - val_loss: 0.2130 - val_mse_loss_fn: 0.0352 - val_kl_loss_fn: 17.8088\n",
      "Epoch 166/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9003\n",
      "Epoch 166: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9001 - val_loss: 0.2116 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8089\n",
      "Epoch 167/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9008\n",
      "Epoch 167: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9018 - val_loss: 0.2120 - val_mse_loss_fn: 0.0342 - val_kl_loss_fn: 17.8156\n",
      "Epoch 168/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8998\n",
      "Epoch 168: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8997 - val_loss: 0.2120 - val_mse_loss_fn: 0.0344 - val_kl_loss_fn: 17.8026\n",
      "Epoch 169/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9009\n",
      "Epoch 169: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9009 - val_loss: 0.2120 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.7817\n",
      "Epoch 170/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8970\n",
      "Epoch 170: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8977 - val_loss: 0.2148 - val_mse_loss_fn: 0.0376 - val_kl_loss_fn: 17.7581\n",
      "Epoch 171/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9022\n",
      "Epoch 171: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9026 - val_loss: 0.2107 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.8664\n",
      "Epoch 172/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8995\n",
      "Epoch 172: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8992 - val_loss: 0.2168 - val_mse_loss_fn: 0.0391 - val_kl_loss_fn: 17.8086\n",
      "Epoch 173/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9014\n",
      "Epoch 173: val_loss did not improve from 0.21019\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9014 - val_loss: 0.2156 - val_mse_loss_fn: 0.0382 - val_kl_loss_fn: 17.7786\n",
      "Epoch 174/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8963\n",
      "Epoch 174: val_loss improved from 0.21019 to 0.21010, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8958 - val_loss: 0.2101 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.7813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8959\n",
      "Epoch 175: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8957 - val_loss: 0.2124 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.8227\n",
      "Epoch 176/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8958\n",
      "Epoch 176: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8958 - val_loss: 0.2117 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.8565\n",
      "Epoch 177/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8984\n",
      "Epoch 177: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8985 - val_loss: 0.2175 - val_mse_loss_fn: 0.0406 - val_kl_loss_fn: 17.7347\n",
      "Epoch 178/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.9018\n",
      "Epoch 178: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9017 - val_loss: 0.2135 - val_mse_loss_fn: 0.0360 - val_kl_loss_fn: 17.7872\n",
      "Epoch 179/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8955\n",
      "Epoch 179: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8957 - val_loss: 0.2161 - val_mse_loss_fn: 0.0383 - val_kl_loss_fn: 17.8165\n",
      "Epoch 180/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8994\n",
      "Epoch 180: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8988 - val_loss: 0.2145 - val_mse_loss_fn: 0.0371 - val_kl_loss_fn: 17.7754\n",
      "Epoch 181/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8969\n",
      "Epoch 181: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8969 - val_loss: 0.2124 - val_mse_loss_fn: 0.0348 - val_kl_loss_fn: 17.8008\n",
      "Epoch 182/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8971\n",
      "Epoch 182: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8975 - val_loss: 0.2120 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8414\n",
      "Epoch 183/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8978\n",
      "Epoch 183: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8982 - val_loss: 0.2126 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.8407\n",
      "Epoch 184/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8990\n",
      "Epoch 184: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8992 - val_loss: 0.2178 - val_mse_loss_fn: 0.0402 - val_kl_loss_fn: 17.7958\n",
      "Epoch 185/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8948\n",
      "Epoch 185: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8953 - val_loss: 0.2137 - val_mse_loss_fn: 0.0362 - val_kl_loss_fn: 17.7931\n",
      "Epoch 186/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8945\n",
      "Epoch 186: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8953 - val_loss: 0.2124 - val_mse_loss_fn: 0.0344 - val_kl_loss_fn: 17.8418\n",
      "Epoch 187/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8974\n",
      "Epoch 187: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8971 - val_loss: 0.2110 - val_mse_loss_fn: 0.0336 - val_kl_loss_fn: 17.7758\n",
      "Epoch 188/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8984\n",
      "Epoch 188: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8976 - val_loss: 0.2117 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.7683\n",
      "Epoch 189/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8971\n",
      "Epoch 189: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8975 - val_loss: 0.2107 - val_mse_loss_fn: 0.0333 - val_kl_loss_fn: 17.7785\n",
      "Epoch 190/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8983\n",
      "Epoch 190: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8981 - val_loss: 0.2119 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.7965\n",
      "Epoch 191/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8986\n",
      "Epoch 191: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8986 - val_loss: 0.2161 - val_mse_loss_fn: 0.0380 - val_kl_loss_fn: 17.8475\n",
      "Epoch 192/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8985\n",
      "Epoch 192: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8987 - val_loss: 0.2118 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8289\n",
      "Epoch 193/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8956\n",
      "Epoch 193: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8953 - val_loss: 0.2132 - val_mse_loss_fn: 0.0357 - val_kl_loss_fn: 17.7812\n",
      "Epoch 194/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8946\n",
      "Epoch 194: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8946 - val_loss: 0.2144 - val_mse_loss_fn: 0.0365 - val_kl_loss_fn: 17.8186\n",
      "Epoch 195/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9019\n",
      "Epoch 195: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.9024 - val_loss: 0.2119 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8314\n",
      "Epoch 196/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8962\n",
      "Epoch 196: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8962 - val_loss: 0.2167 - val_mse_loss_fn: 0.0392 - val_kl_loss_fn: 17.7933\n",
      "Epoch 197/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8946\n",
      "Epoch 197: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8944 - val_loss: 0.2106 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.7863\n",
      "Epoch 198/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8976\n",
      "Epoch 198: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8976 - val_loss: 0.2167 - val_mse_loss_fn: 0.0391 - val_kl_loss_fn: 17.7980\n",
      "Epoch 199/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9015\n",
      "Epoch 199: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.9015 - val_loss: 0.2146 - val_mse_loss_fn: 0.0369 - val_kl_loss_fn: 17.8076\n",
      "Epoch 200/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8977\n",
      "Epoch 200: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8977 - val_loss: 0.2119 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.8205\n",
      "Epoch 201/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8972\n",
      "Epoch 201: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8980 - val_loss: 0.2107 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8460\n",
      "Epoch 202/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8983\n",
      "Epoch 202: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8982 - val_loss: 0.2104 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8139\n",
      "Epoch 203/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8963\n",
      "Epoch 203: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8962 - val_loss: 0.2121 - val_mse_loss_fn: 0.0346 - val_kl_loss_fn: 17.7906\n",
      "Epoch 204/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8973\n",
      "Epoch 204: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8973 - val_loss: 0.2133 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.8679\n",
      "Epoch 205/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8952\n",
      "Epoch 205: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8954 - val_loss: 0.2122 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.8037\n",
      "Epoch 206/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8962\n",
      "Epoch 206: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8966 - val_loss: 0.2129 - val_mse_loss_fn: 0.0354 - val_kl_loss_fn: 17.7923\n",
      "Epoch 207/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8955\n",
      "Epoch 207: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8955 - val_loss: 0.2138 - val_mse_loss_fn: 0.0361 - val_kl_loss_fn: 17.8121\n",
      "Epoch 208/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8930\n",
      "Epoch 208: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8929 - val_loss: 0.2174 - val_mse_loss_fn: 0.0397 - val_kl_loss_fn: 17.8095\n",
      "Epoch 209/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8982\n",
      "Epoch 209: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8985 - val_loss: 0.2122 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8637\n",
      "Epoch 210/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8935\n",
      "Epoch 210: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8936 - val_loss: 0.2131 - val_mse_loss_fn: 0.0356 - val_kl_loss_fn: 17.7855\n",
      "Epoch 211/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8927\n",
      "Epoch 211: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8927 - val_loss: 0.2137 - val_mse_loss_fn: 0.0362 - val_kl_loss_fn: 17.7923\n",
      "Epoch 212/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8930\n",
      "Epoch 212: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8925 - val_loss: 0.2117 - val_mse_loss_fn: 0.0341 - val_kl_loss_fn: 17.7883\n",
      "Epoch 213/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2103 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.8940\n",
      "Epoch 213: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2103 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.8941 - val_loss: 0.2114 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.7857\n",
      "Epoch 214/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8925\n",
      "Epoch 214: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8922 - val_loss: 0.2113 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.8286\n",
      "Epoch 215/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8971\n",
      "Epoch 215: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8976 - val_loss: 0.2206 - val_mse_loss_fn: 0.0430 - val_kl_loss_fn: 17.8034\n",
      "Epoch 216/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8932\n",
      "Epoch 216: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8930 - val_loss: 0.2116 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.7984\n",
      "Epoch 217/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8919\n",
      "Epoch 217: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8920 - val_loss: 0.2195 - val_mse_loss_fn: 0.0419 - val_kl_loss_fn: 17.8078\n",
      "Epoch 218/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8902\n",
      "Epoch 218: val_loss did not improve from 0.21010\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8909 - val_loss: 0.2127 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.8149\n",
      "Epoch 219/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2103 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8906\n",
      "Epoch 219: val_loss improved from 0.21010 to 0.21004, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8914 - val_loss: 0.2100 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8264\n",
      "Epoch 220/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8960\n",
      "Epoch 220: val_loss did not improve from 0.21004\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2103 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.8962 - val_loss: 0.2119 - val_mse_loss_fn: 0.0341 - val_kl_loss_fn: 17.8145\n",
      "Epoch 221/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8987\n",
      "Epoch 221: val_loss did not improve from 0.21004\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8990 - val_loss: 0.2107 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.7612\n",
      "Epoch 222/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8923\n",
      "Epoch 222: val_loss did not improve from 0.21004\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8924 - val_loss: 0.2192 - val_mse_loss_fn: 0.0413 - val_kl_loss_fn: 17.8297\n",
      "Epoch 223/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8973\n",
      "Epoch 223: val_loss did not improve from 0.21004\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8968 - val_loss: 0.2124 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.8298\n",
      "Epoch 224/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8914\n",
      "Epoch 224: val_loss improved from 0.21004 to 0.21000, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8905 - val_loss: 0.2100 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.7547\n",
      "Epoch 225/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8935\n",
      "Epoch 225: val_loss improved from 0.21000 to 0.20963, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8935 - val_loss: 0.2096 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.7786\n",
      "Epoch 226/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8919\n",
      "Epoch 226: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8929 - val_loss: 0.2144 - val_mse_loss_fn: 0.0366 - val_kl_loss_fn: 17.8153\n",
      "Epoch 227/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8981\n",
      "Epoch 227: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8969 - val_loss: 0.2104 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.7802\n",
      "Epoch 228/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8911\n",
      "Epoch 228: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8906 - val_loss: 0.2110 - val_mse_loss_fn: 0.0337 - val_kl_loss_fn: 17.7641\n",
      "Epoch 229/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8971\n",
      "Epoch 229: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8970 - val_loss: 0.2108 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8409\n",
      "Epoch 230/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8917\n",
      "Epoch 230: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8919 - val_loss: 0.2149 - val_mse_loss_fn: 0.0373 - val_kl_loss_fn: 17.8008\n",
      "Epoch 231/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2106 - mse_loss_fn: 0.0320 - kl_loss_fn: 17.8928\n",
      "Epoch 231: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2106 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8931 - val_loss: 0.2146 - val_mse_loss_fn: 0.0367 - val_kl_loss_fn: 17.8220\n",
      "Epoch 232/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8900\n",
      "Epoch 232: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8900 - val_loss: 0.2128 - val_mse_loss_fn: 0.0351 - val_kl_loss_fn: 17.8023\n",
      "Epoch 233/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8902\n",
      "Epoch 233: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8894 - val_loss: 0.2147 - val_mse_loss_fn: 0.0369 - val_kl_loss_fn: 17.8191\n",
      "Epoch 234/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8926\n",
      "Epoch 234: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8918 - val_loss: 0.2109 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.7717\n",
      "Epoch 235/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8934\n",
      "Epoch 235: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8930 - val_loss: 0.2127 - val_mse_loss_fn: 0.0350 - val_kl_loss_fn: 17.8029\n",
      "Epoch 236/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8919\n",
      "Epoch 236: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8918 - val_loss: 0.2103 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.7464\n",
      "Epoch 237/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2104 - mse_loss_fn: 0.0318 - kl_loss_fn: 17.8911\n",
      "Epoch 237: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2104 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8906 - val_loss: 0.2131 - val_mse_loss_fn: 0.0355 - val_kl_loss_fn: 17.7967\n",
      "Epoch 238/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8906\n",
      "Epoch 238: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2105 - mse_loss_fn: 0.0319 - kl_loss_fn: 17.8906 - val_loss: 0.2109 - val_mse_loss_fn: 0.0331 - val_kl_loss_fn: 17.8059\n",
      "Epoch 239/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8905\n",
      "Epoch 239: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2103 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.8898 - val_loss: 0.2103 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.7871\n",
      "Epoch 240/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8888\n",
      "Epoch 240: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2103 - mse_loss_fn: 0.0317 - kl_loss_fn: 17.8893 - val_loss: 0.2144 - val_mse_loss_fn: 0.0371 - val_kl_loss_fn: 17.7659\n",
      "Train on 499889 samples, validate on 378759 samples\n",
      "Epoch 1/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2103 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.8968\n",
      "Epoch 1: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2103 - mse_loss_fn: 0.0316 - kl_loss_fn: 17.8969 - val_loss: 0.2102 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8638\n",
      "Epoch 2/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8936\n",
      "Epoch 2: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8938 - val_loss: 0.2111 - val_mse_loss_fn: 0.0333 - val_kl_loss_fn: 17.8125\n",
      "Epoch 3/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8967\n",
      "Epoch 3: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 6s 13us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8964 - val_loss: 0.2113 - val_mse_loss_fn: 0.0331 - val_kl_loss_fn: 17.8518\n",
      "Epoch 4/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8906\n",
      "Epoch 4: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8905 - val_loss: 0.2114 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.8280\n",
      "Epoch 5/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8914\n",
      "Epoch 5: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8922 - val_loss: 0.2100 - val_mse_loss_fn: 0.0317 - val_kl_loss_fn: 17.8578\n",
      "Epoch 6/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8911\n",
      "Epoch 6: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8917 - val_loss: 0.2112 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8276\n",
      "Epoch 7/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8940\n",
      "Epoch 7: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8944 - val_loss: 0.2098 - val_mse_loss_fn: 0.0316 - val_kl_loss_fn: 17.8530\n",
      "Epoch 8/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8925\n",
      "Epoch 8: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8925 - val_loss: 0.2099 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.8238\n",
      "Epoch 9/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8938\n",
      "Epoch 9: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8938 - val_loss: 0.2114 - val_mse_loss_fn: 0.0333 - val_kl_loss_fn: 17.8483\n",
      "Epoch 10/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8920\n",
      "Epoch 10: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8922 - val_loss: 0.2105 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.8492\n",
      "Epoch 11/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8888\n",
      "Epoch 11: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8886 - val_loss: 0.2107 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8358\n",
      "Epoch 12/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8883\n",
      "Epoch 12: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8877 - val_loss: 0.2101 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8116\n",
      "Epoch 13/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8885\n",
      "Epoch 13: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8882 - val_loss: 0.2104 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.7933\n",
      "Epoch 14/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8922\n",
      "Epoch 14: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8919 - val_loss: 0.2105 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.8450\n",
      "Epoch 15/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8911\n",
      "Epoch 15: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8912 - val_loss: 0.2104 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.8313\n",
      "Epoch 16/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8917\n",
      "Epoch 16: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8914 - val_loss: 0.2098 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8156\n",
      "Epoch 17/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8877\n",
      "Epoch 17: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8879 - val_loss: 0.2106 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8279\n",
      "Epoch 18/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8888\n",
      "Epoch 18: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8894 - val_loss: 0.2097 - val_mse_loss_fn: 0.0315 - val_kl_loss_fn: 17.8504\n",
      "Epoch 19/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8905\n",
      "Epoch 19: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8909 - val_loss: 0.2112 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.8110\n",
      "Epoch 20/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2099 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8936\n",
      "Epoch 20: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8935 - val_loss: 0.2098 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.8108\n",
      "Epoch 21/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8872\n",
      "Epoch 21: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8872 - val_loss: 0.2103 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8680\n",
      "Epoch 22/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8903\n",
      "Epoch 22: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8903 - val_loss: 0.2108 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.8160\n",
      "Epoch 23/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8886\n",
      "Epoch 23: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8890 - val_loss: 0.2098 - val_mse_loss_fn: 0.0316 - val_kl_loss_fn: 17.8498\n",
      "Epoch 24/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8905\n",
      "Epoch 24: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8906 - val_loss: 0.2107 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8437\n",
      "Epoch 25/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8935\n",
      "Epoch 25: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8930 - val_loss: 0.2123 - val_mse_loss_fn: 0.0347 - val_kl_loss_fn: 17.7986\n",
      "Epoch 26/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8851\n",
      "Epoch 26: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8848 - val_loss: 0.2102 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8482\n",
      "Epoch 27/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8906\n",
      "Epoch 27: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8905 - val_loss: 0.2106 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.8567\n",
      "Epoch 28/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8849\n",
      "Epoch 28: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8849 - val_loss: 0.2119 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.8257\n",
      "Epoch 29/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8910\n",
      "Epoch 29: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8909 - val_loss: 0.2107 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8287\n",
      "Epoch 30/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8873\n",
      "Epoch 30: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8872 - val_loss: 0.2100 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.8344\n",
      "Epoch 31/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8927\n",
      "Epoch 31: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8925 - val_loss: 0.2104 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8149\n",
      "Epoch 32/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8900\n",
      "Epoch 32: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8898 - val_loss: 0.2109 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.8328\n",
      "Epoch 33/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8945\n",
      "Epoch 33: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8943 - val_loss: 0.2112 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8346\n",
      "Epoch 34/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8857\n",
      "Epoch 34: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8853 - val_loss: 0.2109 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.8336\n",
      "Epoch 35/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8897\n",
      "Epoch 35: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8890 - val_loss: 0.2102 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8331\n",
      "Epoch 36/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8895\n",
      "Epoch 36: val_loss did not improve from 0.20963\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8896 - val_loss: 0.2101 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8000\n",
      "Epoch 37/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8869\n",
      "Epoch 37: val_loss improved from 0.20963 to 0.20938, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8869 - val_loss: 0.2094 - val_mse_loss_fn: 0.0317 - val_kl_loss_fn: 17.8025\n",
      "Epoch 38/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8899\n",
      "Epoch 38: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8898 - val_loss: 0.2116 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.7902\n",
      "Epoch 39/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8845\n",
      "Epoch 39: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8846 - val_loss: 0.2107 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8305\n",
      "Epoch 40/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8890\n",
      "Epoch 40: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8891 - val_loss: 0.2109 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8364\n",
      "Epoch 41/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8839\n",
      "Epoch 41: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8839 - val_loss: 0.2114 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.8237\n",
      "Epoch 42/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8824\n",
      "Epoch 42: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8822 - val_loss: 0.2095 - val_mse_loss_fn: 0.0317 - val_kl_loss_fn: 17.8070\n",
      "Epoch 43/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8848\n",
      "Epoch 43: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8848 - val_loss: 0.2107 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8906\n",
      "Epoch 44: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8902 - val_loss: 0.2116 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8017\n",
      "Epoch 45/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8879\n",
      "Epoch 45: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8880 - val_loss: 0.2103 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8367\n",
      "Epoch 46/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8869\n",
      "Epoch 46: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8863 - val_loss: 0.2103 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8068\n",
      "Epoch 47/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8858\n",
      "Epoch 47: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8858 - val_loss: 0.2110 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8560\n",
      "Epoch 48/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8846\n",
      "Epoch 48: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8853 - val_loss: 0.2102 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8449\n",
      "Epoch 49/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8928\n",
      "Epoch 49: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8924 - val_loss: 0.2099 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8351\n",
      "Epoch 50/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8842\n",
      "Epoch 50: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8841 - val_loss: 0.2101 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8152\n",
      "Epoch 51/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8867\n",
      "Epoch 51: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8867 - val_loss: 0.2099 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8118\n",
      "Epoch 52/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8838\n",
      "Epoch 52: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8838 - val_loss: 0.2115 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.8364\n",
      "Epoch 53/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8843\n",
      "Epoch 53: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8843 - val_loss: 0.2111 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8220\n",
      "Epoch 54/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8838\n",
      "Epoch 54: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8832 - val_loss: 0.2098 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8064\n",
      "Epoch 55/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8821\n",
      "Epoch 55: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8822 - val_loss: 0.2104 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8226\n",
      "Epoch 56/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8842\n",
      "Epoch 56: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8850 - val_loss: 0.2104 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8621\n",
      "Epoch 57/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8844\n",
      "Epoch 57: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8848 - val_loss: 0.2114 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8520\n",
      "Epoch 58/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8808\n",
      "Epoch 58: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8811 - val_loss: 0.2106 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8326\n",
      "Epoch 59/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8855\n",
      "Epoch 59: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8856 - val_loss: 0.2110 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.8308\n",
      "Epoch 60/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8855\n",
      "Epoch 60: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8855 - val_loss: 0.2111 - val_mse_loss_fn: 0.0331 - val_kl_loss_fn: 17.8331\n",
      "Epoch 61/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8837\n",
      "Epoch 61: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 4s 9us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8839 - val_loss: 0.2104 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8652\n",
      "Epoch 62/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8838\n",
      "Epoch 62: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 4s 7us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8830 - val_loss: 0.2101 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.8010\n",
      "Epoch 63/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8853\n",
      "Epoch 63: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8850 - val_loss: 0.2121 - val_mse_loss_fn: 0.0341 - val_kl_loss_fn: 17.8397\n",
      "Epoch 64/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8833\n",
      "Epoch 64: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8830 - val_loss: 0.2097 - val_mse_loss_fn: 0.0314 - val_kl_loss_fn: 17.8529\n",
      "Epoch 65/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8810\n",
      "Epoch 65: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8812 - val_loss: 0.2100 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8229\n",
      "Epoch 66/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8819\n",
      "Epoch 66: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8817 - val_loss: 0.2104 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8046\n",
      "Epoch 67/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8831\n",
      "Epoch 67: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8835 - val_loss: 0.2104 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8151\n",
      "Epoch 68/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8800\n",
      "Epoch 68: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8803 - val_loss: 0.2102 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.7989\n",
      "Epoch 69/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8805\n",
      "Epoch 69: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8807 - val_loss: 0.2101 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8249\n",
      "Epoch 70/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8811\n",
      "Epoch 70: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8811 - val_loss: 0.2096 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.7920\n",
      "Epoch 71/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8832\n",
      "Epoch 71: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8834 - val_loss: 0.2116 - val_mse_loss_fn: 0.0336 - val_kl_loss_fn: 17.8298\n",
      "Epoch 72/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8856\n",
      "Epoch 72: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8855 - val_loss: 0.2104 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.8324\n",
      "Epoch 73/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8833\n",
      "Epoch 73: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8833 - val_loss: 0.2121 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.7964\n",
      "Epoch 74/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8779\n",
      "Epoch 74: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8781 - val_loss: 0.2118 - val_mse_loss_fn: 0.0338 - val_kl_loss_fn: 17.8404\n",
      "Epoch 75/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8794\n",
      "Epoch 75: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8796 - val_loss: 0.2117 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.8681\n",
      "Epoch 76/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8841\n",
      "Epoch 76: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8847 - val_loss: 0.2098 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8283\n",
      "Epoch 77/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8824\n",
      "Epoch 77: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8824 - val_loss: 0.2113 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.8162\n",
      "Epoch 78/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8792\n",
      "Epoch 78: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8797 - val_loss: 0.2099 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8305\n",
      "Epoch 79/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8831\n",
      "Epoch 79: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8819 - val_loss: 0.2104 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.7998\n",
      "Epoch 80/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8830\n",
      "Epoch 80: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8832 - val_loss: 0.2116 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.8386\n",
      "Epoch 81/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8841\n",
      "Epoch 81: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8836 - val_loss: 0.2101 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8135\n",
      "Epoch 82/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8814\n",
      "Epoch 82: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8807 - val_loss: 0.2118 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.7839\n",
      "Epoch 83/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8771\n",
      "Epoch 83: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8775 - val_loss: 0.2106 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8210\n",
      "Epoch 84/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8800\n",
      "Epoch 84: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8803 - val_loss: 0.2095 - val_mse_loss_fn: 0.0314 - val_kl_loss_fn: 17.8481\n",
      "Epoch 85/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8834\n",
      "Epoch 85: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8834 - val_loss: 0.2121 - val_mse_loss_fn: 0.0346 - val_kl_loss_fn: 17.7841\n",
      "Epoch 86/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8762\n",
      "Epoch 86: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8759 - val_loss: 0.2107 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.7824\n",
      "Epoch 87/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8773\n",
      "Epoch 87: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8768 - val_loss: 0.2106 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8250\n",
      "Epoch 88/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8770\n",
      "Epoch 88: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8779 - val_loss: 0.2099 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8405\n",
      "Epoch 89/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8795\n",
      "Epoch 89: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8794 - val_loss: 0.2125 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.8272\n",
      "Epoch 90/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8780\n",
      "Epoch 90: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8781 - val_loss: 0.2103 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8041\n",
      "Epoch 91/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8805\n",
      "Epoch 91: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8803 - val_loss: 0.2108 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8247\n",
      "Epoch 92/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8803\n",
      "Epoch 92: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8804 - val_loss: 0.2110 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.8258\n",
      "Epoch 93/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8789\n",
      "Epoch 93: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8795 - val_loss: 0.2105 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8561\n",
      "Epoch 94/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8832\n",
      "Epoch 94: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8830 - val_loss: 0.2133 - val_mse_loss_fn: 0.0349 - val_kl_loss_fn: 17.8691\n",
      "Epoch 95/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8799\n",
      "Epoch 95: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8804 - val_loss: 0.2098 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8195\n",
      "Epoch 96/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8786\n",
      "Epoch 96: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8781 - val_loss: 0.2112 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.8096\n",
      "Epoch 97/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8762\n",
      "Epoch 97: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8762 - val_loss: 0.2100 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8453\n",
      "Epoch 98/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8780\n",
      "Epoch 98: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8780 - val_loss: 0.2103 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.7968\n",
      "Epoch 99/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8757\n",
      "Epoch 99: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8762 - val_loss: 0.2120 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8434\n",
      "Epoch 100/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8773\n",
      "Epoch 100: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8763 - val_loss: 0.2101 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.7687\n",
      "Epoch 101/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8724\n",
      "Epoch 101: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8726 - val_loss: 0.2111 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.7990\n",
      "Epoch 102/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8787\n",
      "Epoch 102: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8786 - val_loss: 0.2111 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.7908\n",
      "Epoch 103/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8749\n",
      "Epoch 103: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8748 - val_loss: 0.2105 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8345\n",
      "Epoch 104/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8790\n",
      "Epoch 104: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8792 - val_loss: 0.2097 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.7875\n",
      "Epoch 105/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8750\n",
      "Epoch 105: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8750 - val_loss: 0.2106 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8424\n",
      "Epoch 106/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8786\n",
      "Epoch 106: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8780 - val_loss: 0.2121 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.8423\n",
      "Epoch 107/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8770\n",
      "Epoch 107: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8778 - val_loss: 0.2104 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8397\n",
      "Epoch 108/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8756\n",
      "Epoch 108: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8755 - val_loss: 0.2096 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8213\n",
      "Epoch 109/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8736\n",
      "Epoch 109: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8730 - val_loss: 0.2096 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.7896\n",
      "Epoch 110/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8747\n",
      "Epoch 110: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8752 - val_loss: 0.2099 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8396\n",
      "Epoch 111/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8788\n",
      "Epoch 111: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8786 - val_loss: 0.2116 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8037\n",
      "Epoch 112/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2098 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8816\n",
      "Epoch 112: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2098 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8814 - val_loss: 0.2096 - val_mse_loss_fn: 0.0317 - val_kl_loss_fn: 17.8298\n",
      "Epoch 113/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8740\n",
      "Epoch 113: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8736 - val_loss: 0.2094 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.7759\n",
      "Epoch 114/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8755\n",
      "Epoch 114: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8756 - val_loss: 0.2103 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8254\n",
      "Epoch 115/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8718\n",
      "Epoch 115: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8716 - val_loss: 0.2108 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8523\n",
      "Epoch 116/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8726\n",
      "Epoch 116: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8733 - val_loss: 0.2095 - val_mse_loss_fn: 0.0312 - val_kl_loss_fn: 17.8584\n",
      "Epoch 117/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8768\n",
      "Epoch 117: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8766 - val_loss: 0.2096 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8158\n",
      "Epoch 118/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8750\n",
      "Epoch 118: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 5s 9us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8749 - val_loss: 0.2122 - val_mse_loss_fn: 0.0345 - val_kl_loss_fn: 17.8075\n",
      "Epoch 119/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8752\n",
      "Epoch 119: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8748 - val_loss: 0.2105 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.7878\n",
      "Epoch 120/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8723\n",
      "Epoch 120: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8721 - val_loss: 0.2096 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.8001\n",
      "Epoch 121/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8737\n",
      "Epoch 121: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8735 - val_loss: 0.2100 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8139\n",
      "Epoch 122/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8720\n",
      "Epoch 122: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8722 - val_loss: 0.2115 - val_mse_loss_fn: 0.0333 - val_kl_loss_fn: 17.8516\n",
      "Epoch 123/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8724\n",
      "Epoch 123: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8722 - val_loss: 0.2110 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.8394\n",
      "Epoch 124/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8719\n",
      "Epoch 124: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8716 - val_loss: 0.2117 - val_mse_loss_fn: 0.0342 - val_kl_loss_fn: 17.7861\n",
      "Epoch 125/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8752\n",
      "Epoch 125: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8754 - val_loss: 0.2103 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8101\n",
      "Epoch 126/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8699\n",
      "Epoch 126: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8700 - val_loss: 0.2120 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.8360\n",
      "Epoch 127/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8704\n",
      "Epoch 127: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8711 - val_loss: 0.2094 - val_mse_loss_fn: 0.0315 - val_kl_loss_fn: 17.8272\n",
      "Epoch 128/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8712\n",
      "Epoch 128: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8712 - val_loss: 0.2107 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8228\n",
      "Epoch 129/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8681\n",
      "Epoch 129: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8687 - val_loss: 0.2111 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8194\n",
      "Epoch 130/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8680\n",
      "Epoch 130: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8680 - val_loss: 0.2097 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8212\n",
      "Epoch 131/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8689\n",
      "Epoch 131: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8694 - val_loss: 0.2105 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.8439\n",
      "Epoch 132/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8689\n",
      "Epoch 132: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8687 - val_loss: 0.2100 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8084\n",
      "Epoch 133/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8672\n",
      "Epoch 133: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8673 - val_loss: 0.2102 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8389\n",
      "Epoch 134/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8673\n",
      "Epoch 134: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8680 - val_loss: 0.2097 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8202\n",
      "Epoch 135/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8702\n",
      "Epoch 135: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8701 - val_loss: 0.2100 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8436\n",
      "Epoch 136/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2097 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8706\n",
      "Epoch 136: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2097 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8707 - val_loss: 0.2100 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8503\n",
      "Epoch 137/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8697\n",
      "Epoch 137: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8696 - val_loss: 0.2106 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8316\n",
      "Epoch 138/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8661\n",
      "Epoch 138: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8659 - val_loss: 0.2100 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.8328\n",
      "Epoch 139/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8648\n",
      "Epoch 139: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8646 - val_loss: 0.2108 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8256\n",
      "Epoch 140/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8698\n",
      "Epoch 140: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8703 - val_loss: 0.2102 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8275\n",
      "Epoch 141/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8665\n",
      "Epoch 141: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8671 - val_loss: 0.2100 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8086\n",
      "Epoch 142/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8696\n",
      "Epoch 142: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8696 - val_loss: 0.2108 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8324\n",
      "Epoch 143/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8683\n",
      "Epoch 143: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8684 - val_loss: 0.2095 - val_mse_loss_fn: 0.0316 - val_kl_loss_fn: 17.8211\n",
      "Epoch 144/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8674\n",
      "Epoch 144: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8673 - val_loss: 0.2123 - val_mse_loss_fn: 0.0346 - val_kl_loss_fn: 17.7993\n",
      "Epoch 145/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8658\n",
      "Epoch 145: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8661 - val_loss: 0.2100 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8120\n",
      "Epoch 146/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8659\n",
      "Epoch 146: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8660 - val_loss: 0.2100 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.7818\n",
      "Epoch 147/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8677\n",
      "Epoch 147: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8679 - val_loss: 0.2098 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8291\n",
      "Epoch 148/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8691\n",
      "Epoch 148: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8692 - val_loss: 0.2102 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8193\n",
      "Epoch 149/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8651\n",
      "Epoch 149: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8655 - val_loss: 0.2113 - val_mse_loss_fn: 0.0337 - val_kl_loss_fn: 17.7988\n",
      "Epoch 150/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8687\n",
      "Epoch 150: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8687 - val_loss: 0.2104 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8105\n",
      "Epoch 151/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8669\n",
      "Epoch 151: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8670 - val_loss: 0.2109 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8046\n",
      "Epoch 152/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8680\n",
      "Epoch 152: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8681 - val_loss: 0.2101 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8151\n",
      "Epoch 153/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8672\n",
      "Epoch 153: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8672 - val_loss: 0.2104 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.7713\n",
      "Epoch 154/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8660\n",
      "Epoch 154: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8658 - val_loss: 0.2096 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8136\n",
      "Epoch 155/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8648\n",
      "Epoch 155: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8642 - val_loss: 0.2117 - val_mse_loss_fn: 0.0343 - val_kl_loss_fn: 17.7815\n",
      "Epoch 156/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8642\n",
      "Epoch 156: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8643 - val_loss: 0.2110 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.7944\n",
      "Epoch 157/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8645\n",
      "Epoch 157: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8642 - val_loss: 0.2097 - val_mse_loss_fn: 0.0315 - val_kl_loss_fn: 17.8421\n",
      "Epoch 158/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8686\n",
      "Epoch 158: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8681 - val_loss: 0.2099 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.7849\n",
      "Epoch 159/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8631\n",
      "Epoch 159: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8633 - val_loss: 0.2106 - val_mse_loss_fn: 0.0331 - val_kl_loss_fn: 17.7899\n",
      "Epoch 160/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8674\n",
      "Epoch 160: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8675 - val_loss: 0.2118 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8258\n",
      "Epoch 161/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8670\n",
      "Epoch 161: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8674 - val_loss: 0.2094 - val_mse_loss_fn: 0.0316 - val_kl_loss_fn: 17.8152\n",
      "Epoch 162/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8676\n",
      "Epoch 162: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8674 - val_loss: 0.2104 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.8078\n",
      "Epoch 163/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8611\n",
      "Epoch 163: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8611 - val_loss: 0.2120 - val_mse_loss_fn: 0.0341 - val_kl_loss_fn: 17.8179\n",
      "Epoch 164/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8644\n",
      "Epoch 164: val_loss did not improve from 0.20938\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8640 - val_loss: 0.2107 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.8005\n",
      "Epoch 165/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8603\n",
      "Epoch 165: val_loss improved from 0.20938 to 0.20937, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8604 - val_loss: 0.2094 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.7867\n",
      "Epoch 166/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8660\n",
      "Epoch 166: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8656 - val_loss: 0.2114 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.7855\n",
      "Epoch 167/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8635\n",
      "Epoch 167: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8643 - val_loss: 0.2097 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8158\n",
      "Epoch 168/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8595\n",
      "Epoch 168: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8599 - val_loss: 0.2110 - val_mse_loss_fn: 0.0330 - val_kl_loss_fn: 17.8336\n",
      "Epoch 169/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8636\n",
      "Epoch 169: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8638 - val_loss: 0.2119 - val_mse_loss_fn: 0.0340 - val_kl_loss_fn: 17.8235\n",
      "Epoch 170/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8630\n",
      "Epoch 170: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8638 - val_loss: 0.2099 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8335\n",
      "Epoch 171/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8619\n",
      "Epoch 171: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8625 - val_loss: 0.2109 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8054\n",
      "Epoch 172/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8640\n",
      "Epoch 172: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8637 - val_loss: 0.2111 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8233\n",
      "Epoch 173/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8680\n",
      "Epoch 173: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8678 - val_loss: 0.2099 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.7864\n",
      "Epoch 174/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8638\n",
      "Epoch 174: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8638 - val_loss: 0.2109 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8421\n",
      "Epoch 175/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8652\n",
      "Epoch 175: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8652 - val_loss: 0.2096 - val_mse_loss_fn: 0.0316 - val_kl_loss_fn: 17.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8612\n",
      "Epoch 176: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8613 - val_loss: 0.2113 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.8144\n",
      "Epoch 177/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8582\n",
      "Epoch 177: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8591 - val_loss: 0.2106 - val_mse_loss_fn: 0.0328 - val_kl_loss_fn: 17.8198\n",
      "Epoch 178/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8608\n",
      "Epoch 178: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8608 - val_loss: 0.2110 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.7759\n",
      "Epoch 179/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8636\n",
      "Epoch 179: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8627 - val_loss: 0.2099 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.7798\n",
      "Epoch 180/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8613\n",
      "Epoch 180: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8608 - val_loss: 0.2109 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.7862\n",
      "Epoch 181/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8632\n",
      "Epoch 181: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8631 - val_loss: 0.2160 - val_mse_loss_fn: 0.0383 - val_kl_loss_fn: 17.8042\n",
      "Epoch 182/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8593\n",
      "Epoch 182: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8594 - val_loss: 0.2099 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8040\n",
      "Epoch 183/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8623\n",
      "Epoch 183: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8623 - val_loss: 0.2097 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8184\n",
      "Epoch 184/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8586\n",
      "Epoch 184: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8586 - val_loss: 0.2103 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.8108\n",
      "Epoch 185/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8583\n",
      "Epoch 185: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8585 - val_loss: 0.2108 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.8222\n",
      "Epoch 186/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8625\n",
      "Epoch 186: val_loss did not improve from 0.20937\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8625 - val_loss: 0.2100 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8091\n",
      "Epoch 187/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8644\n",
      "Epoch 187: val_loss improved from 0.20937 to 0.20933, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8644 - val_loss: 0.2093 - val_mse_loss_fn: 0.0316 - val_kl_loss_fn: 17.8078\n",
      "Epoch 188/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8656\n",
      "Epoch 188: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8654 - val_loss: 0.2095 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.7920\n",
      "Epoch 189/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8619\n",
      "Epoch 189: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8620 - val_loss: 0.2095 - val_mse_loss_fn: 0.0317 - val_kl_loss_fn: 17.8068\n",
      "Epoch 190/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8600\n",
      "Epoch 190: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8605 - val_loss: 0.2114 - val_mse_loss_fn: 0.0334 - val_kl_loss_fn: 17.8337\n",
      "Epoch 191/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8587\n",
      "Epoch 191: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8587 - val_loss: 0.2094 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.7888\n",
      "Epoch 192/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8603\n",
      "Epoch 192: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8604 - val_loss: 0.2099 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8146\n",
      "Epoch 193/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8599\n",
      "Epoch 193: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8594 - val_loss: 0.2099 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.7909\n",
      "Epoch 194/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8579\n",
      "Epoch 194: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8580 - val_loss: 0.2107 - val_mse_loss_fn: 0.0327 - val_kl_loss_fn: 17.8364\n",
      "Epoch 195/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8618\n",
      "Epoch 195: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8617 - val_loss: 0.2117 - val_mse_loss_fn: 0.0338 - val_kl_loss_fn: 17.8170\n",
      "Epoch 196/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8557\n",
      "Epoch 196: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8556 - val_loss: 0.2096 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8004\n",
      "Epoch 197/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8637\n",
      "Epoch 197: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8636 - val_loss: 0.2099 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.7957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2096 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8615\n",
      "Epoch 198: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2096 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8620 - val_loss: 0.2098 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.8112\n",
      "Epoch 199/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8585\n",
      "Epoch 199: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8582 - val_loss: 0.2105 - val_mse_loss_fn: 0.0329 - val_kl_loss_fn: 17.7929\n",
      "Epoch 200/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8584\n",
      "Epoch 200: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8583 - val_loss: 0.2099 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.7892\n",
      "Epoch 201/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8591\n",
      "Epoch 201: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8590 - val_loss: 0.2127 - val_mse_loss_fn: 0.0350 - val_kl_loss_fn: 17.8046\n",
      "Epoch 202/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8584\n",
      "Epoch 202: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8583 - val_loss: 0.2098 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8187\n",
      "Epoch 203/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8561\n",
      "Epoch 203: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8566 - val_loss: 0.2100 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8215\n",
      "Epoch 204/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8560\n",
      "Epoch 204: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8560 - val_loss: 0.2101 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8090\n",
      "Epoch 205/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8579\n",
      "Epoch 205: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8577 - val_loss: 0.2097 - val_mse_loss_fn: 0.0317 - val_kl_loss_fn: 17.8241\n",
      "Epoch 206/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8562\n",
      "Epoch 206: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8570 - val_loss: 0.2101 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.8368\n",
      "Epoch 207/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8580\n",
      "Epoch 207: val_loss did not improve from 0.20933\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8581 - val_loss: 0.2097 - val_mse_loss_fn: 0.0318 - val_kl_loss_fn: 17.8158\n",
      "Epoch 208/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8566\n",
      "Epoch 208: val_loss improved from 0.20933 to 0.20927, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8567 - val_loss: 0.2093 - val_mse_loss_fn: 0.0315 - val_kl_loss_fn: 17.8056\n",
      "Epoch 209/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8537\n",
      "Epoch 209: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8536 - val_loss: 0.2110 - val_mse_loss_fn: 0.0333 - val_kl_loss_fn: 17.8065\n",
      "Epoch 210/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8583\n",
      "Epoch 210: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 7s 13us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8588 - val_loss: 0.2114 - val_mse_loss_fn: 0.0337 - val_kl_loss_fn: 17.8032\n",
      "Epoch 211/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8571\n",
      "Epoch 211: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8568 - val_loss: 0.2110 - val_mse_loss_fn: 0.0332 - val_kl_loss_fn: 17.8209\n",
      "Epoch 212/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8538\n",
      "Epoch 212: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8537 - val_loss: 0.2111 - val_mse_loss_fn: 0.0338 - val_kl_loss_fn: 17.7655\n",
      "Epoch 213/240\n",
      "499889/499889 [==============================] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8579\n",
      "Epoch 213: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8579 - val_loss: 0.2100 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8057\n",
      "Epoch 214/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8555\n",
      "Epoch 214: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8556 - val_loss: 0.2097 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8055\n",
      "Epoch 215/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8574\n",
      "Epoch 215: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8575 - val_loss: 0.2113 - val_mse_loss_fn: 0.0335 - val_kl_loss_fn: 17.8183\n",
      "Epoch 216/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8533\n",
      "Epoch 216: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 7us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8535 - val_loss: 0.2117 - val_mse_loss_fn: 0.0339 - val_kl_loss_fn: 17.8095\n",
      "Epoch 217/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8580\n",
      "Epoch 217: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8580 - val_loss: 0.2097 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.7923\n",
      "Epoch 218/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8570\n",
      "Epoch 218: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8567 - val_loss: 0.2095 - val_mse_loss_fn: 0.0317 - val_kl_loss_fn: 17.8078\n",
      "Epoch 219/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8563\n",
      "Epoch 219: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8559 - val_loss: 0.2098 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.8194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/240\n",
      "493568/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8578\n",
      "Epoch 220: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8575 - val_loss: 0.2095 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.7904\n",
      "Epoch 221/240\n",
      "492544/499889 [============================>.] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8554\n",
      "Epoch 221: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8558 - val_loss: 0.2101 - val_mse_loss_fn: 0.0323 - val_kl_loss_fn: 17.8087\n",
      "Epoch 222/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8527\n",
      "Epoch 222: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8525 - val_loss: 0.2097 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.7894\n",
      "Epoch 223/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8553\n",
      "Epoch 223: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8556 - val_loss: 0.2097 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.7939\n",
      "Epoch 224/240\n",
      "488448/499889 [============================>.] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8540\n",
      "Epoch 224: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8538 - val_loss: 0.2093 - val_mse_loss_fn: 0.0317 - val_kl_loss_fn: 17.7947\n",
      "Epoch 225/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8587\n",
      "Epoch 225: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8585 - val_loss: 0.2100 - val_mse_loss_fn: 0.0325 - val_kl_loss_fn: 17.7798\n",
      "Epoch 226/240\n",
      "499712/499889 [============================>.] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8536\n",
      "Epoch 226: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8535 - val_loss: 0.2100 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.7704\n",
      "Epoch 227/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8567\n",
      "Epoch 227: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8567 - val_loss: 0.2101 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.7965\n",
      "Epoch 228/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8566\n",
      "Epoch 228: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8565 - val_loss: 0.2100 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.7792\n",
      "Epoch 229/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8557\n",
      "Epoch 229: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8560 - val_loss: 0.2101 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8283\n",
      "Epoch 230/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8572\n",
      "Epoch 230: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8566 - val_loss: 0.2099 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.8075\n",
      "Epoch 231/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8548\n",
      "Epoch 231: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8546 - val_loss: 0.2102 - val_mse_loss_fn: 0.0326 - val_kl_loss_fn: 17.7940\n",
      "Epoch 232/240\n",
      "498688/499889 [============================>.] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8529\n",
      "Epoch 232: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8529 - val_loss: 0.2098 - val_mse_loss_fn: 0.0322 - val_kl_loss_fn: 17.7953\n",
      "Epoch 233/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8584\n",
      "Epoch 233: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8583 - val_loss: 0.2096 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.7990\n",
      "Epoch 234/240\n",
      "497664/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8559\n",
      "Epoch 234: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8562 - val_loss: 0.2096 - val_mse_loss_fn: 0.0319 - val_kl_loss_fn: 17.7979\n",
      "Epoch 235/240\n",
      "496640/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8550\n",
      "Epoch 235: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8555 - val_loss: 0.2101 - val_mse_loss_fn: 0.0321 - val_kl_loss_fn: 17.8232\n",
      "Epoch 236/240\n",
      "494592/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8575\n",
      "Epoch 236: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8575 - val_loss: 0.2098 - val_mse_loss_fn: 0.0320 - val_kl_loss_fn: 17.8079\n",
      "Epoch 237/240\n",
      "489472/499889 [============================>.] - ETA: 0s - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8526\n",
      "Epoch 237: val_loss did not improve from 0.20927\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0311 - kl_loss_fn: 17.8524 - val_loss: 0.2101 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.7998\n",
      "Epoch 238/240\n",
      "490496/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8556\n",
      "Epoch 238: val_loss improved from 0.20927 to 0.20923, saving model to outputs/models/z6_smallModel_02-12-2022/cbvae_LHCO2020_20d_e-6.hdf5\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2094 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8558 - val_loss: 0.2092 - val_mse_loss_fn: 0.0313 - val_kl_loss_fn: 17.8285\n",
      "Epoch 239/240\n",
      "491520/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8552\n",
      "Epoch 239: val_loss did not improve from 0.20923\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0312 - kl_loss_fn: 17.8552 - val_loss: 0.2123 - val_mse_loss_fn: 0.0350 - val_kl_loss_fn: 17.7647\n",
      "Epoch 240/240\n",
      "495616/499889 [============================>.] - ETA: 0s - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8521\n",
      "Epoch 240: val_loss did not improve from 0.20923\n",
      "499889/499889 [==============================] - 3s 6us/sample - loss: 0.2095 - mse_loss_fn: 0.0313 - kl_loss_fn: 17.8522 - val_loss: 0.2098 - val_mse_loss_fn: 0.0324 - val_kl_loss_fn: 17.7655\n"
     ]
    }
   ],
   "source": [
    "list_loss = []\n",
    "list_val_loss = [] \n",
    "\n",
    "while learnrate > lr_limit:\n",
    "    if k < 4:\n",
    "        opt = Adam(learning_rate=learnrate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "        epochs = epochs_1\n",
    "    else:\n",
    "        opt = SGD(learning_rate=learnrate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        epochs = epochs_2\n",
    "    cvae.compile(loss=vae_loss, optimizer=opt, metrics=[mse_loss_fn, kl_loss_fn])\n",
    "    cvae.fit([x_train, y_train], x_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=([x_test, y_test], x_test),\n",
    "            callbacks = [checkpointer, history, decoderSaver])\n",
    "    cvae.load_weights('outputs/models/%s/cbvae_LHCO2020_20d_e-6.hdf5'%(folder_name))\n",
    "\n",
    "    learnrate /= 2\n",
    "    k=k+1\n",
    "\n",
    "list_loss = np.append(list_loss, history.history['loss'])\n",
    "list_val_loss = np.append(list_val_loss, history.history['val_loss'])\n",
    "    \n",
    "# train the autoencoder\n",
    "cvae.save_weights('outputs/models/%s/cbvae_LHCO2020_20d_e-6.h5'%(folder_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ce97743-819f-4ad7-b265-863d798240d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/cfs/projectdirs/atlas/elham/conda/lib/python3.8/site-packages/keras/engine/training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "# Predict the mean and std from the training dataset\n",
    "# latent mean\n",
    "latent_mean = encoder.predict([x_train, y_train])[0]\n",
    "# latent log variance --> variance --> std\n",
    "latent_logvar = encoder.predict([x_train, y_train])[1]\n",
    "latent_var = np.exp(latent_logvar)\n",
    "latent_std = np.sqrt(latent_var)\n",
    "\n",
    "# Save the latent mean and atd values\n",
    "np.savetxt('outputs/models/%s/cbvae_LHCO2020_latent_mean_20d_e-6.csv'%folder_name, latent_mean)\n",
    "np.savetxt('outputs/models/%s/cbvae_LHCO2020_latent_std_20d_e-6.csv'%folder_name, latent_std)\n",
    "\n",
    "# Save the loss values\n",
    "np.save(\"outputs/models/%s/cbvae_LHCO2020_val_loss.npy\"%folder_name, list_val_loss)\n",
    "np.save(\"outputs/models/%s/cbvae_LHCO2020_train_loss.npy\"%folder_name, list_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd46642a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.44878777, 0.39771963, 0.3751677 , 0.35092922, 0.33497851,\n",
       "       0.31206627, 0.38703952, 0.31556758, 0.31097482, 0.29695632,\n",
       "       0.2948337 , 0.30349879, 0.28738432, 0.29035154, 0.30063606,\n",
       "       0.28417653, 0.28904413, 0.36474683, 0.31934964, 0.30763028,\n",
       "       0.27642078, 0.26232924, 0.30331878, 0.27517328, 0.27721729,\n",
       "       0.29564568, 0.29738049, 0.28267259, 0.24986311, 0.25816242,\n",
       "       0.27683339, 0.27688566, 0.25212226, 0.25394825, 0.26239371,\n",
       "       0.24757256, 0.28879086, 0.2393936 , 0.24085919, 0.26693329,\n",
       "       0.22971952, 0.2287277 , 0.25815253, 0.25915465, 0.24033146,\n",
       "       0.28054477, 0.23588254, 0.25699037, 0.2222717 , 0.23449427,\n",
       "       0.2325394 , 0.23069464, 0.22336635, 0.22883094, 0.23981587,\n",
       "       0.22774893, 0.24837769, 0.2340351 , 0.23024131, 0.22577997,\n",
       "       0.21588705, 0.22929635, 0.22515472, 0.26539125, 0.22455748,\n",
       "       0.25766193, 0.22287168, 0.24829821, 0.22002447, 0.23166081,\n",
       "       0.24540803, 0.22965476, 0.22891782, 0.22232464, 0.2346642 ,\n",
       "       0.24372842, 0.23212004, 0.22817732, 0.21433536, 0.22825286,\n",
       "       0.23726109, 0.24545265, 0.22086745, 0.21837104, 0.22168561,\n",
       "       0.22141504, 0.22220224, 0.22258805, 0.21318105, 0.2221022 ,\n",
       "       0.21822335, 0.23629155, 0.2238858 , 0.22115905, 0.22150021,\n",
       "       0.21750158, 0.22056117, 0.22346652, 0.23263595, 0.22605946,\n",
       "       0.2396046 , 0.22984301, 0.22471844, 0.21455601, 0.22674716,\n",
       "       0.23126109, 0.25018579, 0.22039414, 0.2151372 , 0.24740696,\n",
       "       0.21848758, 0.22353745, 0.21636024, 0.24493246, 0.2230026 ,\n",
       "       0.22034443, 0.21532447, 0.21824616, 0.21558368, 0.2181874 ,\n",
       "       0.22003133, 0.22191282, 0.21958738, 0.21753396, 0.22224969,\n",
       "       0.24572976, 0.22010117, 0.21938746, 0.22778842, 0.23308557,\n",
       "       0.22156478, 0.21337129, 0.2263434 , 0.21348055, 0.21409393,\n",
       "       0.21332886, 0.22624014, 0.21431426, 0.2296241 , 0.23142233,\n",
       "       0.22066144, 0.23082294, 0.2184404 , 0.22457859, 0.22115408,\n",
       "       0.22137887, 0.23787357, 0.21595581, 0.22024672, 0.22021934,\n",
       "       0.21735614, 0.22323057, 0.21858344, 0.21767218, 0.24305177,\n",
       "       0.2197258 , 0.21745251, 0.22056008, 0.22231685, 0.21978092,\n",
       "       0.21314028, 0.22515724, 0.23477938, 0.22359522, 0.21867107,\n",
       "       0.21716037, 0.23782838, 0.2212214 , 0.21923378, 0.22922776,\n",
       "       0.22032375, 0.21306984, 0.2216516 , 0.22504152, 0.21726045,\n",
       "       0.23059521, 0.21751548, 0.22041203, 0.23202505, 0.21691842,\n",
       "       0.21811014, 0.22552143, 0.21549385, 0.22147633, 0.22450129,\n",
       "       0.22186703, 0.23233488, 0.22378467, 0.22041077, 0.21308795,\n",
       "       0.21548945, 0.23450332, 0.2259575 , 0.21922789, 0.21457202,\n",
       "       0.21217454, 0.22662883, 0.22616994, 0.21186384, 0.22248801,\n",
       "       0.21677217, 0.22481216, 0.22227254, 0.2129358 , 0.21253239,\n",
       "       0.21796625, 0.22569807, 0.21833335, 0.21453941, 0.22765943,\n",
       "       0.22485052, 0.21398224, 0.2218743 , 0.21933937, 0.21991987,\n",
       "       0.21463381, 0.21810962, 0.23002812, 0.21922291, 0.2163746 ,\n",
       "       0.21227262, 0.21723915, 0.22123034, 0.23813136, 0.2121224 ,\n",
       "       0.21384492, 0.21838706, 0.21557964, 0.21538979, 0.21281051,\n",
       "       0.22418443, 0.21832381, 0.22476688, 0.21650127, 0.22676647,\n",
       "       0.21990906, 0.21588237, 0.21888489, 0.22599619, 0.21703474,\n",
       "       0.2122602 , 0.21306149, 0.21397168, 0.21508588, 0.21763807,\n",
       "       0.21083799, 0.21172045, 0.21218193, 0.21124415, 0.21148675,\n",
       "       0.21085903, 0.21178729, 0.2149056 , 0.21394112, 0.21454681,\n",
       "       0.2148855 , 0.21370839, 0.21407162, 0.21366896, 0.21436955,\n",
       "       0.21898762, 0.21321782, 0.21179042, 0.21364584, 0.21099851,\n",
       "       0.21275257, 0.21505102, 0.21133275, 0.21235295, 0.21523355,\n",
       "       0.21614662, 0.21295475, 0.21420187, 0.21953917, 0.21392362,\n",
       "       0.21077592, 0.21092631, 0.21196003, 0.21162184, 0.21064165,\n",
       "       0.21317178, 0.21865454, 0.21377906, 0.21158021, 0.21256088,\n",
       "       0.21199651, 0.21706955, 0.2118104 , 0.21342965, 0.21134957,\n",
       "       0.21712485, 0.21239924, 0.21038539, 0.21196554, 0.22030453,\n",
       "       0.2104655 , 0.21273423, 0.21353454, 0.21283843, 0.21654721,\n",
       "       0.2149132 , 0.21183282, 0.21293231, 0.21019106, 0.2109281 ,\n",
       "       0.21603299, 0.21162277, 0.21357113, 0.21067361, 0.2118485 ,\n",
       "       0.2134948 , 0.21839505, 0.21676933, 0.21206491, 0.21056878,\n",
       "       0.21399899, 0.21292764, 0.21063953, 0.21359716, 0.21136795,\n",
       "       0.21619583, 0.21295108, 0.21417228, 0.21513454, 0.21324388,\n",
       "       0.21595907, 0.21129953, 0.21326234, 0.21208154, 0.2134055 ,\n",
       "       0.21225766, 0.21469271, 0.21366712, 0.21800379, 0.21408071,\n",
       "       0.21223696, 0.2154956 , 0.21252142, 0.21340636, 0.21693105,\n",
       "       0.2129854 , 0.21307145, 0.21238208, 0.21201006, 0.21545918,\n",
       "       0.21061898, 0.2147691 , 0.21394677, 0.21359634, 0.21144567,\n",
       "       0.21031572, 0.21390158, 0.2116576 , 0.21227306, 0.2121387 ,\n",
       "       0.21464466, 0.21315958, 0.21324379, 0.2139082 , 0.21289032,\n",
       "       0.21653447, 0.21257148, 0.2127995 , 0.21168524, 0.21200267,\n",
       "       0.21145999, 0.21360622, 0.21095916, 0.21360468, 0.2119392 ,\n",
       "       0.21428263, 0.21161237, 0.2118058 , 0.21103557, 0.21197742,\n",
       "       0.21235526, 0.21053901, 0.21093573, 0.21469463, 0.2114483 ,\n",
       "       0.2145144 , 0.21332533, 0.21762231, 0.21088732, 0.2126072 ,\n",
       "       0.21344139, 0.21664168, 0.21105663, 0.21276575, 0.21266449,\n",
       "       0.21228384, 0.21771214, 0.21188525, 0.21075638, 0.2135933 ,\n",
       "       0.21979589, 0.21363582, 0.21655207, 0.21104973, 0.21217658,\n",
       "       0.21354671, 0.21160086, 0.21126456, 0.21042536, 0.21298364,\n",
       "       0.21164751, 0.21198652, 0.21203534, 0.21196171, 0.21482715,\n",
       "       0.2107406 , 0.21684526, 0.21560167, 0.21010029, 0.21238159,\n",
       "       0.21172826, 0.21751614, 0.21353329, 0.21606359, 0.21448356,\n",
       "       0.21241701, 0.2120096 , 0.21257049, 0.21780262, 0.2137475 ,\n",
       "       0.21243644, 0.21097484, 0.21167076, 0.21073559, 0.21189791,\n",
       "       0.21610725, 0.21184522, 0.21317267, 0.21436463, 0.21187338,\n",
       "       0.21669888, 0.21058045, 0.21671773, 0.21462403, 0.21188623,\n",
       "       0.21068096, 0.21039254, 0.21211258, 0.21325995, 0.21216589,\n",
       "       0.21293116, 0.21384067, 0.21740002, 0.21218878, 0.213079  ,\n",
       "       0.21374211, 0.21165129, 0.21142625, 0.21133875, 0.22059486,\n",
       "       0.21164796, 0.21951846, 0.21274874, 0.21003576, 0.21188684,\n",
       "       0.21066073, 0.21915   , 0.21243912, 0.21000177, 0.20963151,\n",
       "       0.21437957, 0.21043976, 0.2109576 , 0.21077261, 0.21493741,\n",
       "       0.21455632, 0.21279528, 0.21472375, 0.21086926, 0.21269843,\n",
       "       0.21034588, 0.21314482, 0.2108506 , 0.21033381, 0.21440075,\n",
       "       0.21022734, 0.21112897, 0.21131284, 0.21135538, 0.2099596 ,\n",
       "       0.21118241, 0.20982019, 0.20993997, 0.21142752, 0.21053407,\n",
       "       0.21069094, 0.21010799, 0.2103929 , 0.21052046, 0.21043635,\n",
       "       0.20977776, 0.21056401, 0.20967949, 0.21122581, 0.20975895,\n",
       "       0.2103092 , 0.21077435, 0.20978637, 0.21068155, 0.2123196 ,\n",
       "       0.2102286 , 0.21062587, 0.21189952, 0.21066823, 0.21001632,\n",
       "       0.21035312, 0.2109191 , 0.21121664, 0.21094528, 0.21016587,\n",
       "       0.21013406, 0.20937852, 0.21155676, 0.21073147, 0.21088225,\n",
       "       0.21143736, 0.20949096, 0.21072494, 0.21158022, 0.21028589,\n",
       "       0.21031969, 0.21104653, 0.21021673, 0.20985334, 0.21013281,\n",
       "       0.20990029, 0.21154136, 0.21112074, 0.2098091 , 0.21038034,\n",
       "       0.21035256, 0.21138698, 0.21055744, 0.21096352, 0.21106897,\n",
       "       0.2104071 , 0.21009014, 0.21214835, 0.20965403, 0.20999185,\n",
       "       0.2103763 , 0.21043246, 0.21017557, 0.21009615, 0.20955322,\n",
       "       0.21157997, 0.21042685, 0.21211191, 0.21183003, 0.21171074,\n",
       "       0.20980184, 0.21130366, 0.20993293, 0.21039888, 0.21159555,\n",
       "       0.21012343, 0.21180494, 0.21057156, 0.20953313, 0.21213156,\n",
       "       0.21073423, 0.21063639, 0.20991142, 0.21246339, 0.21025922,\n",
       "       0.21076181, 0.21097585, 0.21046716, 0.21329147, 0.20979394,\n",
       "       0.21118361, 0.20998098, 0.2103274 , 0.2119873 , 0.21009057,\n",
       "       0.21112339, 0.21107414, 0.21053241, 0.20966285, 0.2105788 ,\n",
       "       0.21209898, 0.21039596, 0.20964881, 0.20959   , 0.2098745 ,\n",
       "       0.21163154, 0.2096351 , 0.20942925, 0.21027944, 0.21079234,\n",
       "       0.20951005, 0.20959575, 0.21220067, 0.21051355, 0.20963646,\n",
       "       0.20998437, 0.21152931, 0.21099183, 0.21172418, 0.21031416,\n",
       "       0.21202797, 0.20942832, 0.21071728, 0.21105147, 0.20970179,\n",
       "       0.21046822, 0.20999376, 0.21015539, 0.20965926, 0.21002285,\n",
       "       0.20998339, 0.21058069, 0.20996055, 0.21076644, 0.21017336,\n",
       "       0.21003275, 0.21082759, 0.20950013, 0.2122946 , 0.21002293,\n",
       "       0.20995621, 0.20977218, 0.21015677, 0.21132553, 0.21038367,\n",
       "       0.21094953, 0.21010318, 0.21040416, 0.20959459, 0.21174336,\n",
       "       0.21101389, 0.20965103, 0.20988457, 0.21063906, 0.21182842,\n",
       "       0.20943953, 0.21036514, 0.21197454, 0.21066187, 0.2093706 ,\n",
       "       0.21140472, 0.20968732, 0.21102486, 0.21192039, 0.20985199,\n",
       "       0.21090071, 0.21108331, 0.20989438, 0.21087738, 0.20961333,\n",
       "       0.21130318, 0.21063498, 0.21095965, 0.20991643, 0.21092556,\n",
       "       0.21598797, 0.20992379, 0.20974007, 0.21028401, 0.21081495,\n",
       "       0.20996199, 0.20933143, 0.20953743, 0.20946526, 0.2114402 ,\n",
       "       0.20944745, 0.20991799, 0.20986448, 0.21070123, 0.2116749 ,\n",
       "       0.20960847, 0.20994635, 0.20978156, 0.21054787, 0.2099148 ,\n",
       "       0.2127057 , 0.209798  , 0.20998856, 0.21007129, 0.20966579,\n",
       "       0.21009063, 0.20967281, 0.2092694 , 0.21102188, 0.2114426 ,\n",
       "       0.21103034, 0.21110242, 0.20999208, 0.20966739, 0.21134619,\n",
       "       0.21166147, 0.20968697, 0.20950977, 0.20977298, 0.20952746,\n",
       "       0.21010531, 0.20972247, 0.2096723 , 0.20934053, 0.21000092,\n",
       "       0.20997099, 0.21008962, 0.21004344, 0.21006494, 0.2099126 ,\n",
       "       0.21017206, 0.20978923, 0.20956766, 0.20960632, 0.2100524 ,\n",
       "       0.20976978, 0.21005298, 0.20922567, 0.21230018, 0.20977776])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44eb99e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.278681783907617,\n",
       " 0.8296730808763605,\n",
       " 0.36899187236896663,\n",
       " 0.33845826936073514,\n",
       " 0.32466064385689547,\n",
       " 0.3156884111949358,\n",
       " 0.3103427709637853,\n",
       " 0.30765561189510054,\n",
       " 0.30137028253438386,\n",
       " 0.2996458234442568,\n",
       " 0.29500199044628983,\n",
       " 0.29328499526719837,\n",
       " 0.290397999525488,\n",
       " 0.2878762136436223,\n",
       " 0.2852416436561498,\n",
       " 0.282608470999165,\n",
       " 0.2799879879362657,\n",
       " 0.2789075015700355,\n",
       " 0.27827135735884445,\n",
       " 0.27333695917340955,\n",
       " 0.27166369593491224,\n",
       " 0.2685873761206054,\n",
       " 0.2665443572862018,\n",
       " 0.26523757158479777,\n",
       " 0.2611159124906901,\n",
       " 0.2589798917819063,\n",
       " 0.25750073596497014,\n",
       " 0.25492993288453514,\n",
       " 0.252474549281723,\n",
       " 0.24958284844938214,\n",
       " 0.24772592800098286,\n",
       " 0.24630876141703384,\n",
       " 0.24422232044256348,\n",
       " 0.24264915124773617,\n",
       " 0.24026492997633167,\n",
       " 0.23966400890720244,\n",
       " 0.23666467577192002,\n",
       " 0.23649889202016178,\n",
       " 0.23374078558089073,\n",
       " 0.2329941704395338,\n",
       " 0.23259171074797919,\n",
       " 0.23012795187962673,\n",
       " 0.22924769374023288,\n",
       " 0.22917634444363633,\n",
       " 0.22800468529123782,\n",
       " 0.22619803035235447,\n",
       " 0.22675224181239845,\n",
       " 0.22361124247083194,\n",
       " 0.2241497130656148,\n",
       " 0.2223356944400292,\n",
       " 0.22235942189128735,\n",
       " 0.22187046605278393,\n",
       " 0.2204285192057907,\n",
       " 0.2202620948043188,\n",
       " 0.22011310070951445,\n",
       " 0.22000391186999463,\n",
       " 0.2193526694519017,\n",
       " 0.21897131278802534,\n",
       " 0.219227256453525,\n",
       " 0.21802496013686734,\n",
       " 0.21810207078906726,\n",
       " 0.21790382242331605,\n",
       " 0.2177638152634547,\n",
       " 0.21762643204996193,\n",
       " 0.21914547514598204,\n",
       " 0.21714491852016402,\n",
       " 0.21781494255547645,\n",
       " 0.2165274805847525,\n",
       " 0.21828943930672862,\n",
       " 0.2167014527485562,\n",
       " 0.21683528002480423,\n",
       " 0.21755111659085435,\n",
       " 0.21634295380311963,\n",
       " 0.2164694881661536,\n",
       " 0.21676864520114242,\n",
       " 0.216379896200506,\n",
       " 0.21658324859550562,\n",
       " 0.21626040524404574,\n",
       " 0.21635280149129552,\n",
       " 0.21589916199885406,\n",
       " 0.2159749068176461,\n",
       " 0.21635178527034102,\n",
       " 0.21602890162846206,\n",
       " 0.21546116836354715,\n",
       " 0.2157426043058378,\n",
       " 0.21521898833322012,\n",
       " 0.21584414343567607,\n",
       " 0.21549945441717563,\n",
       " 0.21562038562384023,\n",
       " 0.21487769705147847,\n",
       " 0.21561522194198446,\n",
       " 0.21540914109661333,\n",
       " 0.21535959676283056,\n",
       " 0.2152137370046151,\n",
       " 0.215079264831416,\n",
       " 0.2147136725620404,\n",
       " 0.21516622546478492,\n",
       " 0.21497690014906623,\n",
       " 0.21494653237535172,\n",
       " 0.21511709896884573,\n",
       " 0.21460700915803327,\n",
       " 0.2149891054482737,\n",
       " 0.2150407529409956,\n",
       " 0.2139933187359917,\n",
       " 0.21447315122218755,\n",
       " 0.21473479298621603,\n",
       " 0.21464863603105172,\n",
       " 0.21506214480493147,\n",
       " 0.21413446183299814,\n",
       " 0.2142905792842783,\n",
       " 0.21492985630962624,\n",
       " 0.2140110275994232,\n",
       " 0.2147002750432196,\n",
       " 0.2139710347475964,\n",
       " 0.21469485273950736,\n",
       " 0.21384404556240932,\n",
       " 0.21405988853866473,\n",
       " 0.21399240016515997,\n",
       " 0.2140386164974566,\n",
       " 0.21411900052789964,\n",
       " 0.21381206150543217,\n",
       " 0.2141895839917516,\n",
       " 0.21390417791180852,\n",
       " 0.21412000025619365,\n",
       " 0.21357436432902904,\n",
       " 0.21381905413205932,\n",
       " 0.21430261350142416,\n",
       " 0.21341843706018693,\n",
       " 0.21390161640035413,\n",
       " 0.21415347602931487,\n",
       " 0.21367476502110988,\n",
       " 0.21365461357778362,\n",
       " 0.21356989644691354,\n",
       " 0.21385244621524016,\n",
       " 0.21360010974357674,\n",
       " 0.21358138439803462,\n",
       " 0.2133010099438095,\n",
       " 0.21369255750055557,\n",
       " 0.21369023238171567,\n",
       " 0.21355951335216933,\n",
       " 0.2134490932708981,\n",
       " 0.2135727783744252,\n",
       " 0.2135259735355541,\n",
       " 0.21315083367399112,\n",
       " 0.21355831077722837,\n",
       " 0.21325336263296196,\n",
       " 0.2135642713284201,\n",
       " 0.21344821233829459,\n",
       " 0.21315674479423988,\n",
       " 0.2132965052271744,\n",
       " 0.21319324110012414,\n",
       " 0.21333060758466094,\n",
       " 0.21337454863949995,\n",
       " 0.21307303452843077,\n",
       " 0.2133518888713503,\n",
       " 0.21361258455438303,\n",
       " 0.21292875575853049,\n",
       " 0.21312887535571723,\n",
       " 0.21323954474337234,\n",
       " 0.21307445433682662,\n",
       " 0.2131706331848342,\n",
       " 0.21298699461371715,\n",
       " 0.2133265618974127,\n",
       " 0.21305502270219556,\n",
       " 0.21321363108123542,\n",
       " 0.2128049247089428,\n",
       " 0.21315638860226785,\n",
       " 0.21334835304995325,\n",
       " 0.21304782029071181,\n",
       " 0.21253595094126992,\n",
       " 0.21314048092814603,\n",
       " 0.2130307805129342,\n",
       " 0.21282307250549795,\n",
       " 0.21304187661182722,\n",
       " 0.21289767566153317,\n",
       " 0.21279759768091722,\n",
       " 0.21321546963915147,\n",
       " 0.21275262757434243,\n",
       " 0.2129958962173799,\n",
       " 0.21275737159544852,\n",
       " 0.2128602508076159,\n",
       " 0.2127291211431986,\n",
       " 0.2128175755934668,\n",
       " 0.21263983227133518,\n",
       " 0.21292636333980833,\n",
       " 0.2128545846964942,\n",
       " 0.2128341809367668,\n",
       " 0.21294704778883125,\n",
       " 0.21285329415468576,\n",
       " 0.2127516981483169,\n",
       " 0.21304352886258668,\n",
       " 0.21279363525993492,\n",
       " 0.21282480142046908,\n",
       " 0.2125563547985024,\n",
       " 0.21279778181574735,\n",
       " 0.21261824888180023,\n",
       " 0.21265394724474976,\n",
       " 0.21287293926481826,\n",
       " 0.21286274335412028,\n",
       " 0.2122806451615096,\n",
       " 0.21269371443959217,\n",
       " 0.21248347211024055,\n",
       " 0.21294794680630996,\n",
       " 0.21227498092396924,\n",
       " 0.21274520084927379,\n",
       " 0.2124509487939492,\n",
       " 0.2126410766320607,\n",
       " 0.21269418262366224,\n",
       " 0.21255492056946546,\n",
       " 0.21235746932395205,\n",
       " 0.2129743257262329,\n",
       " 0.21252622684322464,\n",
       " 0.21236722021635923,\n",
       " 0.2127917154088961,\n",
       " 0.2125466027522806,\n",
       " 0.2121535996271419,\n",
       " 0.2124960897048856,\n",
       " 0.212750364363186,\n",
       " 0.21253668099210823,\n",
       " 0.21259883232572338,\n",
       " 0.21253157801934824,\n",
       " 0.21218371229126812,\n",
       " 0.21244181439075216,\n",
       " 0.2124386053858986,\n",
       " 0.21251709828126825,\n",
       " 0.2126150786608219,\n",
       " 0.21229779208221597,\n",
       " 0.21237250719243225,\n",
       " 0.21229260033706157,\n",
       " 0.21209816107057627,\n",
       " 0.21254951566010435,\n",
       " 0.21242762657803022,\n",
       " 0.21226140861047268,\n",
       " 0.21270230921426153,\n",
       " 0.21223375128381175,\n",
       " 0.21256782235568816,\n",
       " 0.21226988275423433,\n",
       " 0.21217931631514206,\n",
       " 0.21226594070223725,\n",
       " 0.21244686602566143,\n",
       " 0.21341890953036521,\n",
       " 0.21064402371390226,\n",
       " 0.21076436588497313,\n",
       " 0.21088867998610797,\n",
       " 0.210917840497217,\n",
       " 0.21095517057998875,\n",
       " 0.2109360891235549,\n",
       " 0.21099111993626965,\n",
       " 0.21085679807968807,\n",
       " 0.2109082812707792,\n",
       " 0.21094879849035747,\n",
       " 0.2108072411040233,\n",
       " 0.21087893919398315,\n",
       " 0.210941565242509,\n",
       " 0.21100698487089972,\n",
       " 0.21077945366968587,\n",
       " 0.2109601333805308,\n",
       " 0.2109058830331433,\n",
       " 0.21087726511503124,\n",
       " 0.21084286750470407,\n",
       " 0.21087804151951642,\n",
       " 0.21087450410447384,\n",
       " 0.2109446755295134,\n",
       " 0.21083393369835404,\n",
       " 0.21085011761046196,\n",
       " 0.21085436021997936,\n",
       " 0.21087938613951138,\n",
       " 0.21088676537965406,\n",
       " 0.21084569047835977,\n",
       " 0.21076527409123644,\n",
       " 0.2108576889216477,\n",
       " 0.21082535512323392,\n",
       " 0.2107522023797178,\n",
       " 0.21070857142534374,\n",
       " 0.21087505225823916,\n",
       " 0.2107098815892446,\n",
       " 0.2107422765434412,\n",
       " 0.2108152105240951,\n",
       " 0.21077347997537477,\n",
       " 0.21082164483494029,\n",
       " 0.21077483534992855,\n",
       " 0.21083679836902325,\n",
       " 0.21068423925752877,\n",
       " 0.21084004067266862,\n",
       " 0.21082474381445984,\n",
       " 0.21068456433901306,\n",
       " 0.21075489251525772,\n",
       " 0.21076396002233463,\n",
       " 0.21082584008040697,\n",
       " 0.2107291873718427,\n",
       " 0.21065102268494498,\n",
       " 0.21090081312744047,\n",
       " 0.21080527437207708,\n",
       " 0.21050331122819807,\n",
       " 0.2106951493327184,\n",
       " 0.21089825794919345,\n",
       " 0.21057876309036197,\n",
       " 0.21077788867634112,\n",
       " 0.21079962454450618,\n",
       " 0.21075343295204985,\n",
       " 0.21082646823522652,\n",
       " 0.21067091822776232,\n",
       " 0.21066433270355728,\n",
       " 0.2106568532719903,\n",
       " 0.2107105640163665,\n",
       " 0.21080012070250767,\n",
       " 0.21074639508785234,\n",
       " 0.21067583245198368,\n",
       " 0.21084768797852743,\n",
       " 0.21055348348855335,\n",
       " 0.21066190959834977,\n",
       " 0.21073621663157047,\n",
       " 0.21078160330699244,\n",
       " 0.21079926713376584,\n",
       " 0.21057209332427423,\n",
       " 0.2106572420757773,\n",
       " 0.21066366693131613,\n",
       " 0.21065395644036633,\n",
       " 0.21059074375896653,\n",
       " 0.21078097207907986,\n",
       " 0.21060157815727618,\n",
       " 0.21058534433629852,\n",
       " 0.21072924187030548,\n",
       " 0.2106526796197322,\n",
       " 0.2105927617566854,\n",
       " 0.2107377064944629,\n",
       " 0.21071446728565088,\n",
       " 0.2106687555529793,\n",
       " 0.21065627291500114,\n",
       " 0.2106649449351267,\n",
       " 0.2106959633093752,\n",
       " 0.21062045232180487,\n",
       " 0.2106639138787397,\n",
       " 0.2106481165664054,\n",
       " 0.21061720273380846,\n",
       " 0.21062485330803868,\n",
       " 0.2105887158684355,\n",
       " 0.21060793989286156,\n",
       " 0.21064397993622475,\n",
       " 0.21062625639737514,\n",
       " 0.21079906646683802,\n",
       " 0.21054129311524844,\n",
       " 0.2105952448597772,\n",
       " 0.21065658585297908,\n",
       " 0.21059534928126897,\n",
       " 0.21045502182094938,\n",
       " 0.21065189394571002,\n",
       " 0.21064438156667936,\n",
       " 0.21060167870622892,\n",
       " 0.2106358791241583,\n",
       " 0.21055247959606965,\n",
       " 0.2104959242413379,\n",
       " 0.21065110995434286,\n",
       " 0.2106347921562455,\n",
       " 0.21058255463389117,\n",
       " 0.21066494601802588,\n",
       " 0.21060959495871767,\n",
       " 0.21062046618418412,\n",
       " 0.21036005784550135,\n",
       " 0.210618163904179,\n",
       " 0.2105122946666418,\n",
       " 0.2106963744495971,\n",
       " 0.21049655730977368,\n",
       " 0.2105705103088319,\n",
       " 0.2105089531424195,\n",
       " 0.2105929936125879,\n",
       " 0.21058390820217224,\n",
       " 0.21055438257647058,\n",
       " 0.2105121865801111,\n",
       " 0.21063450585324103,\n",
       " 0.21066982100804835,\n",
       " 0.2105524652189794,\n",
       " 0.21047614112269916,\n",
       " 0.21054838670630535,\n",
       " 0.210453688078952,\n",
       " 0.21052206135003684,\n",
       " 0.21054717262648476,\n",
       " 0.2105384444140034,\n",
       " 0.21062426604944529,\n",
       " 0.210671748656301,\n",
       " 0.21041018548545054,\n",
       " 0.21059493465390786,\n",
       " 0.21041639868791712,\n",
       " 0.21063769961690282,\n",
       " 0.21050787387508,\n",
       " 0.2106097219225943,\n",
       " 0.2105294573355006,\n",
       " 0.21055797881262994,\n",
       " 0.2104053857329541,\n",
       " 0.2105783189218644,\n",
       " 0.21050464108671654,\n",
       " 0.21056819016170586,\n",
       " 0.21058749750205952,\n",
       " 0.21043544259501296,\n",
       " 0.21058807274070462,\n",
       " 0.21050311547485667,\n",
       " 0.210581061716268,\n",
       " 0.21060133326264524,\n",
       " 0.21045475849360273,\n",
       " 0.21054325945058672,\n",
       " 0.21060575442291382,\n",
       " 0.21050349721654807,\n",
       " 0.21048670854641913,\n",
       " 0.21035117460799097,\n",
       " 0.2104756849888931,\n",
       " 0.21050572343436286,\n",
       " 0.21048563738138798,\n",
       " 0.21059726361032086,\n",
       " 0.21039237077318582,\n",
       " 0.21041405702100188,\n",
       " 0.2105909573103019,\n",
       " 0.210452477812768,\n",
       " 0.21053758614761112,\n",
       " 0.21046497557204633,\n",
       " 0.2103705387363725,\n",
       " 0.21045750170890856,\n",
       " 0.21040812241744908,\n",
       " 0.21054027717405083,\n",
       " 0.2103754437375886,\n",
       " 0.2105020969753962,\n",
       " 0.21051727861990574,\n",
       " 0.2104937474731563,\n",
       " 0.21042294007977785,\n",
       " 0.21049608110566792,\n",
       " 0.21051243212174506,\n",
       " 0.21036558262346614,\n",
       " 0.21053302138650032,\n",
       " 0.2104473607630342,\n",
       " 0.21052772252870305,\n",
       " 0.2103641303166783,\n",
       " 0.21046629002032652,\n",
       " 0.21051302902722682,\n",
       " 0.21042593119448558,\n",
       " 0.21037524146518105,\n",
       " 0.21044727954410591,\n",
       " 0.210503282351175,\n",
       " 0.2104648019266543,\n",
       " 0.2105029787695675,\n",
       " 0.2105113095311653,\n",
       " 0.210507089880881,\n",
       " 0.2103895036951168,\n",
       " 0.21055289010490838,\n",
       " 0.21036422830709994,\n",
       " 0.21041712344641658,\n",
       " 0.21052112320683397,\n",
       " 0.21044342032850002,\n",
       " 0.210419775249329,\n",
       " 0.21038432974375332,\n",
       " 0.21049663950181483,\n",
       " 0.21035381474782774,\n",
       " 0.21040724090190194,\n",
       " 0.2104362123013995,\n",
       " 0.2102535371850611,\n",
       " 0.21038141442689026,\n",
       " 0.2104303778585678,\n",
       " 0.2105427121553189,\n",
       " 0.21041359315687322,\n",
       " 0.2105291605212975,\n",
       " 0.21033471864778194,\n",
       " 0.21033337722241108,\n",
       " 0.2104867198484787,\n",
       " 0.21036726774976025,\n",
       " 0.21048331330779857,\n",
       " 0.21034632299157566,\n",
       " 0.21039995817318052,\n",
       " 0.2104182412478026,\n",
       " 0.21043612088015284,\n",
       " 0.21032274391673073,\n",
       " 0.2104691269498423,\n",
       " 0.2103845018061714,\n",
       " 0.21056118609613644,\n",
       " 0.21037520146304425,\n",
       " 0.21029340724983997,\n",
       " 0.2104559503533625,\n",
       " 0.21037515799022277,\n",
       " 0.21033705416275794,\n",
       " 0.21037123476817537,\n",
       " 0.21049725135710598,\n",
       " 0.21025242830662358,\n",
       " 0.210302695402303,\n",
       " 0.21028133892736184,\n",
       " 0.20974504555439302,\n",
       " 0.20983071600425696,\n",
       " 0.20977531476490713,\n",
       " 0.20984282872461743,\n",
       " 0.20978265551327235,\n",
       " 0.20982547235908505,\n",
       " 0.20977626370765048,\n",
       " 0.20980388412318285,\n",
       " 0.209777910514433,\n",
       " 0.20977349181736657,\n",
       " 0.20980082290625443,\n",
       " 0.2097851047465821,\n",
       " 0.2097769291436766,\n",
       " 0.20978554977649844,\n",
       " 0.20976250949743866,\n",
       " 0.20975416026988813,\n",
       " 0.2097345881527281,\n",
       " 0.2097742784845332,\n",
       " 0.20984853172457063,\n",
       " 0.20973424291598866,\n",
       " 0.20978208294538903,\n",
       " 0.2097695110677315,\n",
       " 0.20978261395439346,\n",
       " 0.2097319960196824,\n",
       " 0.20977035959041598,\n",
       " 0.20975877198833648,\n",
       " 0.209673103948108,\n",
       " 0.20982718618605256,\n",
       " 0.20972026007925568,\n",
       " 0.20982782941555114,\n",
       " 0.2097686645809082,\n",
       " 0.20983121080869413,\n",
       " 0.20971306967713804,\n",
       " 0.2097784118349554,\n",
       " 0.20969130019984028,\n",
       " 0.20972000661550838,\n",
       " 0.2097718040958763,\n",
       " 0.2097598900958305,\n",
       " 0.20972980745207906,\n",
       " 0.2097396855862716,\n",
       " 0.2096777123004414,\n",
       " 0.20977297454029745,\n",
       " 0.20975514580218124,\n",
       " 0.20980871290189612,\n",
       " 0.2097753527000026,\n",
       " 0.20976944360416838,\n",
       " 0.20969593677292314,\n",
       " 0.20980528603455945,\n",
       " 0.2097400307308418,\n",
       " 0.20974799534359606,\n",
       " 0.209744037258801,\n",
       " 0.20969271532614595,\n",
       " 0.20974966898799324,\n",
       " 0.20966625228452995,\n",
       " 0.20972314007189888,\n",
       " 0.2096956731569067,\n",
       " 0.20963427432288484,\n",
       " 0.20971180570874762,\n",
       " 0.20971325517304434,\n",
       " 0.20974415848445668,\n",
       " 0.20970800444985888,\n",
       " 0.20970381831009927,\n",
       " 0.20973526360682354,\n",
       " 0.2096753142994885,\n",
       " 0.20969571793595596,\n",
       " 0.20969653336609667,\n",
       " 0.20965938358561964,\n",
       " 0.20969657844120831,\n",
       " 0.20967614970048626,\n",
       " 0.20967088980061863,\n",
       " 0.2097739600153574,\n",
       " 0.2097423280619369,\n",
       " 0.2096702504481304,\n",
       " 0.20971189473359397,\n",
       " 0.20975723887413278,\n",
       " 0.20973791836448752,\n",
       " 0.20968790846740687,\n",
       " 0.20967958017747693,\n",
       " 0.20968065229028332,\n",
       " 0.20968238344301157,\n",
       " 0.2096842847212326,\n",
       " 0.20971033980836776,\n",
       " 0.20966920767578667,\n",
       " 0.20967468632769584,\n",
       " 0.20962527828971683,\n",
       " 0.20962418775990402,\n",
       " 0.20970384831205213,\n",
       " 0.20962618115263823,\n",
       " 0.20962260510953176,\n",
       " 0.20970612027484506,\n",
       " 0.20968095383740085,\n",
       " 0.20972527142040728,\n",
       " 0.20968278631166995,\n",
       " 0.20970854712825848,\n",
       " 0.20970644037939892,\n",
       " 0.2097176780613074,\n",
       " 0.20960503852786705,\n",
       " 0.2097100162027837,\n",
       " 0.20964802541788358,\n",
       " 0.20961163416368186,\n",
       " 0.20963015978059216,\n",
       " 0.2096280635905063,\n",
       " 0.20969857386449772,\n",
       " 0.20959392570362492,\n",
       " 0.20963516268581375,\n",
       " 0.20972072344998677,\n",
       " 0.20964154398527474,\n",
       " 0.20961231583195758,\n",
       " 0.20961050397349174,\n",
       " 0.20971233557073385,\n",
       " 0.20977093607555172,\n",
       " 0.20961596579747926,\n",
       " 0.209660848711444,\n",
       " 0.2095501518617962,\n",
       " 0.20964286104866345,\n",
       " 0.20966818740615212,\n",
       " 0.20957505770695342,\n",
       " 0.2096303848605351,\n",
       " 0.2095559048971879,\n",
       " 0.20959052052831348,\n",
       " 0.20965864470787726,\n",
       " 0.2096815328260106,\n",
       " 0.20957465966009975,\n",
       " 0.20961546881615484,\n",
       " 0.2095856607509556,\n",
       " 0.20959670944609243,\n",
       " 0.2095756005830161,\n",
       " 0.20958945411909005,\n",
       " 0.20955678994885032,\n",
       " 0.2095700801710177,\n",
       " 0.20954977897961985,\n",
       " 0.2095311613509776,\n",
       " 0.20949648586347075,\n",
       " 0.20962307720319334,\n",
       " 0.20967546939406176,\n",
       " 0.20953973951106789,\n",
       " 0.2095823761703936,\n",
       " 0.20954430161641077,\n",
       " 0.20956064316719558,\n",
       " 0.2096080154324146,\n",
       " 0.2095578275461236,\n",
       " 0.2096235881001954,\n",
       " 0.20951719736699811,\n",
       " 0.2095950748200476,\n",
       " 0.2095428065101556,\n",
       " 0.20958706353913237,\n",
       " 0.20961629415639688,\n",
       " 0.20949329049340518,\n",
       " 0.2096237988063867,\n",
       " 0.20961482923896682,\n",
       " 0.2095507042831286,\n",
       " 0.20952645245675616,\n",
       " 0.20953785464708002,\n",
       " 0.20956638619393755,\n",
       " 0.20955713817772173,\n",
       " 0.2095101182625793,\n",
       " 0.20952392260346914,\n",
       " 0.2095288628038566,\n",
       " 0.20953955339668567,\n",
       " 0.20961668705095413,\n",
       " 0.20955129272385511,\n",
       " 0.2095409020046995,\n",
       " 0.20957646952676204,\n",
       " 0.20942990142785736,\n",
       " 0.209517140775441,\n",
       " 0.20951618917520085,\n",
       " 0.20954550363630928,\n",
       " 0.20957109356161335,\n",
       " 0.2095380008185856,\n",
       " 0.20951455460334867,\n",
       " 0.20951294483199798,\n",
       " 0.209585664690058,\n",
       " 0.20956939269116123,\n",
       " 0.2095073387220992,\n",
       " 0.20950751855916577,\n",
       " 0.20950142188321397,\n",
       " 0.20948788155575335,\n",
       " 0.2095518647121036,\n",
       " 0.209475716873343,\n",
       " 0.20955405299199106,\n",
       " 0.20955119343608883,\n",
       " 0.20949599337241598,\n",
       " 0.2095194717430632,\n",
       " 0.2094694571770679,\n",
       " 0.2094721534313101,\n",
       " 0.20956322376504596,\n",
       " 0.20952527973171264,\n",
       " 0.20954091074554515,\n",
       " 0.2094764473973982,\n",
       " 0.2094752343921601,\n",
       " 0.2095113452641282,\n",
       " 0.20949960858542346,\n",
       " 0.20945752547915633,\n",
       " 0.2095081910780345,\n",
       " 0.20948344940012933,\n",
       " 0.20952226498546103,\n",
       " 0.20955348180259237,\n",
       " 0.20948816235453707,\n",
       " 0.20947793800959796,\n",
       " 0.20948098086943592,\n",
       " 0.20949494983517486,\n",
       " 0.2094272057831782,\n",
       " 0.20944089250076314,\n",
       " 0.20951065000524136,\n",
       " 0.20943801039225157,\n",
       " 0.20951118140569677,\n",
       " 0.20948141422181926,\n",
       " 0.20944189939086363,\n",
       " 0.20946282038834219,\n",
       " 0.20951710781673938,\n",
       " 0.2094800718008596,\n",
       " 0.20943888497382193,\n",
       " 0.2094322756260438,\n",
       " 0.20951341934072026,\n",
       " 0.20945026257036928,\n",
       " 0.20947015326008256,\n",
       " 0.20944685394404702,\n",
       " 0.2094823428016882,\n",
       " 0.20953224945979773,\n",
       " 0.20942322241122088,\n",
       " 0.20945142111452503,\n",
       " 0.20950744935839724,\n",
       " 0.20940828192777253,\n",
       " 0.20950055144994512,\n",
       " 0.20943653848191246,\n",
       " 0.20948401088424395,\n",
       " 0.20944502713091295,\n",
       " 0.2094823276180575,\n",
       " 0.20950124821585275,\n",
       " 0.20949612016727592,\n",
       " 0.20940103363067208,\n",
       " 0.20945115733533445,\n",
       " 0.20950240375404516,\n",
       " 0.20950154840872032,\n",
       " 0.20948117617501724,\n",
       " 0.20936788016441904,\n",
       " 0.20944490351368603,\n",
       " 0.20946516039445232,\n",
       " 0.2095087569781349]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "124a5452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15544c003eb0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAJECAYAAADzOSkiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABs2klEQVR4nO3dd3xUVf7/8fekTSohBCkBpAgalCLSlCJFxC8CFizLV0AEXcuCgl1WV1BXcZWf666sXUFUkK+rIAiooBSRKqGDNCkRCDWk15nz+yNyzZBJIcwkM8zr+XjMwzv3nnvuuTejvvPJmXttxhgjAAAAIAAFVfcAAAAAgOpCGAYAAEDAIgwDAAAgYBGGAQAAELAIwwAAAAhYhGEAAAAELMIwAAAAAhZhGAAAAAGLMAwAAICARRgGAMCPLFmyRDabTTabTU2aNKnu4QB+jzAMwK277rrL+h9uz549q3s4AAB4BWEYAAAAAYswDAAAgIBFGAYAAEDAIgwDAAAgYBGGAQAAELAIwwCq1Lp16/Twww+rbdu2ql27tux2uxo2bKjevXtr0qRJOnHiRIX7ysvL08cff6xBgwapWbNmio6OVkhIiGJiYnTRRRepb9++euaZZ/TTTz/JGFNqP06nU7NmzdIdd9yhSy65RDVq1FBISIiio6PVuHFj9erVS4899pi+++47ORyOSp/7448/bt2ho1u3bme1b9++fa19R40a5bbNsWPH9Oqrr+raa69VQkKCIiIiFBoaqpo1a+qyyy7ToEGD9Oqrr2rXrl2VPgdPMMZo7ty5uvvuu5WYmKi4uDiFh4frwgsv1MCBA/X+++8rPz+/3H4mTJhgXZO77rrLWj9//nzdeuutuuiiixQREaG6deuqZ8+eevvttyvUb3GFhYX65JNPdOutt6pZs2aKiopSTEyMmjdvrqFDh2rWrFllfrZKc+LECf3rX/9S//791bRpU0VHR8tutyshIUG9e/fWhAkTtHHjxrPqc+/evXrqqafUpk0b1axZU9HR0UpMTNSoUaO0e/fusx4jEDAMALgxfPhwI8lIMj169Djn/rKyssydd95pbDab1a+7V1xcnPnwww/L7W/Dhg3m4osvLrOv4q+ZM2e67Wf//v2mY8eOFe7nH//4R6WvwYYNG6x+bDab2bt3b4X2S0lJMcHBwda+P/30U4k2M2bMMLGxsRU+jyNHjlT6PM7Fxo0bK3S9L7roIrN69eoy+xo/frzVfvjw4SYzM9PcfvvtZfbbqlUr88svv1RorGvXrjUtW7Ysd6ydOnUyO3bsqFCfTqfTvPLKK6ZGjRoV+jm99tprJfpYvHixtb1x48bGGGM++OADExERUWo/YWFh5tNPP63QGIFAE3JWyRkAKiErK0vXXXedfvrpJ2tdcHCwWrVqpbi4OO3bt0/79u2TJKWmpmrkyJE6cuSInnrqKbf9paSk6JprrnGpItesWVOXXHKJYmJilJ2drcOHD2vfvn1W1c7pdJboJzs7W9dcc41L1SwqKsqqVubm5urIkSPas2ePtb+7fiqqbdu2uuyyy7R161YZYzR9+nT99a9/LXe/mTNnWhXppk2bqkuXLi7bv/32Ww0ZMsRlbA0aNFDTpk0VHh6ujIwM7d27V0ePHrW2n8t5VNbSpUt1ww03KD093VpXs2ZNJSYmKjw8XPv379fevXslSXv27FHv3r317bffqmvXrhXqf/jw4friiy8kSbVq1VLLli1VUFCgrVu3KisrS5K0ZcsWXXPNNfrpp5/UuHHjUvv68ccfdf311yszM9NaFxcXp5YtW8rpdGrbtm3WeaxZs0bdunXT999/r9atW5fap8Ph0LBhwzRjxgyX9RdccIFVxT527Jh++eUXFRYWSpLS0tLKPe+pU6fq7rvvliSFh4erVatWio6O1q+//qoDBw5IkvLz8zVs2DA1b95cnTp1KrdPIKBUdxoH4Js8WRm+7777XKpUw4YNMykpKS5tli9fbhITE10qpz/88IPb/kaPHm21S0hIMF9//bVxOBwl2qWmppoZM2aYa6+91nz22Wcltk+aNMnqp0aNGubjjz82+fn5JdplZWWZr776ytx6663mlVdeqeRVKPLSSy9Zx7zssssqtE+nTp2sfZ5++ukS21u1amVt79q1q9m4caPbfvbv32/+/e9/m0svvdQcPnz4nM7jbCUnJ5tatWpZ47z00kvNggULSvzc1q1b51I5btSokUlNTXXbZ/HKcO3atY0kEx0dbd5//32Xn2NmZqZ5/vnnXarrvXr1KnWsJ0+eNAkJCVbbmJgY88EHH7j0mZOTY1577TVjt9utdomJiSYnJ6fUfseNG+fy78GVV15pli1bZpxOp0u77Oxs88UXX5i+ffuaCRMmlOineGU4KirKhIeHG7vdbiZNmmSysrJc2s6bN8/lLwbdunUrdXxAoCIMA3DLU2E4KSnJJQDcd999pbY9evSoadq0qdX2kksuKREUjDGmWbNmVptFixZVaByFhYUl1vXu3dvq5/333690P2dj3759LlNFNmzYUGb73bt3u1y/bdu2uWw/cOCAtS06OrrU4Fic0+l0+8uDNw0YMMAaZ+fOnU1mZmapbbOysky7du2s9u4CoTGuYViSCQ4ONt9//32p/U6ePNml/RdffOG23ZgxY6w2oaGhZunSpaX2+fnnn7v0+dJLL7ltl5SU5PJzHzRokNtfvM6UkZFRYl3xMHz6F8f58+eX2scXX3zh0n737t3lHhcIJIRhAG55Kgzfc889Vj8NGjQoUbk60/z5813+x/3dd9+VaBMWFmZtL6sSV57ic463b99e6X7OVrdu3azjPvHEE2W2ff755622V1xxRYntK1ascAmZvmjr1q1WEAwLCzN79uwpd5/Vq1db51WvXj23vxSdGYb//Oc/l9tvly5drPbXXnttie1ZWVkuldSxY8eW22fxecqNGjVy+wvTHXfc4dImPT293H5Lc2YYHjlyZJntnU6nady4sdV+2rRplT42cD7ibhIAvGrOnDnW8j333KPIyMgy2/fr10+XXHKJ9f6rr74q0SY8PNxaPttv3Hujn7M1dOhQa3nGjBll3o1g+vTp1vKQIUNKbC9+Drt27VJ2draHRuk5n376qXWOAwcOVLNmzcrdp1OnTmrevLmkojniv/zyS7n7lHaXjdLafP/99y5zgiVpyZIlLvN0H3rooXL7HDt2rLWcnJys9evXu2zPz8/XrFmzXNrHxMSU229F3XvvvWVut9lsLvPMK3ItgUBCGAbgNWd+aatfv34V2q9///7W8urVq0ts79Chg7U8ZMgQ/fjjj5UaX/F+HnzwQc2dO7dSt8k6W7fddpvCwsIkFYWnZcuWuW2XlJRkBZegoCANHjy4RJtLL73U+gXj5MmTuuWWW/Trr796aeSVU/zn06tXrwrv16pVK2s5KSmpzLZ169ZV27Zty+2z+GfQ6XRq3bp1LtuLf94SExPVtGnTcvu86qqrFB8f77YPSfr555+Vk5Njvb/lllvK7bOiwsLC1L59+3LbNWzY0Fo+deqUx44PnA+4mwQAr9mzZ4/L+7K+aV9cmzZtSu1Dkh5++GH98MMP1varr75aF198sa6//npdffXV6tKli+rWrVvucUaPHq1p06apsLBQx44d0w033KCGDRuqf//+6tmzp7p06aILL7ywQmM+G7Vq1dL//M//WFXz6dOnq0ePHiXaFa8K9+rVSwkJCSXa2O12PfDAA/p//+//SZK++eYbNW/eXFdddZX69u2rbt266corr1RUVJTHz6Oitm7dai1/8MEHmjt3boX227x5s7V8/PjxMtsWD85liYuLU/369XX48GFJ0u7du12uffHPW0U/r6fbLlmypEQfkrRjxw5rOT4+vsy7WJyt+Ph4hYSU/7/y4n+R8cW/HgDViTAMwGuKV6AiIiLKnSJxWu3ata3ltLQ0GWNks9msdQMGDNA//vEPjRs3zrpF2M6dO7Vz5069/vrrkorCyW233aZ77rlH9evXd3ucdu3aWbelysvLkyT99ttveuedd/TOO+9Ikpo3b65Bgwbp3nvv1UUXXVThcy/PkCFDrDD8+eef64033rCqxVJR1fKzzz5zaV+al156Sfv27bNuK2aM0YoVK7RixQpJUmhoqLp27ao77rhDw4YNc5la4W1Op9Plc3DmFIKKKu8WY8Urs+WJj4+3wnBqaqrLtuJjLf45LE/xtmf2efLkSWv5ggsuqHCfFVH8M1NRVfHXD8CfME0CgNecDpjS2f1P2263W8tOp1MFBQUl2jzxxBNav369hgwZ4rbquXnzZj377LNq3ry5VTV1Z8iQIdq+fbseeOABxcXFldi+e/duvfLKK0pMTNSTTz5p3f/1XA0cOFA1atSQVBSevvnmG5ftS5cu1cGDByUVzQsu60/rYWFh+u9//6uvvvpK11xzjYKDg122FxQUaMmSJbr33nvVvHlzLVq0yCPnUBE5OTkeuadxeX1U9vNV/DN65ntv9Fm8HQDfQBgG4DWxsbHW8plfVCpL8YcyRERElBpK2rRpo08++UQnT57U0qVL9fe//119+vRxCRzZ2dl67LHH9M9//rPU4zVt2lRvvvmmjh07ptWrV2vSpEkaOHCgoqOjrTaFhYV65ZVX9Oijj1b4PMoSERGhQYMGWe8//fRTl+3Fp0gUD85lueGGG7Ro0SKdOHFCc+bM0eOPP6727du7VNUPHjyo/v37a9WqVR44i/JFRUUpNDTUer9kyRKZojsZndVrwoQJZR4nIyOjwmMq3rb4Z/TM92fT55kPEimu+PuKPEQDQNUiDAPwmuJ/EnY4HNbTsMpTfM5lRf6sHBYWpquvvlpPP/20Fi5cqOPHj+utt95y+dP5+PHjraeQlSY4OFidOnXSo48+qjlz5uj48eOaMWOGyxzPyZMnW0/LO1fFpz7MnTvXCl/5+fnWlIcz21VEbGysBg4cqFdeeUU///yzDhw4oCeffNKqGOfn5+vpp5/2wBlUTPGf4a5du7xyjIr+TBwOh5KTk633derUcdlefKynn4ZXEWV9ZuvVq2ct//bbb8rNza1wvwC8jzAMwGvatGnj8uUed3eGcKd41fKKK6446+NGR0fr/vvv13//+19rXUZGxllXQ+12uwYPHqzvvvvOqm46nU59//33Zz0md3r37m3NZ87JybFuvzV//nxr3mlcXFyF78JRmoYNG+rll1/WM888Y61btmxZiT/ne8uVV15pLXvq2p1p+/btFfrrw5YtW1zu7HDm56v4+6SkJLdTdM506tQply/Jndln8fMvLCy05nID8A2EYQBeExER4XLbpxkzZpS7T2pqqubPn2+97969e6WP37NnT5c/ex85cqRS/Vx88cW69NJLz7mfM515u7TTUyWKT5Eofhu2c3XTTTdZy4WFhTpx4oRH+i1P3759reXZs2crJSXF48fIz8/X7Nmzy21X/EuJ9erVK/GlyOKft7S0NC1YsKBCfTocDklFf1246qqrXLYnJCSoZcuW1vv33nuv3D4BVB3CMACvGjlypLU8e/bscquzzz77rPVn5LCwMJcHVEhn9034/Px8l8perVq1Kt1X8SkWZ/ZzLopPgfj++++1a9cuff3119a6M8//TGdzDmdWTt19YdAbhg4dat1tITc3V3/5y1+8ckeDF154ocxq96FDhzR58mTr/fDhw13mU0tF9xYuHmb/9re/lVkdzsjI0AsvvGC9HzhwYImpF1LRfaxPmzlzphYuXFj2yQCoMoRhAF41dOhQa86tMUa33HJLqU/AevPNN13Cyr333lsiWOzfv1/du3fX3Llzy72zw3PPPWfdUzUsLMzlz9WSdPnll+vTTz8tdw7ne++9p927d1vvr7766jLbn4327dsrMTFRUtF81mHDhll/xr/wwgvVrVu3Mvf/9NNPNWTIkBIPjzhTTk6Oy5fQOnbsqIiIiBLtpk6dKpvNZr1O3zv3XERFRen555+33s+aNUtDhgwp9wtqaWlpmjx5stuHjbizc+dODRs2zO3P88SJE7rxxhutXwiio6M1evRot/0Un0+9adMmDR8+3G3ITk9P16BBg3To0CFJRVXhcePGue3zrrvusp6sePrfg+J/AXFn1apVLr8YAfAO7jMMoFzLli0763vT7tixQ40bN1ZkZKQ+/PBD9e3bVw6HQ4cOHdIVV1yhu+++W3369FHNmjW1f/9+ffLJJy7VshYtWujll1922/fy5cu1fPly1a5dW/3791fHjh3VtGlTxcbGKicnR7/88os+++wz/fTTT9Y+f/nLX0p8y3/Tpk0aOnSoHnjgAV1//fXq3Lmzmjdvrri4OOXn52vPnj2aPXu2S2i56aabXKZMeMKQIUP0t7/9TZLrvOo77rijROXyTIWFhZo+fbqmT5+uiy++WNddd53at2+v+vXrKyoqSqdOndL69ev14Ycfunwh7K9//atHz6E8DzzwgFatWqVp06ZJKpoy88033+iOO+5Qt27drC+ZnTx5Utu2bdPKlSu1aNEi5efnq3PnzuX236dPHyUlJenzzz/Xpk2bdN9996lNmzYqLCzU6tWr9dZbb7lMz3jppZdcnspWXP/+/TVixAhNmTLFGmtSUpLuvfdetWnTxnpy3dtvv+3ypdAnnnhCnTp1cttnRESEZs6cqa5duyorK0sZGRnq37+/+vTpo5tvvlnNmzdXeHi4jh07pvXr12vu3LnatGmTxo8frwEDBlTsIgOoHAMAbgwfPtxIqvRr7969Lv3997//NWFhYRXaNzEx0SQnJ7sd1969e896LAMHDjQ5OTkl+jrbfjp37mxOnjzp8Wu9Z88et8fbvHlzuftOmTLlrM/jxRdfrHB/ixcv9th5OhwO89hjj1Xqurszfvx4q83w4cPN119/bex2e7n9jR07ttyx5ufnm8GDB1d4jA8++KBxOp3l9rt27VpTt27dCvc7fvz4En0sXrzY2t64ceNyj+nuWgH4A9MkAFSJW265RRs2bNCAAQNKPBTitNjYWD3zzDP6+eefS63a1a1bV6+88oq6d+9e7hfLLrnkEr333nv66quv3Fa2J0+erL59+5b7ZLxGjRrpH//4h3788UevzLNt1qxZiS9dtWnTpkKPGO7Vq5eeeOIJtWrVqswqss1m09VXX62lS5dWeVX4tKCgIL366qtatWqVrr/++jIfI2yz2XT55ZfrhRde0Oeff16h/vv376/ly5eXegeS+vXra9q0aWXec/q00NBQTZ8+XZ988kmZTx5s3bq15syZo3//+9/lVvElqUOHDtq2bZseffTREvc4Li4yMlK33357mQ9bAeAZNmN4LiOAqnXixAktWbJEBw8eVFZWluLj43XxxRerW7duZQakM+Xm5mrjxo3atWuXUlJSlJOTo6ioKNWrV0/t2rVz+QZ/WQoLC7Vp0ybt3LlThw8fVlZWlsLDw1WnTh21bdtWrVu3VlCQ79cOUlNTtWHDBu3Zs0cnTpxQYWGhoqOj1aRJE3Xs2FEJCQnVPUQXGRkZWr58uQ4cOKCTJ08qODhYNWvWVPPmzdWmTZtyH4c8YcIEPffcc5KKvgw3depUa9umTZu0fv16HT58WDVq1FBiYqJ69OhR6i9i5dm8ebOSkpJ09OhR2Ww21a1bV1deeaVatGhRqf6kos/dypUrtWPHDh0/flw2m03x8fFKTExUx44deVodUEUIwwAAv1RWGAaAivL9UgcAAADgJYRhAAAABCzCMAAAAAIWYRgAAAABizAMAACAgMXdJM6S0+nUoUOHFBMTU6F7SgIAAKBqGWOUkZGhhISEcm+NyeOYz9KhQ4fUqFGj6h4GAAAAypGcnFzqQ5xOIwyfpZiYGElFF7dGjRrVPBoAAACcKT09XY0aNbJyW1kIw2fp9NSIGjVqEIYBAAB8WEWmtPIFOgAAAAQswjAAAAACFmEYAAAAAava5wzn5ORo1apVOnLkiGrVqqUrr7ySubgAAACoEl4Jw//973/ldDpls9l06623ljp5+V//+pfGjx+vjIwMa11YWJhGjRqll156SWFhYd4YHgAAACDJC2F4xYoVuv3222Wz2XTttdfqtttuc9vutdde0+OPP64zn/mRl5enf/7zn9qzZ49mzZrl6eEBAAAAFo/PGV6wYIG1PHLkSLdtUlJS9Oyzz0r645YXsbGxioyMlFT01JA5c+ZoypQpnh4eAAAAYPF4GF6zZo2kopD7P//zP27bvP/++8rOzpYkxcfHa/HixUpNTVVqaqrGjRsnqSgQv/rqq54eHgAAAGDxeBjes2ePJKlJkyalfhHu888/t5b//ve/q0ePHpKk0NBQvfjii+rataskaceOHdqxY4enhwgAAABI8kIYPnr0qGw2m+rXr1/q9s2bN0uS7Ha7hg4dWqLN4MGDreX169d7eogAAACAJC+E4ZycHEmy5v+eacWKFZKKplF0797dbbvExERrOSUlxdNDBAAAACR5IQyHh4dLksvt0opbtmyZtdyzZ0+3bSIiIqzlrKwszw0OAAAAKMbjYbhOnToyxpQ613f+/PnWcvfu3d22SUtLs5aLB2MAAADAkzwehi+//HJJ0qlTp/TNN9+4bFu+fLl27twpSYqKitKVV17pto+9e/day/Xq1fP0EAEAAABJXgjDN998s7X85z//WUuWLFF+fr7Wrl2rESNGSCqaL3zTTTcpJMT9Mz/Wrl1rLbdo0cLTQwQAAAAkSTZz5iPgzlF+fr5at26t3bt3u91ujFFwcLDWr1+vVq1aldjucDhUv359HT9+XHa7XWlpaT71WOb09HTFxsYqLS2t1FvHecqsWVJWlnT6J9S7t9SggVcPCQAA4PfOJq95/HHMYWFh+r//+z9dc801OnnypNs2EydOdBuEpaIn2B0/flw2m02dO3f2qSBc1caOlQ4c+OP9vHmEYQAAAE/y+DQJSWrbtq22bt2qUaNGqVmzZgoLC1ONGjXUu3dvzZ07V4899lip+77yyiuSiirIAwcO9Mbw/JZna/gAAADweGX4tLp16+qNN9446/0+/vhjlz4Cmc1W3SMAAAA4v3ktDFdW48aNq3sIPovKMAAAgGd5ZZoEPIPKMAAAgHf5RGV47969OnLkiGrVqqWLL764uofjs6gMAwAAeJZXKsM///yz1qxZozVr1qisO7fNnj1bLVq0UPPmzdW1a1e1bNlSDRo00OTJk70xLL9DZRgAAO+x2Wyy2WyaMGGC145x1113yWazqUmTJl47Bs6NxyvDGzduVKdOnaxbo61YscJtuxkzZmjo0KGS5BKYDx8+rDFjxmj79u36z3/+4+nh+TUqwwAAAJ7l8crw3LlzreV7773XbZv09HSNHj261KqxMUZvv/225syZ4+nh+RUqwwAAfzd16lSrArtv377qHg5QgsfD8OrVq63lAQMGuG3z4YcfKjU1VTabTZGRkZoyZYpOnjyp5ORkl2rxCy+84Onh+TUqwwAAeI4xRsYYr06TmDp1qowx/CLgwzwehnft2iVJatCggWrXru22zWeffWYtP/vssxo+fLhq1qypBg0aaOrUqWrTpo0kKSkpSfv37/f0EP0GlWEAAADv8ngYTklJkc1mU6NGjdxuP3XqlH7++WdJUnBwsO655x7XAQUFadiwYdb7021BZRgAAMDTPB6Gs7OzJUnR0dFut69cuVJOp1M2m01XXXWV4uLiSrRp1aqVtXzw4EFPD9FvUBkGAPirJUuWyGazacSIEda6pk2bWvOHT7+WLFkiqeRdFw4fPqwnn3xSl112mWJiYlzaSlJqaqqmTJmioUOH6tJLL1V0dLTCwsJUr149XXfddXr33XeVn59f5hjLupvEmXOdnU6n3n33XXXp0kVxcXGKiopSmzZt9OKLL1rZx53y7iZx5hjWrl2r//3f/1XDhg1lt9vVoEEDDRs2TNu3by/zXCQpKytLzz//vFq3bq2oqCjFx8erW7du+vDDD2WMsX4mZ17LQOfxu0mEhobK4XCU+sH48ccfreVevXq5bRMTE2MtZ2ZmenaAfozKMAAgEKxatUoDBw7U8ePHS23Trl07t1Mpjxw5ou+++07fffed3n77bc2fP1/16tU7p/FkZWXp2muv1Q8//OCyfvPmzdq8ebPmzJmjH374QVFRUed0nMmTJ+vhhx9WYWGhte7QoUP65JNP9OWXX2rBggW6+uqr3e6bnJys3r17a/fu3da67Oxs/fTTT/rpp580a9YsPfTQQ+c0vvOVx8NwfHy8fvvtN2vu8Jm++eYba7l79+5u22RkZFjLdrvdswP0I1SGAQD+qmPHjtq8ebO++uorPfPMM5Kkb7/9VgkJCS7tmjZt6vI+MzNTt9xyi3Jzc/X000/r2muvVWRkpDZv3qz69etb7RwOhzp37qwBAwaoXbt2qlu3rvLz87V371598skn+uabb7R+/XoNHjz4nKug9957r1atWqXhw4fr9ttvV7169XTgwAG98sorWrlypdasWaO///3vmjhxYqWP8e2332r16tVq06aNxowZo9atWysnJ0ezZs3Sv/71L2VnZ2vYsGHatWuXwsLCXPbNz8/X9ddfbwXhfv366d5771WjRo3022+/6d1339XXX3+tY8eOndN1OF95PAy3adNGv/32m44dO6ZVq1bpyiuvtLZt2rRJGzZskCSFhYWpa9eubvtITk62li+44AJPD9FvURkGAO9zOqUTJ6p7FFUrPl4K8vDEyaioKLVq1crluz8XX3xxuQ+fOHHihKKjo7V8+XK1bdvWWt+xY0eXdj/88INatGhRYv8uXbpoyJAhmjJlikaOHKmlS5fq+++/1zXXXFPpc1mxYoU+/vhj645XknTFFVeoX79+6tChg7Zs2aL33ntPL7zwgkJCKhetVq1apeuvv16zZs1yCbvdu3dXfHy8nnnmGR04cEDz5s3TzTff7LLvf/7zH23ZskWSNHr0aL3xxhvWtvbt2+vGG2/Ugw8+yEPNSuHxMDxgwADNnz9fknTPPfdozpw5atasmY4cOWJ9Wc5ms6lfv34KDw9320fxf3GaN2/u6SH6DSrDAFD1TpyQ6tSp7lFUraNHJV+qPT3xxBMuQdgdd0G4uBEjRuiNN97Q+vXrNXv27HMKw4MGDXIJwqfZ7XaNHj1a999/v06cOKFt27ZZd8Q6W+Hh4ZoyZUqJqq8kPfTQQ3r++eeVn5+vH3/8sUQYfueddyRJCQkJevXVV932/+qrr+rLL7/UoUOHKjW+85nHv0A3dOhQ688Y27dv18UXX6yEhAQ1aNBA69ats9o9+uijpfaxYMECSUV3m7j88ss9PUS/RWUYABAIhgwZclbtjTFKSUnRzp07tWXLFut1ekrGxo0bvTae9u3bW8u//vprpY9x7bXXqk4pv4XFxMRY4f/MYxw8eFA7duyQJN1+++2lFhrDw8N12223VXp85zOPV4ajo6P18ccfa+DAgcrJyZExRkeOHHF52tyDDz5Y6hSJpUuXKjk5WTabTe3atVNkZKSnh+g3qAwDAAJNdHS0mjVrVqG28+bN01tvvaVly5a5fN/oTGV9Ea8iEhMTS91Wq1Yta7msMZzLMYof58xjnJ4eIbkGc3c6dOhQydGd3zxeGZak3r17a+XKlerfv7/CwsKsINysWTO98cYbev3110vdd9KkSZKKfssr7Ql2gYrKMADgfFezZs1y2xhjdM8992jAgAGaN29euSE0JyfnnMZUVmEuqNhka4fD4ZVjFD/OmcdITU21lkurLJ/G97Dc83hl+LQ2bdpo7ty5cjgcOnbsmMLDwyv0AX/88cf12GOPSZJat27treH5BSrDAFD14uOL5tAGkvj46h7BH4KDg8tt8+GHH+qDDz6QJF1++eUaO3asOnfurAYNGigyMtLq484779THH3/s8tdp4ExeC8OnBQcHn9X9/Uq7fx6oDANAVQgK8q0vk6Gk9957T5J00UUXacWKFYqIiHDbrnjV9HxV/OFlR8v5LY5bq7nnlWkS8AwqwwAAf2fzwv/Mtm7dKkm68cYbSw3CxhglJSV5/Ni+5rLLLrOWi9+Ny53ytgcqwrAfoTIMAPA3xe9ukJeX55E+Tz+hrazHIM+ZMycgbiPWsGFDXXzxxZKkzz//XLm5uW7b5ebm6vPPP6/KofmNKgnDu3fv1muvvaY//elP6tChgy666CI1bNhQrVq1Uq9evfToo49q9uzZLo8fBJVhAID/K/7UuD179nikz9O3GZs7d67bqRB79uzRX/7yF48cyx/cd999kooe3fz444+7bfP4448HxC8HleHVOcM7d+7UmDFjtHDhwhKT140xOnz4sLZv365ly5bp9ddfV506dfTkk09q7Nix3hyW36IyDADwN+3atVN4eLhyc3P1t7/9TSEhIWrSpIl1d4QGDRqUOtWhNHfeeacef/xxHTx4UF26dNETTzyhyy67TLm5ufrhhx/0+uuvKy8vT1dccUVATJUYPXq0pkyZoi1btmjy5Mn69ddfdd9996lhw4bW45jnzZunTp06ac2aNZK8M33FX3ktDM+YMUP33HOPcnNzS/0WZ/H1NptNR44csarEc+fOVUxMjLeG5xf4nAIA/F1MTIweeughvfLKK0pKStJ1113nsn3x4sXq2bPnWfV5utD23Xff6ZdfftHIkSNdtkdERGjatGmaN29eQIThsLAwzZs3T71799aePXs0f/5862nAp/Xt21cPP/yw+vXrJ0mlPpwjEHklDM+fP1933nmnHA6H9ZtHbGysrrnmGrVp00a1a9eW3W5Xenq69uzZo1WrVlkfVmOMfvzxRw0YMEA//PBDhW6xEiioDAMA/NHLL7+sFi1aaNq0adq6davS0tLO6Z68oaGh1gM3pk2bpm3btskYowYNGqhPnz4aM2aMEhMTNW/ePA+ehW+78MILtXHjRv2///f/9Pnnn2vPnj2y2+1KTEzUnXfeqfvuu09z5syx2sfGxlbjaH2LzXj45nvZ2dm65JJLdPDgQdlsNsXFxenvf/+7RowYIbvdXup+27dv15NPPqmvv/66aGA2m/75z3/qoYce8uTwzll6erpiY2OVlpamGjVqePVYrVtLxR4soxkzpMGDvXpIAABwnvr73/9uTVXJyMg4r6vDZ5PXPP4Fuo8++sgKwgkJCVq5cqXuv//+MoOwJLVs2VJz5szRk08+KamoQvzyyy97enh+jcowAACoDGOMZs6cKanoQSXncxA+Wx4Pw6cru5L0zjvvWN/4rKiJEyeqc+fOkqQjR45o7dq1Hh2fP2HOMAAAqIh9+/aVeVeuZ599Vlt+/3Pz8OHDq2pYfsHjc4ZP3wi7fv36uv766yvVx8iRI7V69WpJ0pYtW9SxY0ePjc+fURkGAADuTJ06VVOmTNEdd9yhrl27KiEhQQUFBdq+fbs++ugjLVmyRJJ06aWX6s9//nP1DtbHeDwMHz16VDab7awrwsWdvnm0FNiPDqQyDAAAKurAgQNlTjE9/aXC8qauBhqPh+Hw8HDl5eUpKyur0n0Uf6IMP7A/UBkGAADu3H333YqNjdW3336r3bt369ixY8rJyVGtWrXUtm1b3XzzzRo5cqTCwsKqe6g+x+NhuH79+jp16pS2bNmi9PT0St1x4ccff3TpL1BRGQYAABXRqFEjPfzww3r44Yereyh+x+NfoOvevbukouePv/TSS2e9f0pKit55550S/YHKMAAAgKd5PAwPLnYj3EmTJunVV1+t8L4HDhzQddddp9TUVNlsNnXv3p3KMAAAALzG42G4Z8+e6tevn4wxcjqdeuqpp9SxY0d9/PHHbr8M53A4tG7dOj322GO69NJLrdt+2Gw2vfLKK54enl+jMgwAAOBZXnkc80cffaTu3btrx44dkqSkpCTdddddkqQLLrhAtWvXVlhYmDIyMvTbb78pPz9fUtENoU/75z//qU6dOnljeH6DyjAAAIB3ebwyLEm1a9fWkiVLdN1118kYY4VcY4yOHj2q7du3a+PGjfr111+Vl5fnEoJjY2P10Ucf6cEHHzzr4y5btkwDBw5UQkKCbDabZs+ebW0rKCjQk08+qdatWysqKkoJCQm68847dejQoXM+36pCZRgAAMCzvBKGJalu3bpasGCBvvzyS/Xp00e2YmXO0wG5eAiuW7euxo0bp23btmnYsGGVOmZWVpbatm2ryZMnl9iWnZ2tpKQk/e1vf1NSUpK+/PJL7dy5UzfccEOljlUVqAwDAAB4l1emSRR300036aabblJWVpbWrl2rPXv26NSpU8rLy1NsbKwuuOACXXHFFWrevPk5H6tfv37q16+f222xsbFauHChy7o33nhDnTp10oEDB3ThhRee8/G9jcowAACAZ3k9DJ8WFRWlnj17qmfPnlV1yHKlpaXJZrOpZs2apbbJy8tTXl6e9T49Pb0KRlaEyjAAAIB3eW2ahK/Lzc3VU089pTvuuKPMB4NMnDhRsbGx1qtRo0ZVOEpXVIYBAAA8KyDDcEFBgQYPHiyn06k333yzzLbjxo1TWlqa9UpOTq6iUVIZBgAA8LZKTZOYNm2ap8dRqjvvvNOj/RUUFOj222/X3r179cMPP5T7uGi73S673e7RMVQWlWEAAADPqlQYvuuuu1zuDuEtNpvNo2H4dBDetWuXFi9erPj4eI/17Q1UhgEAALyr0l+gMz5YpszMzNTu3but93v37tWGDRtUq1YtJSQk6NZbb1VSUpK+/vprORwOpaSkSJJq1aqlsLCw6hp2hfngJQcAAPBrlQrDV199dZVUhs/Wzz//rF69elnvH3nkEUnS8OHDNWHCBM2ZM0eSdPnll7vst3jxYp+6y8VpPniJAQDwO02aNNH+/fs1fPhwTZ061WXbvn371LRpU0nSlClTrCfmnq2pU6dqxIgRkoqKcU2aNDmHEZ+7ss4ZrioVhpcsWeLhYXhGz549y6xY+2I1+2z4+fABAAB8TkDeTcJfUBkGAACn9ezZUzabzSf/mu3PquyhGzh3VIYBAPCsJk2a+P1fjt3Zt29fdQ/Bb1AZ9mFUhgEAALyLMOxHzsNfXAEAAKoVYdiHURkGAPir7OxsxcTEyGazaejQoeW2X7NmjWw2m2w2m9544w1rfVZWlmbOnKl77rlHl19+uWJjYxUaGqoLLrhAPXr00KRJk5SZmVnpce7bt886bll3XUhNTdVTTz2lxMRERUREqE6dOurTp48+//zzCh0nPz9fc+fO1ejRo9WxY0fFxcUpNDRU8fHx6ty5syZMmKDjx4+73ff08x2WLl0qSVq6dKk15tOvM+9e0aRJE9lstnLvjjF37lzdeuutatiwoex2u+Lj43XVVVfp5ZdfLvO6Tp061Tr2vn375HQ69e6776pLly6Ki4tTVFSU2rRpoxdffFHZ2dkVukbVxuCspKWlGUkmLS3N68e66ipjiurBRa933vH6IQEA8JihQ4caSSYqKspkZmaW2XbMmDFGkgkODjZHjhyx1vfo0cNIKvPVtGlTs3379lL7bty4sZFkhg8fXmLb3r17rX6mTJnidv+tW7ea+vXrl3r8kSNHmilTpljv9+7dW6KP4cOHl3se8fHxZvny5ZXat3HjxhU+Z2OMycnJMTfffHOZfSYkJJj169e73b/4+W7ZssX07t271H46depU7s/f084mr1EZ9mFUhgEA/mzIkCGSiqq7X331VantHA6HZs6cKUm69tprVadOHWtbYWGhWrduraefflqzZs3S6tWrtWrVKs2cOVODBw9WUFCQ9u7dq5tuukm5ubkeP4e0tDRdd911Onz4sCTpT3/6k+bPn6+ff/5Z06dPV4cOHfThhx/qzTffLLOfwsJCNWvWTI8++qhmzpyplStXau3atfrvf/+r+++/X2FhYTpx4oRuvvlmHT161GXfF198UZs3b1aHDh0kSR06dNDmzZtdXt99991Zndfw4cM1a9YsSVLbtm01bdo0rV27Vt9++61GjBghm82mQ4cO6ZprrtHBgwfL7Ovee+/VkiVLNHz4cM2bN0/r1q3TrFmzdNVVV0kqqvr//e9/P6vxVakqCOfnlaqsDHfp4loZfvttrx8SAOBwGHP0aGC9HA6vXMrCwkJTp04dI8n079+/1HbfffedVUX8+OOPXbbt3LmzzGMsXLjQBAUFGUnm/fffd9vmXCrDjzzyiLX9pZdeKrE9Pz/f9O3b16US6q4yvHv3buN0Oks9j02bNpno6GgjyTzzzDNu25yukvfo0aPUfk4r65y//vpra6zXXHONycvLK9Hm3XfftdrcfvvtJbYXrwy7+7kZY0xubq5p1aqVVfUuKCgod9yecjZ5jTB8lqoyDHftShgGgCp39Kjrf3wD4XX0qNcu54MPPmgkmZCQEHPs2DG3bU5PA4iMjDQZGRlnfYybbrrJSDIDBgxwu72yYTg3N9fExcUZSaZNmzbGUcovDcnJySY0NLTMMFwRY8eONZJMq1at3G73VBju16+fkWRCQ0PNgQMHSu2jT58+1s/u0KFDLtuKh+FBgwaV2sfbb79ttdu4cWO54/YUpkmcp7ibBADA35z+8lxhYaHbL5vl5uZaf66/8cYbFR0dXWZ/x44d065du7RlyxbrdcEFF0iSNm7c6NGxr1u3TqmpqZKKphUEBbmPTQ0bNlTfvn3Pqu/U1FTt2bNHW7dutc6jZs2akqRt27apoKDgnMZemsLCQuuLeNdee60aNWpUats///nP1j5lPX349HQYd9q3b28t//rrr2c52qrBQzd8GHOGAQD+rlOnTmrRooV27dqlTz/9VA888IDL9rlz5yo9PV1S6aHqp59+0r///W8tWrRIJ0+eLPVYpd2NobI2b95sLXfs2LHMtp06ddK8efPK7e+f//ynFixYoJSUlFLbOZ1Opaamusyd9pRff/3VurtD586dy2xbfPuWLVtKbZeYmFjqtlq1alnLGRkZFR1mlaIy7EeoDAMA/NEdd9whSVqxYkWJJ6N9+umnkqTatWu7ra5OmDBB3bp10//93/+VGYQlKScnxzMD/t3pqrCkcoNp3bp1y9z+wQcf6IorrtCUKVPKDMKnefpcTit+Dcsbc7169dzud6bIyMhStxWvpjscjooMscpRGfZhVIYBoBrEx0tnfJv/vBcf79XuhwwZoueee07GGM2YMUPjxo2TVBQ2FyxYIEm6/fbbFRoa6rLf999/r+eee06S1KxZMz322GPq1q2bLrzwQkVHRys4OFiS9Oyzz+qFF17w+LhNsSqUrZz/KZsyKla//PKL7r//fhUWFqpOnTp6/PHH1bt3bzVp0kQxMTHWeX/44Ye6++67y+3PU8o7p0BBGPYjVIYBoAoEBUm/z0GFZ7Ro0UKdOnXSmjVr9Omnn1ph+L///a/y8/MluZ8i8d5770mSatasqZUrV5ZanS1ewfWk4n/iP3LkiC6++OJS2555O7Tipk6dqsLCQgUHB2vJkiVq2bKl23beOo/iip9TeRXq4tuL73e+YZqED+MXNgDA+eJ02N26das2bdokSZo+fbqkoqelnb4nbXFbt26VJPXu3bvMaQo///yzp4crSWrdurW1vHbt2jLblrX99Hm0bdu21CAslX8enqjkNmvWzJrWsHr16jLbrlmzxlpu1arVOR/bVxGG/QiVYQCAvxo8eLA1reHTTz/Vb7/9pmXLlkkqCsrugl5hYaEklfk43w0bNmjVqlVeGHHRnRDi4uIkSR9//HGpUxcOHjxY5kMvKnIeKSkpZT6YRJLCw8MlSXl5eWW2K0tISIh69OghSVq4cKGSk5NLbfv+++9LkoKDg9WzZ89KH9PXEYZ9GJVhAMD5ok6dOurTp48kacaMGZo+fbqcTqekP75gd6YWLVpIkpYvX+72tlzHjh2zbt3mDXa7XSNGjJBUFLpfffXVEm0KCwv15z//2Zru4c7p89i5c6fb4J6dna077rij3C/N1a9fX1LRHSHOZU7xqFGjJEkFBQUaOXKk27F/+OGHVsC/5ZZbrGOfjwjDfoTKMADAn50OrsnJyZo4caIkqV27drr00kvdtr/zzjslSZmZmerRo4cmT56slStXasWKFZo0aZLatm2rbdu2uZ1i4SnPPvusGjZsKEl68skndccdd+ibb75RUlKSPvvsM3Xp0kULFiwo89Zrw4YNk1R0y7Trr79eL7/8spYtW6Y1a9borbfe0uWXX67Fixera9euZY6lS5cukormJz/yyCNat26ddu/erd27d2v//v0VPqf+/fvrtttukyQtWrRInTt31ieffKJ169Zp0aJFuueee3TPPfdIKpor/Nprr1W4b7/k1cd/nIeq8gl0PXu6PiDojTe8fkgAALwmIyPDREZGujzGd9KkSWXuM2LECJf2xV/BwcHm9ddfN+PHj7fWuXMuj2M2xpgtW7aYevXqlTqOESNGuDyRzd0T6J577rlS95dkHn300XL7yMjIMM2aNXO7f+PGjSt8zsYYk5OTY26++eYyx5SQkGDWr1/vdv/yxno219cbeALdeYrKMADAn0VHR+vGG2+03gcFBWnw4MFl7vPhhx/q448/Vvfu3RUTEyO73a7GjRtr2LBhWrFihcaMGePtYeuyyy7T1q1b9cQTT6hFixay2+2qXbu2evXqpenTp+vDDz8st49nn31W8+bNU9++fRUXF6ewsDA1bNhQgwYN0nfffadJkyaV20d0dLR1zi1btizz/r7lCQ8P15dffqk5c+Zo0KBBSkhIUFhYmOLi4tS5c2dNnDhRO3bs0OWXX17pY/gLmzFErLORnp6u2NhYpaWlqUaNGl49Vu/e0uLFf7z/97+lBx/06iEBAAD83tnkNSrDfoRfWwAAADyLMOzDuJsEAACAdxGG/QiVYQAAAM8iDPswKsMAAADeRRj2I1SGAQAAPIsw7MOoDAMAAHgXYdiPUBkGAADwLMKwD6MyDAAA4F2EYT9CZRgAAMCzCMM+jMowAACAdxGG/QiVYQAAAM8iDPswKsMAAADeRRj2I1SGAQAAPIsw7MOoDAMAAHgXYdiPUBkGAADwLMKwD6MyDAAA4F2EYT9CZRgAAMCzCMM+jMowAACAdxGG/QiVYQAAAM8iDPswKsMAAADeRRj2I1SGAQAAPIsw7MOoDAMAAHgXYdiPUBkGAADwLMKwD6MyDAAA4F2EYT9CZRgAAMCzCMM+jMowAACAdxGG/QiVYQAAAM8iDPswKsMAAADeRRj2I1SGAQAAPIsw7MOoDAMAAHgXYdiPUBkGAADwLMKwD6MyDAAA4F3nVRhetmyZBg4cqISEBNlsNs2ePdtluzFGEyZMUEJCgiIiItSzZ09t3bq1egZbCVSGAQAAPOu8CsNZWVlq27atJk+e7Hb7K6+8otdee02TJ0/W2rVrVa9ePV177bXKyMio4pFWDJVhAAAA7wqp7gF4Ur9+/dSvXz+324wxev311/X0009r0KBBkqSPPvpIdevW1fTp03XfffdV5VArhcowAACAZ51XleGy7N27VykpKerbt6+1zm63q0ePHlqxYkWp++Xl5Sk9Pd3lVVWoDAMAAHhXwIThlJQUSVLdunVd1tetW9fa5s7EiRMVGxtrvRo1auTVcZaFyjAAAIBnBUwYPs12RrnVGFNiXXHjxo1TWlqa9UpOTvb2EC1UhgEAALzrvJozXJZ69epJKqoQ169f31p/9OjREtXi4ux2u+x2u9fHVxFUhgEAADwrYCrDTZs2Vb169bRw4UJrXX5+vpYuXaouXbpU48hKR2UYAADAu86rynBmZqZ2795tvd+7d682bNigWrVq6cILL9TYsWP10ksvqUWLFmrRooVeeuklRUZG6o477qjGUVcclWEAAADPOq/C8M8//6xevXpZ7x955BFJ0vDhwzV16lQ98cQTysnJ0V/+8helpqaqc+fO+u677xQTE1NdQy4TlWEAAADvOq/CcM+ePWXKKJ/abDZNmDBBEyZMqLpBeRCVYQAAAM8KmDnD/ojKMAAAgHcRhv0IlWEAAADPIgz7MCrDAAAA3kUY9iNUhgEAADyLMOzDqAwDAAB4F2HYj1AZBgAA8CzCsA+jMgwAAOBdhGE/QmUYAADAswjDPozKMAAAgHcRhv0IlWEAAADPIgz7MCrDAAAA3kUY9iNUhgEAADyLMOzDqAwDAAB4F2HYj1AZBgAA8CzCsA+jMgwAAOBdhGE/QmUYAADAswjDPozKMAAAgHcRhv0IlWEAAADPIgz7MCrDAAAA3kUY9iNUhgEAADyLMOzDzqwME4YBAAA8izAMAACAgEUY9mFUhgEAALyLMAwAAICARRj2YVSGAQAAvIswDAAAgIBFGPZhVIYBAAC8izAMAACAgEUY9mFUhgEAALyLMAwAAICARRj2YVSGAQAAvIsw7MPODMMAAADwLMKwH6EyDAAA4FmEYR9GZRgAAMC7CMN+hMowAACAZxGGfRiVYQAAAO8iDPsRKsMAAACeRRj2YVSGAQAAvIsw7EeoDAMAAHgWYdiHURkGAADwLsKwH6EyDAAA4FmEYR9GZRgAAMC7CMN+hMowAACAZxGGfRiVYQAAAO8iDPsRKsMAAACeRRj2YVSGAQAAvIsw7EeoDAMAAHgWYdiHURkGAADwLsKwH6EyDAAA4FmEYR9GZRgAAMC7CMN+hMowAACAZxGGfRiVYQAAAO8iDPsRKsMAAACeFVBhuLCwUM8884yaNm2qiIgINWvWTM8//7ycTmd1D80tKsMAAADeFVLdA6hK//jHP/T222/ro48+0mWXXaaff/5ZI0aMUGxsrMaMGVPdwysXlWEAAADPCqgwvHLlSt14443q37+/JKlJkyaaMWOGfv7552oemXtUhgEAALwroKZJdOvWTd9//7127twpSdq4caOWL1+u66+/vtR98vLylJ6e7vKqLlSGAQAAPCugKsNPPvmk0tLSlJiYqODgYDkcDr344ov63//931L3mThxop577rkqHOUfqAwDAAB4V0BVhmfOnKlPPvlE06dPV1JSkj766CNNmjRJH330Uan7jBs3TmlpadYrOTm5CkfsisowAACAZwVUZfjxxx/XU089pcGDB0uSWrdurf3792vixIkaPny4233sdrvsdntVDtNCZRgAAMC7AqoynJ2draAg11MODg722VurnYnKMAAAgGcFVGV44MCBevHFF3XhhRfqsssu0/r16/Xaa69p5MiR1T00t6gMAwAAeFdAheE33nhDf/vb3/SXv/xFR48eVUJCgu677z49++yz1T20CqEyDAAA4FkBFYZjYmL0+uuv6/XXX6/uoVQIlWEAAADvCqg5w/6OyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPCugAvDBw8e1NChQxUfH6/IyEhdfvnlWrduXXUPq0KoDAMAAHhWSHUPoCqlpqaqa9eu6tWrlxYsWKA6depoz549qlmzZnUPzS0qwwAAAN4VUGH4H//4hxo1aqQpU6ZY65o0aVJ9AzpLVIYBAAA8K6CmScyZM0cdOnTQbbfdpjp16qhdu3Z67733ytwnLy9P6enpLq+qQmUYAADAuwIqDP/6669666231KJFC3377be6//779dBDD2natGml7jNx4kTFxsZar0aNGlXhiF1RGQYAAPAsmzGBE7HCwsLUoUMHrVixwlr30EMPae3atVq5cqXbffLy8pSXl2e9T09PV6NGjZSWlqYaNWp4dbxvvimNGvXH+6uvlpYu9eohAQAA/F56erpiY2MrlNcCqjJcv359XXrppS7rWrZsqQMHDpS6j91uV40aNVxe1SVwfm0BAACoGgEVhrt27aodO3a4rNu5c6caN25cTSMqG3OGAQAAvCugwvDDDz+sVatW6aWXXtLu3bs1ffp0vfvuuxpVfC6CD6MyDAAA4FkBFYY7duyoWbNmacaMGWrVqpVeeOEFvf766xoyZEh1D80tKsMAAADeFVD3GZakAQMGaMCAAdU9jEqhMgwAAOBZAVUZ9jdUhgEAALyLMOxHqAwDAAB4FmHYh1EZBgAA8C7CsB+hMgwAAOBZhGEfRmUYAADAuwjDfoTKMAAAgGcRhn0YlWEAAADvIgz7ESrDAAAAnkUY9mFUhgEAALyLMOxHqAwDAAB4FmHYh1EZBgAA8C7CsB+hMgwAAOBZhGEfRmUYAADAuwjDfoTKMAAAgGcRhn0YlWEAAADvIgz7ESrDAAAAnkUY9mFUhgEAALyLMOxHqAwDAAB4FmHYh1EZBgAA8C7CsB+hMgwAAOBZhGEfRmUYAADAuwjDfoTKMAAAgGcRhn0YlWEAAADvIgz7ESrDAAAAnkUY9mFUhgEAALyLMOxHqAwDAAB4FmHYh1EZBgAA8C7CsB+hMgwAAOBZhGEfRmUYAADAuwjDfoTKMAAAgGcRhn0YlWEAAADvIgz7ESrDAAAAnkUY9mFUhgEAALyLMOxHqAwDAAB4FmHYh1EZBgAA8C7CsB+hMgwAAOBZhGEfRmUYAADAuwjDfoTKMAAAgGcRhn0YlWEAAADvIgz7ESrDAAAAnkUY9mFUhgEAALyLMOxHqAwDAAB4FmHYh1EZBgAA8C7CsB+hMgwAAOBZhGEfRmUYAADAuwjDfoTKMAAAgGcRhn0YlWEAAADvIgz7ESrDAAAAnkUY9mFUhgEAALyLMOxHqAwDAAB4FmHYh1EZBgAA8C7CsB+hMgwAAOBZhGEfRmUYAADAuwI6DE+cOFE2m01jx46t7qFUCJVhAAAAzwrYMLx27Vq9++67atOmTXUPpVRUhgEAALwrIMNwZmamhgwZovfee09xcXHVPZwKozIMAADgWQEZhkeNGqX+/furT58+5bbNy8tTenq6y6uqUBkGAADwrpDqHkBV++yzz5SUlKS1a9dWqP3EiRP13HPPeXlUFUNlGAAAwLMCqjKcnJysMWPG6JNPPlF4eHiF9hk3bpzS0tKsV3JyspdH+QcqwwAAAN4VUJXhdevW6ejRo2rfvr21zuFwaNmyZZo8ebLy8vIUHBzsso/dbpfdbq/qobpFZRgAAMCzAioMX3PNNdq8ebPLuhEjRigxMVFPPvlkiSBc3agMAwAAeFdAheGYmBi1atXKZV1UVJTi4+NLrPdFVIYBAAA8K6DmDPsbKsMAAADeFVCVYXeWLFlS3UOoMCrDAAAAnkVl2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhVIYBAAC8izDsR6gMAwAAeBZh2IdRGQYAAPAuwrAfoTIMAADgWYRhH0ZlGAAAwLsIw36EyjAAAIBnEYZ9GJVhAAAA7yIM+xEqwwAAAJ5FGPZhZ1aGCcMAAACeRRgGAABAwCIM+zAqwwAAAN5FGAYAAEDAIgz7MCrDAAAA3kUYBgAAQMAiDPswKsMAAADeRRgGAABAwCIM+zAqwwAAAN5FGAYAAEDAIgz7MCrDAAAA3kUYBgAAQMAiDPswKsMAAADeRRgGAABAwCIM+zAqwwAAAN4VUGF44sSJ6tixo2JiYlSnTh3ddNNN2rFjR3UPCwAAANUkoMLw0qVLNWrUKK1atUoLFy5UYWGh+vbtq6ysrOoemltnVoYBAADgWSHVPYCq9M0337i8nzJliurUqaN169bp6quvrqZRAQAAoLoEVBg+U1pamiSpVq1apbbJy8tTXl6e9T49Pd3r4zrNXWXYGCrGAAAAnhJQ0ySKM8bokUceUbdu3dSqVatS202cOFGxsbHWq1GjRlU4SgAAAHhTwIbh0aNHa9OmTZoxY0aZ7caNG6e0tDTrlZycXEUjLL0yDAAAAM8IyGkSDz74oObMmaNly5apYcOGZba12+2y2+1VNDIAAABUpYAKw8YYPfjgg5o1a5aWLFmipk2bVveQykRlGAAAwLsCKgyPGjVK06dP11dffaWYmBilpKRIkmJjYxUREVHNoyuJL8oBAAB4V0DNGX7rrbeUlpamnj17qn79+tZr5syZ1T20CqMyDAAA4DkBVRk2fpYkqQwDAAB4V0BVhs8HfpbnAQAAfBph2IdRGQYAAPAuwrCfoTIMAADgOYRhH0ZlGAAAwLsIw36GyjAAAIDnEIZ9GJVhAAAA7yIM+xkqwwAAAJ5DGPZhVIYBAAC8K6AeuuFvQvfuVBvlKEz5ClWBtulSGVOzuocFAABw3iAM+7CEwd21UUet9731vaTe1TcgAACA8wzTJHxZaJjL2zDlM2cYAADAgwjDPsyElQzDAAAA8BzCsA8zVIYBAAC8ijDsy9yEYQAAAHgOYdiHuZsmQWUYAADAcwjDPszdNAkAAAB4DmHYlzFnGAAAwKsIwz6Mu0kAAAB4F2HYl1EZBgAA8CrCsA+jMgwAAOBdhGEfxn2GAQAAvIsw7MuoDAMAAHgVYdiHURkGAADwLsKwLwsNdX2rgmoaCAAAwPmJMOzLqAwDAAB4FWHYlzFnGAAAwKsIwz6MOcMAAADeRRj2ZVSGAQAAvIow7MOoDAMAAHgXYdiXURkGAADwKsKwL3MThp3OahoLAADAeYgw7MNCokqG4ZycahoMAADAeYgw7MPCY0qG4fT0ahoMAADAeYgw7MOCwkuG4YyMahoMAADAeYgw7MvczBmmMgwAAOA5hGFf5iYMUxkGAADwHMKwL6MyDAAA4FWEYV9GGAYAAPAqwrAvY5oEAACAVxGGfVloqMtbKsMAAACeRRj2ZVSGAQAAvIow7MvOCMOhKlRGGs9jBgAA8BTCsC87IwxLUnZagVRYKBlTDQMCAAA4vxCGfZmbMDxw2z+kunWlCy+Uvv/e/X5padKCBVJKipcHCAAA4N8Iw74sPLzEqpH7x0snT0q//SYNGyYVFLg2+O03qVkz6frrpZYtpQ0bqmasAAAAfogw7Mvq1FFWvYtK3374sFJ73qzj736pwh9XSrt3SzffXBSWJenUKalPH2njRunrr4vWnzgh7dwpOZl7DAAAYDOGyadnIz09XbGxsUpLS1ONGjW8frysFRuV07WPauu4ZzuuU0d65BEpJKQoNF93ndSunTRqlLRihXTLLdJ990m1akmnz/OLL6RFi6R+/aQbbqj4sYyRDh+W6tWTgvj9CwAAeNfZ5DXC8Fmq6jAsSXNe3qZ2465TI/1WJcersE8/lbp3LwrWp05JS5ZI69YVhecbbpDatCmavzxggLR8+R/7XXKJdP/9UmyslJMj3XZb0fzouXOLgvPAgUXbVq6U1qwpav8//yPZbK7HdziKqtzNmkl2+x/rjZGOHy8ayyWXSE2bFh3nrbekX36ROnaUDh0qGl/37tJnn0mNGhUd111Ydzqlzz+XDh6Uhg4t+gVBKvpFwp2cnKJtNpsUHFz0T6dT2rxZuugiKTr6j7b5+dLs2VJkZNHUluLHz8yUUlOlhg2lrKyiyn+bNkX9ubsWwcFSbm7RtThze25u0T9PT705dqxojHFx7s+hMoxxPe62bUXjat3ac8cAAKACCMNeVB1hWJK+mpqqmg8MVo/c76rsmL4kLzRKB+PbKsg4FOLIU1TuccVlFv1ykB8SoQN1Oykzso6is4+o6aGfFGwcZ32M3NBo7Wz6P8oOryV7Qaais4/KZpyqc2K7amQddj+usGgdSLhSWZF11OzAYtXILNkuNbaxYtOTFWSKpqZkR9TS/kbdFOwo0MV7Fric46GEjrIZp2IyD6nmqX0KdhaW6K8w2K6MmPrKs8cqtCBL8Sd3y2kLkrEFKcg4lGuPVXZUHRmbTXnhsYrKPKKap/bLGRSsgw2vlD33lGof264g49TBhp1UGBqpqMwURacfUnheuo7WbSWbjApDwnUk4QqF5meqTsomhRZkK8hRUPQyDqXWaq6M2AbKiYxXw/0/qeaJPUpu2kPH6rVSgwMr1XD/it/HG6b1XUZLxig645CiMo8oMvOYIjOPqDAsUtnRdZUZ20AxqfuVF1lLh5t1VVBhvux56Qp25Cu1zsVyhEYoSE7JOGVzOhWedUJBzgKZoBA5g4IlSTanUxFZx2VkU2Z8YxWGhivIUajwrBPKj4iVzVkoe06aQnPTFZZb9PSaU/VaKi8yzjqv0NwMRZ/6TTkxdZQXUVPhWScUXJCr7Nj6CnIWyp51QnlR8SoMjdAFB9YpJ6aOsmITFOQsVHjmMTmDQ1Vgj1ZhWJRsMgrLOaWC8BrWWGJO7ldobobyw2uoIDxG+eE1VBgWqdC8TIXkZyvIWajC0AgFF+YqpCBX+eE1lBdVS0GF+QopyFFwQa6CHPkKy0lTdo36CnbkKz88RsYWLJuMZIycwaEKzS26IXmQs1DGZpMJCpEJCpYzKETO4BBJNklGNlO0T7AjX/bsVOXE1Pn9ev7+S43NJlN82WaTfv+sGdlkk1F45nE5QsIUUpCrsOxTyo+sKWdQsMKzTion+gIV2qMUXJinyLTDyouqJWdwqGoe2SFnUIjyI2KVWetCOYNCrPFLRf9LOj22sLx0hRTkKiQvUwXhNZQfEauIjKMKyctSgT1aNuNUYViEHCHhikxPkTMoRNmx9eUIi5AzOFRBzkIFF+YVXbvCfNmMo+haOwrkCLErPzJOeZE15QwOVXBBnoId+ZJxKsjpkM3pkM045QwOkTPErtiUXxRzfK9yo2srs3ZTpdVprvDME4pKTVZeZC1lxzWQPfOECu1RcoTYZXM6FGR+7+f3vhyh4QrJz1ahPUqhOWkqiIiVIzjs959VkJzBob//jH6/7CX+C1D2/7JtZ/4v3XbGNmNkM07ZjJupcqXEAVsZxzSyFf0Sf/qzcuYv4qfblbLe3RkWrS6ln7NsX3x9UGG+QnMz5AixyxkSVvTzKcyXCQqSIzRcJihEwQU5RccJCpGxuftLZinXqJRrV/zfGRnj8jm3fh5u1kmSCQ6RMzhUMkZBzsKiz2VhgSLSUpQTW0+F9qg/rkqx/f7oT0X/3gf//gCv4tuLvZeMbE6n28+F68/tj/8W/HE13Kyzlv/YFlSYL5uzUDk1E1RwQYL6jmvv9iYBnkQY9qLqCsOS5Chwase/vtHupQeVse+EWu36Um3z1lbpGAAAAM5JaqpUs6ZXD0EY9qLqDMPumPwCHT+Ur/RFa3QsO0pZe1J06oRDSdFXKz/lpG5bOkqdTi2UJP2s9pqjG9RRazVQX1fzyAEAQKDJVoQinVmlV/M9hDDsRb4WhiskO1smPEInTtp08KB0JMUo9Ju5yj94TJtqdFPukTTVOrBB0ad+U43MQ+p16kulKVaNnftcuvlVTdVMe6vnHAAAgN/bE9RcFzl2ef04hGEv8sswXEnGaZS3O1kZaU6l1mistHSbMjOl3NQcRa5YpOyIeJ2Iv1ixyVvkLHDoWL3WsmVnKTXmQkUf/VWNd3yrGqkHdDz2Ih2o21HhwQWyZWXIlpGhsIIsHbzgcqVGNlDd1F8Ul75fv9brorzQaLXb9X+ql7pNWy+8XsdjmurS/QtkL8xShr22ZLOpzqkdisk5prTI+sq0xystsr6ic48rOve4suxxSo1sqIyIOjoe1Vix2Yd1efJcFQaFaVWzO1Q7c58SDy9WXPZvOhh7mcIc2coLidKpyAaKzEtVdN4JReWdVG5IlDLC68hpC1J03kmlhdeV0xas8IIMnYxqJKex6dIjP6h98mwdqtFS6eF11DBti1IjErQh4Xpl2C9Qo1OblRcSpXR7bRkFqVbOQQU5C5QVGiebjIKdBQpx5stpC1ZhUKjCHLnKCItXkLNQjdK36FBMog5HN1ds7lHF5h2VzelQhj1eMfknFVaYLZtx6lR4PUUVnFLt7AP6LaalYvKPKz84UuEFGTI2m7JDYnUkqpkKguwKchaqXtYe1cveoxPhDXU4qrlq5R5U/czdsskphy1EdkeOCm2h2lujrSIKM9Qoc5vygiJ1IOYyhTuyFFVwSgVBdoU7MpUZGienLUSxeUflCApVeGGmMsJq6YKcZJ2y11Gws1BxeYdVaAtTTki0jGwKc+TIKEgpEU0V6shVYVCoCm1hCnNkK9g4FObIUc38o8oJjlJ2cIwiHJmqnXdQMpLTFiTJJqctSNnBMcoNjlKQcSjYOGR+X++0BSvEWaBwR5bCnEVfGswIjVNUYZrygyKUFVxD2SE1lBkcq3BHlhrnbFeoM//3cYTKYQtVekgtRTnSFebMVVpovIJNoaIL0xRkHMoJjpbdma0IR6ZiC04oPbSWsoNjVGgLU2ZITRnZFOHMVERhpkJNngpsdhmbTXZHjgqC7EoLjVdqaF1FODIV6chQpCNdEY5M5QYXzf3LC4qQkU35QeEqtIUpPv+wQkyBHLYQ5QVFKD+o6AuQ2cExqllwTIW2UIU7s2Vks+bpBZtCGdkU6sxXZkisCm1hCjaFCjaFCpJDIabo3uRFc/1s1rXLDwpXhCPTmk9oOz2Hsdj7omWjIOM8vadygqIVJKeyg6MV6sxXuDNb2cHRyg2KUlzBEUk2FdpC5LQFK8yZJ5ucOhbWUEHGoQhnpmIKU2UU5HIOp+chGtms8aeH1FJMYapCTb6OhyUoP8iuMGeuCm1hsjtzZHfmKC8oQgW2MNUsPKZQZ75CTL4cthDl28KVH2SXwxaiCEeWbHIqPyhcWcGxinKkKaYwtWievC3MGqtTwXL8/s8Qk68IZ5bszhwV2OzKCwpXsClUlCNdDlvR/N7coEhFOjJVaAu1rpmjeD+2YBnZFOnIUE5wtMId2XLaghVq8n6/kkXzvkNMgfUzrPB/q8+irdMWVOJ6V6Qvd+ttv38+ij4bzlLnFpc2n7b0uchn176ix3XYgpUVXEOhJl+hzqLPxumfV5gzVyGmoOjfQZut6N8X45D7WdsVnBdtrH/DrP9OGZt11WRdQTfrJClYhQoxBTKyyWELkVO//+xsNoU5836/Tmf8O1N8nr+kYOOw+ig+RnPGfkWf+T/6P/P6/XGNS64rfv1tZ85LlhQkh3UOF+Qf0qGoFup48lu319CTCMNeFEhhGAAAwB+dTV4LyJu+vvnmm2ratKnCw8PVvn17/fjjj9U9JAAAAFSDgAvDM2fO1NixY/X0009r/fr16t69u/r166cDBw5U99AAAABQxQJumkTnzp11xRVX6K233rLWtWzZUjfddJMmTpxYon1eXp7y8vKs9+np6WrUqBHTJAAAAHwU0yRKkZ+fr3Xr1qlv374u6/v27asVK1a43WfixImKjY21Xo0aNaqKoQIAAKAKBFQYPn78uBwOh+rWreuyvm7dukpJSXG7z7hx45SWlma9kpOTq2KoAAAAqAIh5Tc5/9jOuP2JMabEutPsdrvsdntVDAsAAABVLKAqw7Vr11ZwcHCJKvDRo0dLVIsBAABw/guoMBwWFqb27dtr4cKFLusXLlyoLl26VNOoAAAAUF0CbprEI488omHDhqlDhw666qqr9O677+rAgQO6//77q3toAAAAqGIBF4b/9Kc/6cSJE3r++ed1+PBhtWrVSvPnz1fjxo2re2gAAACoYgF3n+FzxeOYAQAAfBv3GQYAAAAqgDAMAACAgEUYBgAAQMAiDAMAACBgEYYBAAAQsAjDAAAACFgBd5/hc3X6TnTp6enVPBIAAAC4czqnVeQOwoThs5SRkSFJatSoUTWPBAAAAGXJyMhQbGxsmW146MZZcjqdOnTokGJiYmSz2bx+vPT0dDVq1EjJyck85OMsce0qh+tWOVy3yuPaVQ7XrfK4dpXjT9fNGKOMjAwlJCQoKKjsWcFUhs9SUFCQGjZsWOXHrVGjhs9/8HwV165yuG6Vw3WrPK5d5XDdKo9rVzn+ct3KqwifxhfoAAAAELAIwwAAAAhYhGEfZ7fbNX78eNnt9uoeit/h2lUO161yuG6Vx7WrHK5b5XHtKud8vW58gQ4AAAABi8owAAAAAhZhGAAAAAGLMAwAAICARRgGAABAwCIM+7g333xTTZs2VXh4uNq3b68ff/yxuodUrZYtW6aBAwcqISFBNptNs2fPdtlujNGECROUkJCgiIgI9ezZU1u3bnVpk5eXpwcffFC1a9dWVFSUbrjhBv32229VeBZVb+LEierYsaNiYmJUp04d3XTTTdqxY4dLG65dSW+99ZbatGlj3WD+qquu0oIFC6ztXLOKmThxomw2m8aOHWut49q5N2HCBNlsNpdXvXr1rO1ct9IdPHhQQ4cOVXx8vCIjI3X55Zdr3bp11naunXtNmjQp8Zmz2WwaNWqUpAC5bgY+67PPPjOhoaHmvffeM9u2bTNjxowxUVFRZv/+/dU9tGozf/588/TTT5svvvjCSDKzZs1y2f7yyy+bmJgY88UXX5jNmzebP/3pT6Z+/fomPT3danP//febBg0amIULF5qkpCTTq1cv07ZtW1NYWFjFZ1N1rrvuOjNlyhSzZcsWs2HDBtO/f39z4YUXmszMTKsN166kOXPmmHnz5pkdO3aYHTt2mL/+9a8mNDTUbNmyxRjDNauINWvWmCZNmpg2bdqYMWPGWOu5du6NHz/eXHbZZebw4cPW6+jRo9Z2rpt7J0+eNI0bNzZ33XWXWb16tdm7d69ZtGiR2b17t9WGa+fe0aNHXT5vCxcuNJLM4sWLjTGBcd0Iwz6sU6dO5v7773dZl5iYaJ566qlqGpFvOTMMO51OU69ePfPyyy9b63Jzc01sbKx5++23jTHGnDp1yoSGhprPPvvManPw4EETFBRkvvnmmyobe3U7evSokWSWLl1qjOHanY24uDjz/vvvc80qICMjw7Ro0cIsXLjQ9OjRwwrDXLvSjR8/3rRt29btNq5b6Z588knTrVu3Urdz7SpuzJgx5qKLLjJOpzNgrhvTJHxUfn6+1q1bp759+7qs79u3r1asWFFNo/Jte/fuVUpKiss1s9vt6tGjh3XN1q1bp4KCApc2CQkJatWqVUBd17S0NElSrVq1JHHtKsLhcOizzz5TVlaWrrrqKq5ZBYwaNUr9+/dXnz59XNZz7cq2a9cuJSQkqGnTpho8eLB+/fVXSVy3ssyZM0cdOnTQbbfdpjp16qhdu3Z67733rO1cu4rJz8/XJ598opEjR8pmswXMdSMM+6jjx4/L4XCobt26Luvr1q2rlJSUahqVbzt9Xcq6ZikpKQoLC1NcXFypbc53xhg98sgj6tatm1q1aiWJa1eWzZs3Kzo6Wna7Xffff79mzZqlSy+9lGtWjs8++0xJSUmaOHFiiW1cu9J17txZ06ZN07fffqv33ntPKSkp6tKli06cOMF1K8Ovv/6qt956Sy1atNC3336r+++/Xw899JCmTZsmic9cRc2ePVunTp3SXXfdJSlwrltIdQ8AZbPZbC7vjTEl1sFVZa5ZIF3X0aNHa9OmTVq+fHmJbVy7ki655BJt2LBBp06d0hdffKHhw4dr6dKl1nauWUnJyckaM2aMvvvuO4WHh5fajmtXUr9+/azl1q1b66qrrtJFF12kjz76SFdeeaUkrps7TqdTHTp00EsvvSRJateunbZu3aq33npLd955p9WOa1e2Dz74QP369VNCQoLL+vP9ulEZ9lG1a9dWcHBwid+qjh49WuI3NBQ5/Y3rsq5ZvXr1lJ+fr9TU1FLbnM8efPBBzZkzR4sXL1bDhg2t9Vy70oWFhal58+bq0KGDJk6cqLZt2+pf//oX16wM69at09GjR9W+fXuFhIQoJCRES5cu1b///W+FhIRY5861K19UVJRat26tXbt28ZkrQ/369XXppZe6rGvZsqUOHDggif/GVcT+/fu1aNEi3XPPPda6QLluhGEfFRYWpvbt22vhwoUu6xcuXKguXbpU06h8W9OmTVWvXj2Xa5afn6+lS5da16x9+/YKDQ11aXP48GFt2bLlvL6uxhiNHj1aX375pX744Qc1bdrUZTvXruKMMcrLy+OaleGaa67R5s2btWHDBuvVoUMHDRkyRBs2bFCzZs24dhWUl5en7du3q379+nzmytC1a9cSt4vcuXOnGjduLIn/xlXElClTVKdOHfXv399aFzDXraq/sYeKO31rtQ8++MBs27bNjB071kRFRZl9+/ZV99CqTUZGhlm/fr1Zv369kWRee+01s379eut2cy+//LKJjY01X375pdm8ebP53//9X7e3gGnYsKFZtGiRSUpKMr179/arW8BUxgMPPGBiY2PNkiVLXG6hk52dbbXh2pU0btw4s2zZMrN3716zadMm89e//tUEBQWZ7777zhjDNTsbxe8mYQzXrjSPPvqoWbJkifn111/NqlWrzIABA0xMTIz1332um3tr1qwxISEh5sUXXzS7du0yn376qYmMjDSffPKJ1YZrVzqHw2EuvPBC8+STT5bYFgjXjTDs4/7zn/+Yxo0bm7CwMHPFFVdYt8IKVIsXLzaSSryGDx9ujCm6fc748eNNvXr1jN1uN1dffbXZvHmzSx85OTlm9OjRplatWiYiIsIMGDDAHDhwoBrOpuq4u2aSzJQpU6w2XLuSRo4caf37d8EFF5hrrrnGCsLGcM3OxplhmGvn3ul7uIaGhpqEhAQzaNAgs3XrVms71610c+fONa1atTJ2u90kJiaad99912U716503377rZFkduzYUWJbIFw3mzHGVEtJGgAAAKhmzBkGAABAwCIMAwAAIGARhgEAABCwCMMAAAAIWIRhAAAABCzCMAAAAAIWYRgAAAABizAMAACAgEUYBgAAQLVbsmSJbDabbDabmjRpUmXHJQwDAAAgYBGGAQAAELAIwwAAAAhYhGEAAAAELMIwAAAAAhZhGAAAAAGLMAwAAOAhxhjNnTtXd999txITExUXF6fw8HBdeOGFGjhwoN5//33l5+eX2ceECROsW4zddddd1vr58+fr1ltv1UUXXaSIiAjVrVtXPXv21Ntvv11un2cqLCzUJ598oltvvVXNmjVTVFSUYmJi1Lx5cw0dOlSzZs2SMeasz//EiRP617/+pf79+6tp06aKjo6W3W5XQkKCevfurQkTJmjjxo1n1efevXv11FNPqU2bNqpZs6aio6OVmJioUaNGaffu3Wc9xhIMAAAAztnGjRtNx44djaQyXxdddJFZvXp1qf2MHz/eajt8+HCTmZlpbr/99jL7bNWqlfnll18qNM61a9eali1bljvOTp06mR07dlSoT6fTaV555RVTo0aNcvuVZF577bUSfSxevNja3rhxY2OMMR988IGJiIgotZ+wsDDz6aefVmiMpQk59zgNAAAQ2JYuXaobbrhB6enp1rqaNWsqMTFR4eHh2r9/v/bu3StJ2rNnj3r37q1vv/1WXbt2Lbfv4cOH64svvpAk1apVSy1btlRBQYG2bt2qrKwsSdKWLVt0zTXX6KefflLjxo1L7evHH3/U9ddfr8zMTGtdXFycWrZsKafTqW3btlnnsGbNGnXr1k3ff/+9WrduXWqfDodDw4YN04wZM1zWX3DBBVYV+9ixY/rll19UWFgoSUpLSyv3vKdOnaq7775bkhQeHq5WrVopOjpav/76qw4cOCBJys/P17Bhw9S8eXN16tSp3D7dOqcoDQAAEOCSk5NNrVq1rGrlpZdeahYsWGAcDodLu3Xr1rlUjhs1amRSU1NL9Fe8Mly7dm0jyURHR5v333/f5OfnW+0yMzPN888/b4KDg632vXr1KnWcJ0+eNAkJCVbbmJgY88EHH7j0mZOTY1577TVjt9utdomJiSYnJ6fUfseNG+dSrb3yyivNsmXLjNPpdGmXnZ1tvvjiC9O3b18zYcKEEv0UrwxHRUWZ8PBwY7fbzaRJk0xWVpZL23nz5pnY2Firfbdu3UodX3kIwwAAAOdgwIABVijr3LmzyczMLLVtVlaWadeundXeXSgsHoYlmeDgYPP999+X2ufkyZNd2n/xxRdu240ZM8ZqExoaapYuXVpqn59//rlLny+99JLbdklJScZms1ntBg0a5BKuS5ORkVFiXfEwLMnYbDYzf/78Uvv44osvXNrv3r273OO6wxfoAAAAKmnbtm2aN2+eJCksLEzTp09XVFRUqe0jIyP19ttvW+/ffvvtcr+oNnLkSPXu3bvU7aNGjVKXLl1c+jxTdna2pk6d6rLP1VdfXWqft956q26//Xbr/VtvvSWHw1Gi3aRJk6zxN2rUSFOnTlVoaGiZ5yNJ0dHR5bYZMWKE+vXrV+r2m2++2WVKyIoVK8rt0x3CMAAAQCV9+umnVhgcOHCgmjVrVu4+nTp1UvPmzSVJKSkp+uWXX8psP2rUqHL7LN7m+++/d5kTLElLlixxmaf70EMPldvn2LFjreXk5GStX7/eZXt+fr5mzZrl0j4mJqbcfivq3nvvLXO7zWZz+SWgvOtYGsIwAABAJf3444/Wcq9evSq8X6tWrazlpKSkUtvVrVtXbdu2Lbe/4hVUp9OpdevWuWxfvXq1tZyYmKimTZuW2+dVV12l+Ph4t31I0s8//6ycnBzr/S233FJunxUVFham9u3bl9uuYcOG1vKpU6cqdSzuJgEAAFBJW7dutZY/+OADzZ07t0L7bd682Vo+fvx4qe2Kh+ayxMXFqX79+jp8+LAkaffu3erRo4e1fc+ePdZyWXeGOFPr1q21ZMmSEn1I0o4dO6zl+Pj4Mu9icbbi4+MVElJ+TI2MjLSWs7OzK3UswjAAAEAlOJ1Ol2rkmdMIKqqs24wVr8yWJz4+3grDqampLtuKj7N27doV7rN42zP7PHnypLV8wQUXVLjPiggLCzvrfcqbe10apkkAAABUQk5OjpxO5zn3U1YfZxMK7Xa7tZyXl+eyrfh7b/RZvJ2/oTIMAABQCVFRUQoNDVVBQYGkoi+pFZ+a4AkZGRmVahsbG+uyrfj7s+nzzIeIFFf8fUUeouGrqAwDAABUUvHpAbt27fJ4//v27atQO4fDoeTkZOt9nTp1XLYXH+fpJ+FVRPF5wmdOhahXr561/Ntvvyk3N7fC/foSwjAAAEAlXXnlldby999/7/H+t2/fXuI2ae5s2bLF5c4OV1xxhcv24u+TkpKsanZZTp065fIluTP7LH7uhYWFlb7Pb3UjDAMAAFRS3759reXZs2crJSXFo/3n5+dr9uzZ5bb77LPPrOV69erpoosuctnevXt3azktLU0LFiyoUJ+nH7QRHBysq666ymV7QkKCWrZsab1/7733yu3TFxGGAQAAKmno0KHWHRdyc3P1l7/8pdJ3NSjNCy+8UOLLa8UdOnRIkydPtt4PHz5cNpvNpU1iYqJLmP3b3/5WZnU4IyNDL7zwgvV+4MCBJaZeSNKDDz5oLc+cOVMLFy4s+2R8EGEYAACgkqKiovT8889b72fNmqUhQ4aU+yW1tLQ0TZ48WYMHDy73GDt37tSwYcPczsk9ceKEbrzxRmsqRXR0tEaPHu22n6efftpa3rRpk4YPH+42ZKenp2vQoEE6dOiQpKKq8Lhx49z2edddd+mSSy6RVHRrs1tuuUXz588v83xWrVqlr7/+usw2VYm7SQAAAJyDBx54QKtWrdK0adMkSTNmzNA333yjO+64Q926dbO+aHby5Elt27ZNK1eu1KJFi5Sfn6/OnTuX2XefPn2UlJSkzz//XJs2bdJ9992nNm3aqLCwUKtXr9Zbb73lMjXjpZdecnkqW3H9+/fXiBEjNGXKFGucSUlJuvfee9WmTRvryXVvv/22Dhw4YO33xBNPqFOnTm77jIiI0MyZM9W1a1dlZWUpIyND/fv3V58+fXTzzTerefPmCg8P17Fjx7R+/XrNnTtXmzZt0vjx4zVgwICKX2QvIgwDAACcoylTpqhOnTqaNGmSpKIHVPznP//Rf/7zn3Pqt0GDBho7dqxuueUW7dixQ4888kipbceOHesybcGdd955Rzk5OdYc4x07dujRRx8ttf2DDz6oF198scw+27ZtqyVLlmjAgAE6cuSIJGnRokVatGhRmfv5CqZJAAAAnKOgoCC9+uqrWrVqla6//voyHyVss9l0+eWX64UXXtDnn39ebt/9+/fX8uXLS9zN4bT69etr2rRp+uc//1luX6GhoZo+fbo++eSTEl+yK65169aaM2eO/v3vf5eYf+xOhw4dtG3bNj366KMl7nFcXGRkpG6//Xbdcsst5fZZVWzG07O8AQAAAlxGRoaWL1+uAwcO6OTJkwoODlbNmjXVvHlztWnTpsxHIk+YMEHPPfecpKIvw02dOtXatmnTJq1fv16HDx9WjRo1lJiYqB49eig4OLhS49y8ebOSkpJ09OhR2Ww21a1bV1deeaVatGhRqf6kotusrVy5Ujt27NDx48dls9kUHx+vxMREdezY0eeeVsc0CQAAAA+LiYlRv379PN5vmzZt1KZNG4/117p1a7Vu3dpj/UlSSEiIunfv7nI7N1/GNAkAAAAELMIwAAAAAhZhGAAAAAGLMAwAAICARRgGAABAwOLWagAAAAhYVIYBAAAQsAjDAAAACFiEYQAAAAQswjAAAAACFmEYAAAAAYswDAAAgIBFGAYAAEDAIgwDAAAgYP1/rzKO49T0FdEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss function\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "plt.plot(np.arange(0,epochs_1*iterations), list_loss, label='training',c='blue',linewidth = 3)\n",
    "plt.plot(np.arange(0,epochs_1*iterations), list_val_loss, label='validation',c='red',linewidth = 3)\n",
    "\n",
    "plt.title(\"Loss vs. epoch\", fontsize=25)\n",
    "\n",
    "ax.set_ylabel('loss', fontsize=25,horizontalalignment='right',y=1)\n",
    "ax.set_xlabel('epoch', fontsize=25,horizontalalignment='right',x=1)\n",
    "plt.legend(loc='best', prop={'size':20}, edgecolor = \"w\",fancybox=False, framealpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c25d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the mean values\n",
    "filename = 'outputs/models/%s/cbvae_LHCO2020_latent_mean_20d_e-6.csv'%folder_name\n",
    "means_df = pd.read_csv(filename, sep=' ', header=None)\n",
    "mean = means_df.values\n",
    "\n",
    "# Read the std values\n",
    "filename = 'outputs/models/%s/cbvae_LHCO2020_latent_std_20d_e-6.csv'%folder_name\n",
    "stds_df = pd.read_csv(filename, sep=' ', header=None)\n",
    "std = stds_df.values\n",
    "\n",
    "z_samples = np.empty([cond_data.shape[0],latent_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36578f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=0\n",
    "for i in range(0,cond_data.shape[0]):\n",
    "    for j in range(0,latent_dim):\n",
    "        z_samples[l,j] = np.random.normal(mean[i%trainsize,j], 0.05+std[i%trainsize,j])\n",
    "    l=l+1\n",
    "new_events = decoder.predict([z_samples, np.reshape(cond_data, [-1, 1])])\n",
    "for i in range(0,new_events.shape[1]):\n",
    "    new_events[:,i]=new_events[:,i]*feature_max[i]\n",
    "\n",
    "os.system(\"mkdir -p ./outputs/gen_dataset/%s/\"%folder_name)\n",
    "np.savetxt('outputs/gen_dataset/%s/LHCO2020_cB-VAE_events_SB.csv'%folder_name, new_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73d0b6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of gen_SR:  (878648, 6)\n"
     ]
    }
   ],
   "source": [
    "file_gen_SB = 'outputs/gen_dataset/%s/LHCO2020_cB-VAE_events_SB.csv'%folder_name\n",
    "gen_SB = pd.read_csv(file_gen_SB, delimiter = ' ', header=None, index_col=False)\n",
    "gen_SB = gen_SB.to_numpy()\n",
    "print(\"shape of gen_SR: \", gen_SB.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ccc8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_names =  train_features\n",
    "# vnames = train_features\n",
    "\n",
    "plotting_ranges = [(0,0.8), (0,1), (0,1), (0,1), (0,1), (0,1)]\n",
    "\n",
    "def fake_vs_real(gen_data,real_data,doLog,names):\n",
    "    \n",
    "    plt.figure(figsize=(20,15))\n",
    "    colors = [\"steelblue\", \"darkturquoise\"]\n",
    "    for p in range(0,nFeat):\n",
    "        R = np.linspace(plotting_ranges[p][0],plotting_ranges[p][1],51)\n",
    "        plt.subplot((nFeat+1)//2, 2, p+1)\n",
    "        for rd in real_data: b_hist_y, b_hist_x, _ = plt.hist(rd[:,p], R, color=\"black\", histtype='step', linewidth=2, label=\"SB Bkg\", density=True)        \n",
    "        for i,n in enumerate(gen_data): plt.hist(n[:,p], R, color=colors[i], histtype='stepfilled', alpha=0.5, linewidth=2, label=\"Generated Bkg %s\"%names[i], density=True)\n",
    "        # s_hist_y, s_hist_x, _ = plt.hist(sig_data[:,p], R, color=\"r\", histtype='step', linewidth=3, label=\"Signal\", density=True)\n",
    "        plt.xlabel(\"%s\"%feature_labels[p])\n",
    "        if doLog == True: plt.yscale('log')\n",
    "        plt.ylabel(\"Number of Events / bin\")\n",
    "        plt.legend(fontsize=\"large\")\n",
    "        ymax_b = np.max(b_hist_y)\n",
    "        # ymax_s = np.max(s_hist_y)\n",
    "        plt.ylim(0,ymax_b*1.5)\n",
    "#     plt.savefig(\"fake_gen_compare_cbvae_6var_dynamicbeta.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a14facb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878648,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d40a0b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59556/2461113566.py:22: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "  plt.ylim(0,ymax_b*1.5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_vs_real([gen_SB],[x_train],1,[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45f17e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_pytorch",
   "language": "python",
   "name": "tf_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
